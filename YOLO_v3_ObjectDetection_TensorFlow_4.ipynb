{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mralamdari/CV-Yolo/blob/main/YOLO_v3_ObjectDetection_TensorFlow_4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QOQcmZ3Jb28f"
      },
      "source": [
        "# Requirments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "PIUHRF9dD8JW"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import PIL\n",
        "import struct # used to convert native Python data types such as strings and numbers into a string of bytes and vice versa\n",
        "import colorsys\n",
        "import scipy.io\n",
        "import scipy.misc\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab.patches import cv2_imshow\n",
        "from tensorflow.python.saved_model import tag_constants"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "r_4p5NS1kp6j"
      },
      "outputs": [],
      "source": [
        "# YOLO options\n",
        "YOLO_TYPE                   = \"yolov3\" # yolov4 or yolov3\n",
        "YOLO_FRAMEWORK              = \"tf\" # \"tf\" or \"trt\"\n",
        "YOLO_V3_WEIGHTS             = \"model_data/yolov3.weights\"\n",
        "YOLO_V4_WEIGHTS             = \"model_data/yolov4.weights\"\n",
        "YOLO_V3_TINY_WEIGHTS        = \"model_data/yolov3-tiny.weights\"\n",
        "YOLO_V4_TINY_WEIGHTS        = \"model_data/yolov4-tiny.weights\"\n",
        "YOLO_TRT_QUANTIZE_MODE      = \"INT8\" # INT8, FP16, FP32\n",
        "YOLO_CUSTOM_WEIGHTS         = False # \"checkpoints/yolov3_custom\" # used in evaluate_mAP.py and custom model detection, if not using leave False\n",
        "                            # YOLO_CUSTOM_WEIGHTS also used with TensorRT and custom model detection\n",
        "YOLO_COCO_CLASSES           = \"/content/coco.names\"\n",
        "YOLO_STRIDES                = [8, 16, 32]\n",
        "YOLO_IOU_LOSS_THRESH        = 0.5\n",
        "YOLO_ANCHOR_PER_SCALE       = 3\n",
        "YOLO_MAX_BBOX_PER_SCALE     = 100\n",
        "YOLO_INPUT_SIZE             = 416\n",
        "if YOLO_TYPE                == \"yolov4\":\n",
        "    YOLO_ANCHORS            = [[[12,  16], [19,   36], [40,   28]],\n",
        "                               [[36,  75], [76,   55], [72,  146]],\n",
        "                               [[142,110], [192, 243], [459, 401]]]\n",
        "if YOLO_TYPE                == \"yolov3\":\n",
        "    YOLO_ANCHORS            = [[[10,  13], [16,   30], [33,   23]],\n",
        "                               [[30,  61], [62,   45], [59,  119]],\n",
        "                               [[116, 90], [156, 198], [373, 326]]]\n",
        "# Train options\n",
        "TRAIN_YOLO_TINY             = False\n",
        "TRAIN_SAVE_BEST_ONLY        = True # saves only best model according validation loss (True recommended)\n",
        "TRAIN_SAVE_CHECKPOINT       = False # saves all best validated checkpoints in training process (may require a lot disk space) (False recommended)\n",
        "TRAIN_CLASSES               = \"mnist/mnist.names\"\n",
        "TRAIN_ANNOT_PATH            = \"mnist/mnist_train.txt\"\n",
        "TRAIN_LOGDIR                = \"log\"\n",
        "TRAIN_CHECKPOINTS_FOLDER    = \"checkpoints\"\n",
        "TRAIN_MODEL_NAME            = f\"{YOLO_TYPE}_custom\"\n",
        "TRAIN_LOAD_IMAGES_TO_RAM    = True # With True faster training, but need more RAM\n",
        "TRAIN_BATCH_SIZE            = 4\n",
        "TRAIN_INPUT_SIZE            = 416\n",
        "TRAIN_DATA_AUG              = True\n",
        "TRAIN_TRANSFER              = True\n",
        "TRAIN_FROM_CHECKPOINT       = False # \"checkpoints/yolov3_custom\"\n",
        "TRAIN_LR_INIT               = 1e-4\n",
        "TRAIN_LR_END                = 1e-6\n",
        "TRAIN_WARMUP_EPOCHS         = 2\n",
        "TRAIN_EPOCHS                = 100\n",
        "\n",
        "# TEST options\n",
        "TEST_ANNOT_PATH             = \"mnist/mnist_test.txt\"\n",
        "TEST_BATCH_SIZE             = 4\n",
        "TEST_INPUT_SIZE             = 416\n",
        "TEST_DATA_AUG               = False\n",
        "TEST_DECTECTED_IMAGE_PATH   = \"\"\n",
        "TEST_SCORE_THRESHOLD        = 0.3\n",
        "TEST_IOU_THRESHOLD          = 0.45\n",
        "\n",
        "if TRAIN_YOLO_TINY:\n",
        "    YOLO_STRIDES            = [16, 32]    \n",
        "    # YOLO_ANCHORS            = [[[23, 27],  [37, 58],   [81,  82]], # this line can be uncommented for default coco weights\n",
        "    YOLO_ANCHORS            = [[[10, 14],  [23, 27],   [37, 58]],\n",
        "                               [[81,  82], [135, 169], [344, 319]]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L8e42EPzMnXD",
        "outputId": "532e7515-bcd1-4331-f68c-c09a7d3acdf1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data-for-yolo-v3-kernel.zip to /content\n",
            " 96% 257M/267M [00:03<00:00, 87.9MB/s]\n",
            "100% 267M/267M [00:03<00:00, 76.1MB/s]\n",
            "Archive:  data-for-yolo-v3-kernel.zip\n",
            "  inflating: coco.names              \n",
            "  inflating: detections.gif          \n",
            "  inflating: dog.jpg                 \n",
            "  inflating: futur.ttf               \n",
            "  inflating: office.jpg              \n",
            "  inflating: yolov3.weights          \n"
          ]
        }
      ],
      "source": [
        "os.environ['KAGGLE_CONFIG_DIR'] = '/content/drive/MyDrive'\n",
        "!kaggle datasets download -d aruchomu/data-for-yolo-v3-kernel\n",
        "!unzip \\*.zip && rm *.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "diEwCPUvb6Ip"
      },
      "outputs": [],
      "source": [
        "!wget -P model_data https://pjreddie.com/media/files/yolov3.weights\n",
        "\n",
        "!wget -P model_data https://pjreddie.com/media/files/yolov3-tiny.weights\n",
        "\n",
        "!wget -P model_data https://github.com/AlexeyAB/darknet/releases/download/darknet_yolo_v3_optimal/yolov4.weights\n",
        "\n",
        "!wget -P model_data https://github.com/AlexeyAB/darknet/releases/download/darknet_yolo_v4_pre/yolov4-tiny.weights"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load The Yolo Model\n",
        "\n",
        "choose between yolo frameworks between; tf and trt\n",
        "\n",
        "\n",
        "and yolo types between;\n",
        "yolov3\n",
        "yolov3-tiny\n",
        "yolov4\n",
        "yolov4-tiny\n",
        "\n",
        "\n",
        " and decide if you need custom weights "
      ],
      "metadata": {
        "id": "CFx8ix85oymE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "KFGAOGG7gOEa"
      },
      "outputs": [],
      "source": [
        "def Load_Yolo_model():\n",
        "    gpus = tf.config.experimental.list_physical_devices('GPU')\n",
        "    if len(gpus) > 0:\n",
        "        print(f'GPUs {gpus}')\n",
        "        try: tf.config.experimental.set_memory_growth(gpus[0], True)\n",
        "        except RuntimeError: pass\n",
        "        \n",
        "    if YOLO_FRAMEWORK == \"tf\": # TensorFlow detection\n",
        "        if YOLO_TYPE == \"yolov4\":\n",
        "            Darknet_weights = YOLO_V4_TINY_WEIGHTS if TRAIN_YOLO_TINY else YOLO_V4_WEIGHTS\n",
        "        if YOLO_TYPE == \"yolov3\":\n",
        "            Darknet_weights = YOLO_V3_TINY_WEIGHTS if TRAIN_YOLO_TINY else YOLO_V3_WEIGHTS\n",
        "            \n",
        "        if YOLO_CUSTOM_WEIGHTS == False:\n",
        "            print(f\"Loading Darknet_weights from: {Darknet_weights}\")\n",
        "            yolo = Create_Yolo(input_size=YOLO_INPUT_SIZE, classes=YOLO_COCO_CLASSES)\n",
        "            load_yolo_weights(yolo, Darknet_weights) # use Darknet weights\n",
        "        else:\n",
        "            checkpoint = f\"./checkpoints/{TRAIN_MODEL_NAME}\"\n",
        "            if TRAIN_YOLO_TINY:\n",
        "                checkpoint += \"_Tiny\"\n",
        "            print(f\"Loading custom weights from: {checkpoint}\")\n",
        "            yolo = Create_Yolo(input_size=YOLO_INPUT_SIZE, classes=TRAIN_CLASSES)\n",
        "            yolo.load_weights(checkpoint)  # use custom weights\n",
        "        \n",
        "    elif YOLO_FRAMEWORK == \"trt\": # TensorRT detection\n",
        "        saved_model_loaded = tf.saved_model.load(YOLO_CUSTOM_WEIGHTS, tags=[tag_constants.SERVING])\n",
        "        signature_keys = list(saved_model_loaded.signatures.keys())\n",
        "        yolo = saved_model_loaded.signatures['serving_default']\n",
        "\n",
        "    return yolo\n",
        "\n",
        "\n",
        "# def Load_Yolo_model(yolo_framework, yolo_type, yolo_costom_weights):\n",
        "    \n",
        "#     physical_devices = tf.config.list_physical_devices('GPU')\n",
        "#     try:\n",
        "#         tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
        "#     except:\n",
        "#         pass\n",
        "\n",
        "#     if yolo_framework == \"tf\": # TensorFlow detection framework\n",
        "        \n",
        "#         if yolo_costom_weights:\n",
        "#             checkpoint = f\"./checkpoints/{yolo_type}_custom\"\n",
        "#             print(f\"Loading custom weights from: {checkpoint}\")\n",
        "#             yolo = Create_Yolo(input_size=YOLO_INPUT_SIZE, classes=TRAIN_CLASSES)\n",
        "#             yolo.load_weights(checkpoint)  # use custom weights\n",
        "#         else:\n",
        "#             Darknet_weights = f'model_data/{yolo_type}.weights'\n",
        "#             print(f\"Loading Darknet_weights from: {Darknet_weights}\")\n",
        "#             yolo = Create_Yolo(input_size=YOLO_INPUT_SIZE, classes=YOLO_COCO_CLASSES)\n",
        "#             load_yolo_weights(yolo, Darknet_weights) # use Darknet weights\n",
        "        \n",
        "#     elif yolo_framework == \"trt\": # TensorRT detection framework\n",
        "#         saved_model_loaded = tf.saved_model.load(yolo_costom_weights, tags=[tag_constants.SERVING])\n",
        "#         signature_keys = list(saved_model_loaded.signatures.keys())\n",
        "#         yolo = saved_model_loaded.signatures['serving_default']\n",
        "\n",
        "#     return yolo    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "Xq3lmswYkBwX"
      },
      "outputs": [],
      "source": [
        "def load_yolo_weights(model, weights_file):\n",
        "    tf.keras.backend.clear_session() # used to reset layer names\n",
        "    # load Darknet original weights to TensorFlow model\n",
        "    if YOLO_TYPE == \"yolov3\":\n",
        "        range1 = 75 if not TRAIN_YOLO_TINY else 13\n",
        "        range2 = [58, 66, 74] if not TRAIN_YOLO_TINY else [9, 12]\n",
        "    if YOLO_TYPE == \"yolov4\":\n",
        "        range1 = 110 if not TRAIN_YOLO_TINY else 21\n",
        "        range2 = [93, 101, 109] if not TRAIN_YOLO_TINY else [17, 20]\n",
        "    \n",
        "    with open(weights_file, 'rb') as wf:\n",
        "        major, minor, revision, seen, _ = np.fromfile(wf, dtype=np.int32, count=5)\n",
        "\n",
        "        j = 0\n",
        "        for i in range(range1):\n",
        "            conv_layer_name = 'conv2d' if i == 0 else f'conv2d_{i}'\n",
        "            bn_layer_name   = 'batch_normalization' if j == 0 else f'batch_normalization_{j}'\n",
        "            \n",
        "            conv_layer = model.get_layer(conv_layer_name)\n",
        "            \n",
        "            filters = conv_layer.filters\n",
        "            k_size = conv_layer.kernel_size[0]\n",
        "            in_dim = conv_layer.input_shape[-1]\n",
        "\n",
        "            if i not in range2:\n",
        "                # darknet weights: [beta, gamma, mean, variance]\n",
        "                bn_weights = np.fromfile(wf, dtype=np.float32, count=4 * filters)\n",
        "                # tf weights: [gamma, beta, mean, variance]\n",
        "                bn_weights = bn_weights.reshape((4, filters))[[1, 0, 2, 3]]\n",
        "                bn_layer = model.get_layer(bn_layer_name)\n",
        "                j += 1\n",
        "            else:\n",
        "                conv_bias = np.fromfile(wf, dtype=np.float32, count=filters)\n",
        "\n",
        "            # darknet shape (out_dim, in_dim, height, width)\n",
        "            conv_shape = (filters, in_dim, k_size, k_size)\n",
        "            # filters * in_dim * k_size * k_size\n",
        "            conv_count = np.product(conv_shape)    \n",
        "            conv_weights = np.fromfile(wf, dtype=np.float32, count=conv_count)\n",
        "            # tf shape (height, width, in_dim, out_dim)\n",
        "            conv_weights = conv_weights.reshape(conv_shape).transpose([2, 3, 1, 0])\n",
        "            # conv_weights = conv_weights.reshape(conv_shape[::-1])  # why this doesn't works?\n",
        "\n",
        "\n",
        "            if i not in range2:\n",
        "                conv_layer.set_weights([conv_weights])\n",
        "                bn_layer.set_weights(bn_weights)\n",
        "            else:\n",
        "                conv_layer.set_weights([conv_weights, conv_bias])\n",
        "\n",
        "        assert len(wf.read()) == 0, 'failed to read all data'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "TalwmXaWpZ1n"
      },
      "outputs": [],
      "source": [
        "def read_class_names(class_file_name):\n",
        "    names = {}\n",
        "    with open(class_file_name, 'r') as data:\n",
        "        for ID, name in enumerate(data):\n",
        "            names[ID] = name.strip('\\n')\n",
        "    return names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "joRbhoBSlKcw"
      },
      "outputs": [],
      "source": [
        "def Create_Yolo(input_size=416, channels=3, training=False, classes=YOLO_COCO_CLASSES):\n",
        "    NUM_CLASS = len(read_class_names(classes))\n",
        "    input_layer  = tf.keras.layers.Input([input_size, input_size, channels])\n",
        "\n",
        "    if TRAIN_YOLO_TINY:\n",
        "        if YOLO_TYPE == \"yolov4\":\n",
        "            conv_tensors = YOLOv4_tiny(input_layer, NUM_CLASS)\n",
        "        if YOLO_TYPE == \"yolov3\":\n",
        "            conv_tensors = YOLOv3_tiny(input_layer, NUM_CLASS)\n",
        "    else:\n",
        "        if YOLO_TYPE == \"yolov4\":\n",
        "            conv_tensors = YOLOv4(input_layer, NUM_CLASS)\n",
        "        if YOLO_TYPE == \"yolov3\":\n",
        "            conv_tensors = YOLOv3(input_layer, NUM_CLASS)\n",
        "\n",
        "    output_tensors = []\n",
        "    for i, conv_tensor in enumerate(conv_tensors):\n",
        "        pred_tensor = decode(conv_tensor, NUM_CLASS, i)\n",
        "        if training: output_tensors.append(conv_tensor)\n",
        "        output_tensors.append(pred_tensor)\n",
        "\n",
        "    Yolo = tf.keras.Model(input_layer, output_tensors)\n",
        "    return Yolo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "TOjuGYgwpyW9"
      },
      "outputs": [],
      "source": [
        "def upsample(input_layer):\n",
        "    return tf.image.resize(input_layer, (input_layer.shape[1] * 2, input_layer.shape[2] * 2), method='nearest')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "eQuEEydLpyUS"
      },
      "outputs": [],
      "source": [
        "def route_group(input_layer, groups, group_id):\n",
        "    convs = tf.split(input_layer, num_or_size_splits=groups, axis=-1)\n",
        "    return convs[group_id]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "5GcTAo49pwjm"
      },
      "outputs": [],
      "source": [
        "def residual_block(input_layer, input_channel, filter_num1, filter_num2, activate_type='leaky'):\n",
        "    short_cut = input_layer\n",
        "    conv = convolutional(input_layer, filters_shape=(1, 1, input_channel, filter_num1), activate_type=activate_type)\n",
        "    conv = convolutional(conv       , filters_shape=(3, 3, filter_num1,   filter_num2), activate_type=activate_type)\n",
        "\n",
        "    residual_output = short_cut + conv\n",
        "    return residual_output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "-VYN51cMprpZ"
      },
      "outputs": [],
      "source": [
        "def darknet53(input_data):\n",
        "    input_data = convolutional(input_data, (3, 3,  3,  32))\n",
        "    input_data = convolutional(input_data, (3, 3, 32,  64), downsample=True)\n",
        "\n",
        "    for i in range(1):\n",
        "        input_data = residual_block(input_data,  64,  32, 64)\n",
        "\n",
        "    input_data = convolutional(input_data, (3, 3,  64, 128), downsample=True)\n",
        "\n",
        "    for i in range(2):\n",
        "        input_data = residual_block(input_data, 128,  64, 128)\n",
        "\n",
        "    input_data = convolutional(input_data, (3, 3, 128, 256), downsample=True)\n",
        "\n",
        "    for i in range(8):\n",
        "        input_data = residual_block(input_data, 256, 128, 256)\n",
        "\n",
        "    route_1 = input_data\n",
        "    input_data = convolutional(input_data, (3, 3, 256, 512), downsample=True)\n",
        "\n",
        "    for i in range(8):\n",
        "        input_data = residual_block(input_data, 512, 256, 512)\n",
        "\n",
        "    route_2 = input_data\n",
        "    input_data = convolutional(input_data, (3, 3, 512, 1024), downsample=True)\n",
        "\n",
        "    for i in range(4):\n",
        "        input_data = residual_block(input_data, 1024, 512, 1024)\n",
        "\n",
        "    return route_1, route_2, input_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "5qSACC0RlhS8"
      },
      "outputs": [],
      "source": [
        "def YOLOv3(input_layer, NUM_CLASS):\n",
        "    # After the input layer enters the Darknet-53 network, we get three branches\n",
        "    route_1, route_2, conv = darknet53(input_layer)\n",
        "    # See the orange module (DBL) in the figure above, a total of 5 Subconvolution operation\n",
        "    conv = convolutional(conv, (1, 1, 1024,  512))\n",
        "    conv = convolutional(conv, (3, 3,  512, 1024))\n",
        "    conv = convolutional(conv, (1, 1, 1024,  512))\n",
        "    conv = convolutional(conv, (3, 3,  512, 1024))\n",
        "    conv = convolutional(conv, (1, 1, 1024,  512))\n",
        "    conv_lobj_branch = convolutional(conv, (3, 3, 512, 1024))\n",
        "    \n",
        "    # conv_lbbox is used to predict large-sized objects , Shape = [None, 13, 13, 255] \n",
        "    conv_lbbox = convolutional(conv_lobj_branch, (1, 1, 1024, 3*(NUM_CLASS + 5)), activate=False, bn=False)\n",
        "\n",
        "    conv = convolutional(conv, (1, 1,  512,  256))\n",
        "    # upsample here uses the nearest neighbor interpolation method, which has the advantage that the\n",
        "    # upsampling process does not need to learn, thereby reducing the network parameter  \n",
        "    conv = upsample(conv)\n",
        "\n",
        "    conv = tf.concat([conv, route_2], axis=-1)\n",
        "    conv = convolutional(conv, (1, 1, 768, 256))\n",
        "    conv = convolutional(conv, (3, 3, 256, 512))\n",
        "    conv = convolutional(conv, (1, 1, 512, 256))\n",
        "    conv = convolutional(conv, (3, 3, 256, 512))\n",
        "    conv = convolutional(conv, (1, 1, 512, 256))\n",
        "    conv_mobj_branch = convolutional(conv, (3, 3, 256, 512))\n",
        "\n",
        "    # conv_mbbox is used to predict medium-sized objects, shape = [None, 26, 26, 255]\n",
        "    conv_mbbox = convolutional(conv_mobj_branch, (1, 1, 512, 3*(NUM_CLASS + 5)), activate=False, bn=False)\n",
        "\n",
        "    conv = convolutional(conv, (1, 1, 256, 128))\n",
        "    conv = upsample(conv)\n",
        "\n",
        "    conv = tf.concat([conv, route_1], axis=-1)\n",
        "    conv = convolutional(conv, (1, 1, 384, 128))\n",
        "    conv = convolutional(conv, (3, 3, 128, 256))\n",
        "    conv = convolutional(conv, (1, 1, 256, 128))\n",
        "    conv = convolutional(conv, (3, 3, 128, 256))\n",
        "    conv = convolutional(conv, (1, 1, 256, 128))\n",
        "    conv_sobj_branch = convolutional(conv, (3, 3, 128, 256))\n",
        "    \n",
        "    # conv_sbbox is used to predict small size objects, shape = [None, 52, 52, 255]\n",
        "    conv_sbbox = convolutional(conv_sobj_branch, (1, 1, 256, 3*(NUM_CLASS +5)), activate=False, bn=False)\n",
        "        \n",
        "    return [conv_sbbox, conv_mbbox, conv_lbbox]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "H9o9hr2JnL5h"
      },
      "outputs": [],
      "source": [
        "def convolutional(input_layer, filters_shape, downsample=False, activate=True, bn=True, activate_type='leaky'):\n",
        "    if downsample:\n",
        "        input_layer = tf.keras.layers.ZeroPadding2D(((1, 0), (1, 0)))(input_layer)\n",
        "        padding = 'valid'\n",
        "        strides = 2\n",
        "    else:\n",
        "        strides = 1\n",
        "        padding = 'same'\n",
        "\n",
        "    conv = tf.keras.layers.Conv2D(filters=filters_shape[-1], kernel_size = filters_shape[0], strides=strides,\n",
        "                  padding=padding, use_bias=not bn, kernel_regularizer=tf.keras.regularizers.L2(0.0005),\n",
        "                  kernel_initializer=tf.random_normal_initializer(stddev=0.01),\n",
        "                  bias_initializer=tf.constant_initializer(0.))(input_layer)\n",
        "    if bn:\n",
        "        conv = tf.keras.layers.BatchNormalization()(conv)\n",
        "    if activate == True:\n",
        "        if activate_type == \"leaky\":\n",
        "            conv = tf.keras.layers.LeakyReLU(alpha=0.1)(conv)\n",
        "        elif activate_type == \"mish\":\n",
        "          conv = tf.math.softplus(conv)\n",
        "          conv = conv * tf.math.tanh(conv)\n",
        "\n",
        "    return conv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "1T8S6XSvqHoA"
      },
      "outputs": [],
      "source": [
        "STRIDES         = np.array(YOLO_STRIDES)\n",
        "ANCHORS         = (np.array(YOLO_ANCHORS).T/STRIDES).T\n",
        "\n",
        "def decode(conv_output, NUM_CLASS, i=0):\n",
        "    # where i = 0, 1 or 2 to correspond to the three grid scales  \n",
        "    conv_shape       = tf.shape(conv_output)\n",
        "    batch_size       = conv_shape[0]\n",
        "    output_size      = conv_shape[1]\n",
        "\n",
        "    conv_output = tf.reshape(conv_output, (batch_size, output_size, output_size, 3, 5 + NUM_CLASS))\n",
        "\n",
        "    #conv_raw_dxdy = conv_output[:, :, :, :, 0:2] # offset of center position     \n",
        "    #conv_raw_dwdh = conv_output[:, :, :, :, 2:4] # Prediction box length and width offset\n",
        "    #conv_raw_conf = conv_output[:, :, :, :, 4:5] # confidence of the prediction box\n",
        "    #conv_raw_prob = conv_output[:, :, :, :, 5: ] # category probability of the prediction box\n",
        "    conv_raw_dxdy, conv_raw_dwdh, conv_raw_conf, conv_raw_prob = tf.split(conv_output, (2, 2, 1, NUM_CLASS), axis=-1)\n",
        "\n",
        "    # next need Draw the grid. Where output_size is equal to 13, 26 or 52  \n",
        "    #y = tf.range(output_size, dtype=tf.int32)\n",
        "    #y = tf.expand_dims(y, -1)\n",
        "    #y = tf.tile(y, [1, output_size])\n",
        "    #x = tf.range(output_size,dtype=tf.int32)\n",
        "    #x = tf.expand_dims(x, 0)\n",
        "    #x = tf.tile(x, [output_size, 1])\n",
        "    xy_grid = tf.meshgrid(tf.range(output_size), tf.range(output_size))\n",
        "    xy_grid = tf.expand_dims(tf.stack(xy_grid, axis=-1), axis=2)  # [gx, gy, 1, 2]\n",
        "    xy_grid = tf.tile(tf.expand_dims(xy_grid, axis=0), [batch_size, 1, 1, 3, 1])\n",
        "    xy_grid = tf.cast(xy_grid, tf.float32)\n",
        "    \n",
        "    #xy_grid = tf.concat([x[:, :, tf.newaxis], y[:, :, tf.newaxis]], axis=-1)\n",
        "    #xy_grid = tf.tile(xy_grid[tf.newaxis, :, :, tf.newaxis, :], [batch_size, 1, 1, 3, 1])\n",
        "    #y_grid = tf.cast(xy_grid, tf.float32)\n",
        "\n",
        "    # Calculate the center position of the prediction box:\n",
        "    pred_xy = (tf.sigmoid(conv_raw_dxdy) + xy_grid) * STRIDES[i]\n",
        "    # Calculate the length and width of the prediction box:\n",
        "    pred_wh = (tf.exp(conv_raw_dwdh) * ANCHORS[i]) * STRIDES[i]\n",
        "\n",
        "    pred_xywh = tf.concat([pred_xy, pred_wh], axis=-1)\n",
        "    pred_conf = tf.sigmoid(conv_raw_conf) # object box calculates the predicted confidence\n",
        "    pred_prob = tf.sigmoid(conv_raw_prob) # calculating the predicted probability category box object\n",
        "\n",
        "    # calculating the predicted probability category box object\n",
        "    return tf.concat([pred_xywh, pred_conf, pred_prob], axis=-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "ZmSfcTTPqHfH"
      },
      "outputs": [],
      "source": [
        "def detect_image(Yolo, image_path, input_size=416, show=False, CLASSES=YOLO_COCO_CLASSES, score_threshold=0.3, iou_threshold=0.45, rectangle_colors=''):\n",
        "    original_image      = cv2.imread(image_path)\n",
        "    original_image      = cv2.cvtColor(original_image, cv2.COLOR_BGR2RGB)\n",
        "    original_image      = cv2.cvtColor(original_image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    image_data = image_preprocess(np.copy(original_image), [input_size, input_size])\n",
        "    image_data = image_data[np.newaxis, ...].astype(np.float32)\n",
        "\n",
        "    if YOLO_FRAMEWORK == \"tf\":\n",
        "        pred_bbox = Yolo.predict(image_data)\n",
        "    elif YOLO_FRAMEWORK == \"trt\":\n",
        "        batched_input = tf.constant(image_data)\n",
        "        result = Yolo(batched_input)\n",
        "        pred_bbox = []\n",
        "        for key, value in result.items():\n",
        "            value = value.numpy()\n",
        "            pred_bbox.append(value)\n",
        "        \n",
        "    pred_bbox = [tf.reshape(x, (-1, tf.shape(x)[-1])) for x in pred_bbox]\n",
        "    pred_bbox = tf.concat(pred_bbox, axis=0)\n",
        "    \n",
        "    bboxes = postprocess_boxes(pred_bbox, original_image, input_size, score_threshold)\n",
        "    bboxes = nms(bboxes, iou_threshold, method='nms')\n",
        "\n",
        "    image = draw_bbox(original_image, bboxes, CLASSES=CLASSES, rectangle_colors=rectangle_colors)\n",
        "    # CreateXMLfile(\"XML_Detections\", str(int(time.time())), original_image, bboxes, read_class_names(CLASSES))\n",
        "\n",
        "    output_path = f'{image_path[:-4]}_pred.jpg'\n",
        "    cv2.imwrite(output_path, image)\n",
        "    if show:\n",
        "        # Show the image\n",
        "        # cv2.imshow(\"predicted image\", image)\n",
        "        cv2_imshow(image)\n",
        "\n",
        "        # Load and hold the image\n",
        "        cv2.waitKey(0)\n",
        "        # To close the window after the required kill value was provided\n",
        "        cv2.destroyAllWindows()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "6R9ibdXB9Ymo"
      },
      "outputs": [],
      "source": [
        "def image_preprocess(image, target_size, gt_boxes=None):\n",
        "    ih, iw    = target_size\n",
        "    h,  w, _  = image.shape\n",
        "\n",
        "    scale = min(iw/w, ih/h)\n",
        "    nw, nh  = int(scale * w), int(scale * h)\n",
        "    image_resized = cv2.resize(image, (nw, nh))\n",
        "\n",
        "    image_paded = np.full(shape=[ih, iw, 3], fill_value=128.0)\n",
        "    dw, dh = (iw - nw) // 2, (ih-nh) // 2\n",
        "    image_paded[dh:nh+dh, dw:nw+dw, :] = image_resized\n",
        "    image_paded = image_paded / 255.\n",
        "\n",
        "    if gt_boxes is None:\n",
        "        return image_paded\n",
        "\n",
        "    else:\n",
        "        gt_boxes[:, [0, 2]] = gt_boxes[:, [0, 2]] * scale + dw\n",
        "        gt_boxes[:, [1, 3]] = gt_boxes[:, [1, 3]] * scale + dh\n",
        "        return image_paded, gt_boxes\n",
        "\n",
        "\n",
        "def draw_bbox(image, bboxes, CLASSES=YOLO_COCO_CLASSES, show_label=True, show_confidence = True, Text_colors=(255,255,0), rectangle_colors='', tracking=False):   \n",
        "    NUM_CLASS = read_class_names(CLASSES)\n",
        "    num_classes = len(NUM_CLASS)\n",
        "    image_h, image_w, _ = image.shape\n",
        "    hsv_tuples = [(1.0 * x / num_classes, 1., 1.) for x in range(num_classes)]\n",
        "    #print(\"hsv_tuples\", hsv_tuples)\n",
        "    colors = list(map(lambda x: colorsys.hsv_to_rgb(*x), hsv_tuples))\n",
        "    colors = list(map(lambda x: (int(x[0] * 255), int(x[1] * 255), int(x[2] * 255)), colors))\n",
        "\n",
        "    np.random.seed(0)\n",
        "    np.random.shuffle(colors)\n",
        "    np.random.seed(None)\n",
        "\n",
        "    for i, bbox in enumerate(bboxes):\n",
        "        coor = np.array(bbox[:4], dtype=np.int32)\n",
        "        score = bbox[4]\n",
        "        class_ind = int(bbox[5])\n",
        "        bbox_color = rectangle_colors if rectangle_colors != '' else colors[class_ind]\n",
        "        bbox_thick = int(0.6 * (image_h + image_w) / 1000)\n",
        "        if bbox_thick < 1: bbox_thick = 1\n",
        "        fontScale = 0.75 * bbox_thick\n",
        "        (x1, y1), (x2, y2) = (coor[0], coor[1]), (coor[2], coor[3])\n",
        "\n",
        "        # put object rectangle\n",
        "        cv2.rectangle(image, (x1, y1), (x2, y2), bbox_color, bbox_thick*2)\n",
        "\n",
        "        if show_label:\n",
        "            # get text label\n",
        "            score_str = \" {:.2f}\".format(score) if show_confidence else \"\"\n",
        "\n",
        "            if tracking: score_str = \" \"+str(score)\n",
        "\n",
        "            try:\n",
        "                label = \"{}\".format(NUM_CLASS[class_ind]) + score_str\n",
        "            except KeyError:\n",
        "                print(\"You received KeyError, this might be that you are trying to use yolo original weights\")\n",
        "                print(\"while using custom classes, if using custom model in configs.py set YOLO_CUSTOM_WEIGHTS = True\")\n",
        "\n",
        "            # get text size\n",
        "            (text_width, text_height), baseline = cv2.getTextSize(label, cv2.FONT_HERSHEY_COMPLEX_SMALL,\n",
        "                                                                  fontScale, thickness=bbox_thick)\n",
        "            # put filled text rectangle\n",
        "            cv2.rectangle(image, (x1, y1), (x1 + text_width, y1 - text_height - baseline), bbox_color, thickness=cv2.FILLED)\n",
        "\n",
        "            # put text above rectangle\n",
        "            cv2.putText(image, label, (x1, y1-4), cv2.FONT_HERSHEY_COMPLEX_SMALL,\n",
        "                        fontScale, Text_colors, bbox_thick, lineType=cv2.LINE_AA)\n",
        "\n",
        "    return image\n",
        "\n",
        "\n",
        "def bboxes_iou(boxes1, boxes2):\n",
        "    boxes1 = np.array(boxes1)\n",
        "    boxes2 = np.array(boxes2)\n",
        "\n",
        "    boxes1_area = (boxes1[..., 2] - boxes1[..., 0]) * (boxes1[..., 3] - boxes1[..., 1])\n",
        "    boxes2_area = (boxes2[..., 2] - boxes2[..., 0]) * (boxes2[..., 3] - boxes2[..., 1])\n",
        "\n",
        "    left_up       = np.maximum(boxes1[..., :2], boxes2[..., :2])\n",
        "    right_down    = np.minimum(boxes1[..., 2:], boxes2[..., 2:])\n",
        "\n",
        "    inter_section = np.maximum(right_down - left_up, 0.0)\n",
        "    inter_area    = inter_section[..., 0] * inter_section[..., 1]\n",
        "    union_area    = boxes1_area + boxes2_area - inter_area\n",
        "    ious          = np.maximum(1.0 * inter_area / union_area, np.finfo(np.float32).eps)\n",
        "\n",
        "    return ious\n",
        "\n",
        "\n",
        "def nms(bboxes, iou_threshold, sigma=0.3, method='nms'):\n",
        "    \"\"\"\n",
        "    :param bboxes: (xmin, ymin, xmax, ymax, score, class)\n",
        "    Note: soft-nms, https://arxiv.org/pdf/1704.04503.pdf\n",
        "          https://github.com/bharatsingh430/soft-nms\n",
        "    \"\"\"\n",
        "    classes_in_img = list(set(bboxes[:, 5]))\n",
        "    best_bboxes = []\n",
        "\n",
        "    for cls in classes_in_img:\n",
        "        cls_mask = (bboxes[:, 5] == cls)\n",
        "        cls_bboxes = bboxes[cls_mask]\n",
        "        # Process 1: Determine whether the number of bounding boxes is greater than 0 \n",
        "        while len(cls_bboxes) > 0:\n",
        "            # Process 2: Select the bounding box with the highest score according to socre order A\n",
        "            max_ind = np.argmax(cls_bboxes[:, 4])\n",
        "            best_bbox = cls_bboxes[max_ind]\n",
        "            best_bboxes.append(best_bbox)\n",
        "            cls_bboxes = np.concatenate([cls_bboxes[: max_ind], cls_bboxes[max_ind + 1:]])\n",
        "            # Process 3: Calculate this bounding box A and\n",
        "            # Remain all iou of the bounding box and remove those bounding boxes whose iou value is higher than the threshold \n",
        "            iou = bboxes_iou(best_bbox[np.newaxis, :4], cls_bboxes[:, :4])\n",
        "            weight = np.ones((len(iou),), dtype=np.float32)\n",
        "\n",
        "            assert method in ['nms', 'soft-nms']\n",
        "\n",
        "            if method == 'nms':\n",
        "                iou_mask = iou > iou_threshold\n",
        "                weight[iou_mask] = 0.0\n",
        "\n",
        "            if method == 'soft-nms':\n",
        "                weight = np.exp(-(1.0 * iou ** 2 / sigma))\n",
        "\n",
        "            cls_bboxes[:, 4] = cls_bboxes[:, 4] * weight\n",
        "            score_mask = cls_bboxes[:, 4] > 0.\n",
        "            cls_bboxes = cls_bboxes[score_mask]\n",
        "\n",
        "    return best_bboxes\n",
        "\n",
        "\n",
        "def postprocess_boxes(pred_bbox, original_image, input_size, score_threshold):\n",
        "    valid_scale=[0, np.inf]\n",
        "    pred_bbox = np.array(pred_bbox)\n",
        "\n",
        "    pred_xywh = pred_bbox[:, 0:4]\n",
        "    pred_conf = pred_bbox[:, 4]\n",
        "    pred_prob = pred_bbox[:, 5:]\n",
        "\n",
        "    # 1. (x, y, w, h) --> (xmin, ymin, xmax, ymax)\n",
        "    pred_coor = np.concatenate([pred_xywh[:, :2] - pred_xywh[:, 2:] * 0.5,\n",
        "                                pred_xywh[:, :2] + pred_xywh[:, 2:] * 0.5], axis=-1)\n",
        "    # 2. (xmin, ymin, xmax, ymax) -> (xmin_org, ymin_org, xmax_org, ymax_org)\n",
        "    org_h, org_w = original_image.shape[:2]\n",
        "    resize_ratio = min(input_size / org_w, input_size / org_h)\n",
        "\n",
        "    dw = (input_size - resize_ratio * org_w) / 2\n",
        "    dh = (input_size - resize_ratio * org_h) / 2\n",
        "\n",
        "    pred_coor[:, 0::2] = 1.0 * (pred_coor[:, 0::2] - dw) / resize_ratio\n",
        "    pred_coor[:, 1::2] = 1.0 * (pred_coor[:, 1::2] - dh) / resize_ratio\n",
        "\n",
        "    # 3. clip some boxes those are out of range\n",
        "    pred_coor = np.concatenate([np.maximum(pred_coor[:, :2], [0, 0]),\n",
        "                                np.minimum(pred_coor[:, 2:], [org_w - 1, org_h - 1])], axis=-1)\n",
        "    invalid_mask = np.logical_or((pred_coor[:, 0] > pred_coor[:, 2]), (pred_coor[:, 1] > pred_coor[:, 3]))\n",
        "    pred_coor[invalid_mask] = 0\n",
        "\n",
        "    # 4. discard some invalid boxes\n",
        "    bboxes_scale = np.sqrt(np.multiply.reduce(pred_coor[:, 2:4] - pred_coor[:, 0:2], axis=-1))\n",
        "    scale_mask = np.logical_and((valid_scale[0] < bboxes_scale), (bboxes_scale < valid_scale[1]))\n",
        "\n",
        "    # 5. discard boxes with low scores\n",
        "    classes = np.argmax(pred_prob, axis=-1)\n",
        "    scores = pred_conf * pred_prob[np.arange(len(pred_coor)), classes]\n",
        "    score_mask = scores > score_threshold\n",
        "    mask = np.logical_and(scale_mask, score_mask)\n",
        "    coors, scores, classes = pred_coor[mask], scores[mask], classes[mask]\n",
        "\n",
        "    return np.concatenate([coors, scores[:, np.newaxis], classes[:, np.newaxis]], axis=-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PZ982tWdfnZw"
      },
      "outputs": [],
      "source": [
        "yolo = Load_Yolo_model()\n",
        "image_path = '/content/dog.jpg'\n",
        "image_path = '/content/office.jpg'\n",
        "\n",
        "\n",
        "detect_image(yolo, image_path, input_size=YOLO_INPUT_SIZE, show=True, rectangle_colors=(255,0,0))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "PtUUBorIxocK"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "YOLO_v3_ObjectDetection_TensorFlow_4.ipynb",
      "provenance": [],
      "mount_file_id": "1d_ttY-LcvytmmipO7iRzAYwGFHXQvCMj",
      "authorship_tag": "ABX9TyMv6/BNNGIr2k3QOTaqfsNr",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}