{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "YOLO_v3_ObjectDetection_TensorFlow_4.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1d_ttY-LcvytmmipO7iRzAYwGFHXQvCMj",
      "authorship_tag": "ABX9TyNQPXFdcCEiPildtw6SDmQK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mralamdari/CV-Yolo/blob/main/YOLO_v3_ObjectDetection_TensorFlow_4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PIUHRF9dD8JW"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import PIL\n",
        "import struct # used to convert native Python data types such as strings and numbers into a string of bytes and vice versa\n",
        "import scipy.io\n",
        "import scipy.misc\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.layers.merge import add, concatenate"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ['KAGGLE_CONFIG_DIR'] = '/content/drive/MyDrive'\n",
        "!kaggle datasets download -d aruchomu/data-for-yolo-v3-kernel\n",
        "!unzip \\*.zip && rm *.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L8e42EPzMnXD",
        "outputId": "60445046-6028-4b98-e4aa-83d1ddd13960"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data-for-yolo-v3-kernel.zip to /content\n",
            " 96% 257M/267M [00:09<00:00, 24.8MB/s]\n",
            "100% 267M/267M [00:09<00:00, 29.0MB/s]\n",
            "Archive:  data-for-yolo-v3-kernel.zip\n",
            "  inflating: coco.names              \n",
            "  inflating: detections.gif          \n",
            "  inflating: dog.jpg                 \n",
            "  inflating: futur.ttf               \n",
            "  inflating: office.jpg              \n",
            "  inflating: yolov3.weights          \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Weights_Reader:\n",
        "\n",
        "\n",
        "  def __init__(self, filename):\n",
        "\n",
        "    with open(filename, 'rb') as w_file:\n",
        "      major, = struct.unpack('i', w_file.read(4))\n",
        "      minor, = struct.unpack('i', w_file.read(4))\n",
        "      revision, = struct.unpack('i', w_file.read(4))\n",
        "\n",
        "      if (major*10 + minor) >= 2 and major < 1000 and minor < 1000:\n",
        "        w_file.read(8)\n",
        "      else:\n",
        "        w_file.read(4)\n",
        "      \n",
        "      transpose = (major>1000) or (minor>1000)\n",
        "      binary_weights = w_file.read()\n",
        "      \n",
        "    self.offset = 0\n",
        "    self.all_weights = np.frombuffer(binary_weights, dtype='float32')\n",
        "\n",
        "  def byte_reader(self, size):\n",
        "    self.offset +=  size\n",
        "    return self.all_weights[self.offset - size: self.offset]\n",
        "\n",
        "  \n",
        "  def load_weights(self, model):\n",
        "\n",
        "    for i in range(106): # 53*2 = 106 layers in total\n",
        "      try: # if it is a Convolutional Layer\n",
        "        conv_layer = model.get_layer(f'conv_{i}')\n",
        "        print(f'Loading weights of Convolution Layer {i}')\n",
        "\n",
        "        if i not in [81, 93, 105]: #if it is not a Detection Layer (82, 94, 106)\n",
        "         \n",
        "          norm_layer = model.get_layer(f'bnorm_{i}')\n",
        "          size = np.prod(norm_layer.get_weights()[0].shape) \n",
        "\n",
        "          bias = self.byte_reader(size)\n",
        "          scale = self.byte_reader(size)\n",
        "          mean = self.byte_reader(size)\n",
        "          variance = self.byte_reader(size)\n",
        "\n",
        "          weights = norm_layer.set_weights([scale, bias, mean, variance])\n",
        "\n",
        "        if len(conv_layer.get_weights()) > 1:\n",
        "          bias   = self.byte_reader(np.prod(conv_layer.get_weights()[1].shape))\n",
        "          kernel = self.byte_reader(np.prod(conv_layer.get_weights()[0].shape))\n",
        "          kernel = kernel.reshape(list(reversed(conv_layer.get_weights()[0].shape)))\n",
        "          kernel = kernel.transpose([2, 3, 1, 0])\n",
        "          conv_layer.set_weights([kernel, bias])\n",
        "        else:\n",
        "          kernel = self.byte_reader(np.prod(conv_layer.get_weights()[0].shape))\n",
        "          kernel = kernel.reshape(list(reversed(conv_layer.get_weights()[0].shape)))\n",
        "          kernel = kernel.transpose([2, 3, 1, 0])\n",
        "          conv_layer.set_weights([kernel])\n",
        "\n",
        "      except ValueError:\n",
        "        print(f\"Layer {i} is Not Convolution Layer\")\n",
        "\n",
        "        \n",
        "  def reset(self):\n",
        "    self.offset = 0   "
      ],
      "metadata": {
        "id": "FGzyHJKlSC3C"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def convolutional_bloack(inputs, convolutions, skip=True):\n",
        "\n",
        "  X = inputs\n",
        "  count = 0\n",
        "  conv_layers_count = len(convolutions)\n",
        "\n",
        "  for conv_layer in convolutions:\n",
        "    if count == conv_layers_count-2 and skip:\n",
        "      skip_connection = X\n",
        "    \n",
        "    count += 1\n",
        "    if convolutions['stride'] > 1:\n",
        "      X = tf.keras.layers.ZeroPadding2d(((1, 0), (1, 0)))(X) # peculiar padding as darknet prefers left and top\n",
        "    \n",
        "    X = tf.keras.layers.Conv2D(filters = convolutional['filters'],\n",
        "                               kernel  = convolutional['kernel'],\n",
        "                               strides = convolutional['stride'],\n",
        "                               padding = 'valid' if convolutional['stride']>1 else 'same',\n",
        "                               use_bias= False if convolutional['bnorm'] else True,\n",
        "                               name = f'conv_{convolutional['layer_idx']}')(X)\n",
        "  \n",
        "    if convolutional['bnorm']:\n",
        "      X = tf.keras.layers.BatchNormalization(epsilon = 0.001, name=f\"batch_{convolutional['layer_idx']}\")(X)\n",
        "    \n",
        "    if convolutional['leaky']:\n",
        "      X = tf.keras.layers.LeakyReLU(alpha=0.1, name=\"leaky_{convolutional['layer_idx']}\")(X)\n",
        "    \n",
        "    return add([skip_connection, X]) if skip else X"
      ],
      "metadata": {
        "id": "ty0mOdbyulCG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "4IsgWrqfQGhl"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}