{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "YOLO_v3_ObjectDetection_TensorFlow.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1xRxAg9QZNUr77hH4X7ZCBpIWho-PqwTo",
      "authorship_tag": "ABX9TyN7ZOUV+Uzx7CMdwD2A1lLT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mralamdari/CV-Yolo/blob/main/YOLO_v3_ObjectDetection_TensorFlow.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import PIL\n",
        "import cv2\n",
        "import numpy as pd\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from seaborn import color_palette\n",
        "from IPython.display import display"
      ],
      "metadata": {
        "id": "UO0Jt4fiByMJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rETg2Ib5bDfe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "954f5dc8-ef45-43a0-db37-ea69730d7616"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data-for-yolo-v3-kernel.zip to /content\n",
            " 99% 265M/267M [00:04<00:00, 96.9MB/s]\n",
            "100% 267M/267M [00:04<00:00, 64.7MB/s]\n",
            "Archive:  data-for-yolo-v3-kernel.zip\n",
            "  inflating: coco.names              \n",
            "  inflating: detections.gif          \n",
            "  inflating: dog.jpg                 \n",
            "  inflating: futur.ttf               \n",
            "  inflating: office.jpg              \n",
            "  inflating: yolov3.weights          \n"
          ]
        }
      ],
      "source": [
        "os.environ['KAGGLE_CONFIG_DIR'] = '/content/drive/MyDrive'\n",
        "!kaggle datasets download -d aruchomu/data-for-yolo-v3-kernel\n",
        "!unzip \\*.zip && rm *.zip"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "_BATCH_NORM_DECAY = 0.9\n",
        "_BATCH_NORM_EPSILON = 1e-5\n",
        "_LEAKY_RELU = 0.1\n",
        "_ANCHORS = [(10, 13), (16, 30), (33, 23),\n",
        "            (30, 61), (62, 45), (59, 119),\n",
        "            (116, 90), (156, 198), (373, 326)]\n",
        "\n",
        "_MODEL_SIZE = (416, 416)"
      ],
      "metadata": {
        "id": "7LdiD_zyDFbv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def batch_norm(inputs, training, data_format):\n",
        "    return tf.layers.batch_normalization(inputs = inputs, \n",
        "                                       axis=1 if data_format == 'channels_first' else 3,\n",
        "                                       momentum=_BATCH_NORM_DECAY,\n",
        "                                       epsilon=_BATCH_NORM_EPSILON,\n",
        "                                       scale=True,\n",
        "                                       training=training)"
      ],
      "metadata": {
        "id": "9-Tw-43rECdB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def fixed_padding(inputs, kernel_size, data_format):\n",
        "    pad_total = kernel_size - 1\n",
        "    pad_beg = pad_total // 2\n",
        "    pad_end = pad_total - pad_beg\n",
        "\n",
        "    if data_format == 'channels_first':\n",
        "      padded_inputs = tf.pad(inputs, [[0, 0], [0, 0],\n",
        "                                      [pad_beg, pad_end],\n",
        "                                       [pad_beg, pad_end]])  \n",
        "    else:\n",
        "      padded_inputs = tf.pad(inputs, [[0, 0], [pad_beg, pad_end],\n",
        "                                       [pad_beg, pad_end], [0, 0]])\n",
        "    return padded_inputs"
      ],
      "metadata": {
        "id": "vK5MYMBbGCLT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def conv2d_fixed_padding(inputs, filters, kernel_size, data_format, strides=1):\n",
        "    if strides > 1:\n",
        "      inputs = fixed_padding(inputs, kernel_size, data_format)\n",
        "      return tf.layers.conv2d(inputs=inputs, \n",
        "                              filters=filters,\n",
        "                              kernel_size=kernel_size,\n",
        "                              strides=strides,\n",
        "                              padding=('SAME' if strides == 1 else 'VALID'),\n",
        "                              use_bias=False,\n",
        "                              data_format=data_format)"
      ],
      "metadata": {
        "id": "M0ID-k0QGIGZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Feature extraction: Darknet-53\n"
      ],
      "metadata": {
        "id": "7dx4Y501IbeK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def darknet53_residual_block(inputs, filters, training, data_format, strides=1):\n",
        "  shortcut = inputs\n",
        "  inputs = conv2d_fixed_padding(inputs,\n",
        "                               filters=filters,\n",
        "                               kernel_size=1,\n",
        "                               strides=strides,\n",
        "                               data_format=data_format)\n",
        "  \n",
        "  inputs = batch_norm(inputs,\n",
        "                      training=training, \n",
        "                      data_format=data_format)\n",
        "  \n",
        "  inputs = tf.nn.leaky_relu(inputs, alpha=_LEAKY_RELU)\n",
        "\n",
        "  inputs = conv2d_fixed_padding(inputs,\n",
        "                                filters=2 * filters,\n",
        "                                kernel_size=3,\n",
        "                                strids=strides,\n",
        "                                data_format=data_format)\n",
        "  \n",
        "  inputs = batch_norm(inputs, \n",
        "                      training=training, \n",
        "                      data_format=data_format)\n",
        "  \n",
        "  inputs = tf.nn.leaky_relu(inputs, alpha=_LEAKY_RELU)\n",
        "\n",
        "  inputs += shortcut\n",
        "\n",
        "  return inputs"
      ],
      "metadata": {
        "id": "dGY5WMzPIT71"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def darknet53(inputs, training, data_format):\n",
        "  inputs = conv2d_fixed_padding(inputs,\n",
        "                                filters=32,\n",
        "                                kernel_size=3,\n",
        "                                data_format=data_format)\n",
        "  \n",
        "  inputs = batch_norm(inputs,\n",
        "                      training=training,\n",
        "                      data_format=data_format)\n",
        "  \n",
        "  inputs = tf.nn.leaky_relu(inputs, alpha=_LEAKY_RELU)\n",
        "\n",
        "  inputs = conv2d_fixed_padding(inputs,\n",
        "                                filters=64, \n",
        "                                kernel_size=3,\n",
        "                                strides=2,\n",
        "                                data_format=data_format)\n",
        "  \n",
        "  inputs = batch_norm(inputs, \n",
        "                      training=training,\n",
        "                      data_format=data_format)\n",
        "  \n",
        "  inputs = tf.nn.leaky_relu(inputs, alpha=_LEAKY_RELU)\n",
        "\n",
        "  inputs = darknet53_residual_block(inputs, \n",
        "                                    filters=32,\n",
        "                                    training=training,\n",
        "                                    data_format=data_format)\n",
        "  \n",
        "  inputs = conv2d_fixed_padding(inputs,\n",
        "                                filters=128,\n",
        "                                kernel_size=3, \n",
        "                                strides=2,\n",
        "                                data_format=data_format)\n",
        "  \n",
        "  inputs = batch_norm(inputs, \n",
        "                      training=training,\n",
        "                      data_format=data_format)\n",
        "\n",
        "  inputs = tf.nn.leaky_relu(inputs, alpha=_LEAKY_RELU)\n",
        "\n",
        "  for i in range(2):\n",
        "    inputs = darknet53_residual_block(inputs,\n",
        "                                      filters=64,\n",
        "                                      training=training,\n",
        "                                      data_format=data_format)\n",
        "    \n",
        "    inputs = conv2d_fixed_padding(inputs,\n",
        "                                  filters=256,\n",
        "                                  kernel_size=3,\n",
        "                                  strides=2,\n",
        "                                  data_format=data_format)\n",
        "    \n",
        "    inputs = batch_norm(inputs,\n",
        "                        training=training,\n",
        "                        data_format=data_format)\n",
        "    \n",
        "    inputs = tf.nn.leaky_relu(inputs, alpha=_LEAKY_RELU)\n",
        "\n",
        "  for i in range(8):\n",
        "    inputs = darknet53_residual_block(inputs, \n",
        "                                      frilters=128,\n",
        "                                      training=training,\n",
        "                                      data_format=data_format)\n",
        "    route1 = inputs\n",
        "\n",
        "    inputs = conv2d_fixed_padding(inputs,\n",
        "                                  filters=512,\n",
        "                                  kernel_size=3,\n",
        "                                  strides=2,\n",
        "                                  data_format=data_format)\n",
        "    \n",
        "    inputs = batch_norm(inputs,\n",
        "                        training=training,\n",
        "                        data_format=data_format)\n",
        "    \n",
        "    inputs = tf.nn.leaky_relu(inputs, alpha=_LEAKY_RELU)\n",
        "\n",
        "  for i in range(8):\n",
        "    inputs = darknet53_residual_block(inputs,\n",
        "                                      filters=256,\n",
        "                                      training=training,\n",
        "                                      pad_formet=data_format)\n",
        "    \n",
        "    route2=inputs\n",
        "\n",
        "    inputs = conv2d_fixed_padding(inputs,\n",
        "                                  filters=1024,\n",
        "                                  kernel_size=3, \n",
        "                                  strides=2,\n",
        "                                  data_format=data_format)\n",
        "    \n",
        "    inputs = batch_norm(inputs,\n",
        "                        training=training,\n",
        "                        data_format=data_format)\n",
        "    \n",
        "    inputs = tf.nn.leaky_relu(inputs, alpha=_LEAKY_RELU)\n",
        "\n",
        "  for i in range(4):\n",
        "    inputs = darknet53_residual_block(inputs, \n",
        "                                      filters=512,\n",
        "                                      training=training,\n",
        "                                      data_format=data_format)\n",
        " \n",
        "  return route1, route2, inputs"
      ],
      "metadata": {
        "id": "UkMiY5G0KKil"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Convolution layers\n"
      ],
      "metadata": {
        "id": "VIPF6nuyaLeg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def yolo_convolution_block(inputs,  filters, training, data_format):\n",
        "  inputs = conv2d_fixed_padding(inputs,\n",
        "                                filters=filters,\n",
        "                                kernel_size=1,\n",
        "                                data_format=data_format)\n",
        "  \n",
        "  inputs = batch_norm(inputs,\n",
        "                      training=training,\n",
        "                      data_format=data_format)\n",
        "  \n",
        "  inputs = tf.nn.leaky_relu(inputs, alpha=_LEAKY_RELU)\n",
        "\n",
        "  inputs = conv2d_fixed_padding(inputs,\n",
        "                                filters=2*filters,\n",
        "                                kernel_size=3,\n",
        "                                data_format=data_format)\n",
        "  \n",
        "  inputs = batch_norm(inputs, \n",
        "                      training=training,\n",
        "                      data_format=data_format)\n",
        "  \n",
        "  inputs = tf.nn.leaky_relu(inputs, alpha=_LEAKY_RELU)\n",
        "\n",
        "  inputs = conv2d_fixed_padding(inputs,\n",
        "                                filters=filters,\n",
        "                                kernel_size=1, \n",
        "                                data_format=data_format)\n",
        "  \n",
        "  inputs = batch_norm(inputs, \n",
        "                      training=training,\n",
        "                      data_format=data_format)\n",
        "  \n",
        "  inputs = tf.nn.leaky_relu(inputs, alpha=_LEAKY_RELU)\n",
        "\n",
        "  inputs = conv2d_fixed_padding(inputs,\n",
        "                                filters=2 * filters,\n",
        "                                kernel_size=3,\n",
        "                                data_format=data_format)\n",
        "  \n",
        "  inputs = batch_norm(inputs, \n",
        "                      training=training,\n",
        "                      data_format=data_format)\n",
        "  \n",
        "  inputs = tf.nn.leakt_relu(inputs, alpha=_LEAKY_RELU)\n",
        "\n",
        "  inputs = batch_norm(inputs,\n",
        "                      training=training,\n",
        "                      data_format=data_format)\n",
        "  \n",
        "  ipnuts = tf.nn.leaky_relu(inputs, alpha=_LEAKY_RELU)\n",
        "  \n",
        "  route = inputs\n",
        "\n",
        "  inputs = conv2d_fixed_padding(inputs,\n",
        "                                filters=2 * filters,\n",
        "                                kernel_size=3,\n",
        "                                data_format=data_format)\n",
        "  inputs = batch_norm(inputs,\n",
        "                      training=training,\n",
        "                      data_format=data_format)\n",
        "  \n",
        "  inputs = tf.nn.leaky_relu(inputs, alpha=_LEAKY_RELU)\n",
        "\n",
        "  return route, inputs"
      ],
      "metadata": {
        "id": "u0C5IG6jZMHO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Detection layers\n"
      ],
      "metadata": {
        "id": "H-zOe8gEfZiW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def yolo_layer(inputs, n_classes, anchors, img_size, data_format):\n",
        "  n_anchors = len(anchors)\n",
        "  inputs = tf.layers.conv2d(inputs,\n",
        "                            filters=n_anchors * (5 + n_classes),\n",
        "                            kernel_size=1,\n",
        "                            strides=1,\n",
        "                            use_bias=True,\n",
        "                            data_format=data_format)\n",
        "  \n",
        "  shape = inputs.get_shape().as_list()\n",
        "  grid_shape = shape[2: 4] if data_formate == 'channels_fist' else shape[1: 3]\n",
        "  \n",
        "  if data_foramt == 'channels_first':\n",
        "    inputs = tf.transpose(inputs, [0, 2, 3, 1])\n",
        "  inputs = tf.reshape(inputs, [-1, n_anchors*grid_shape[0]*grid_shape[1], 5+n_classes])\n",
        "\n",
        "  strides = (img_size[0] // grid_shape[0], img_size[1]//grid_shape[1])\n",
        "\n",
        "  box_centers, box_shapes, confidence, classes = tf.split(inputs, [2,2,1,n_classes], axis=-1)\n",
        "\n",
        "  x = tf.range(grid_shape[0], dtype=tf.float32)\n",
        "  y = tf.range(grid_shape[1], dtype=tf.float32)\n",
        "  x_offset, y_offset = tf.meshgrid(x, y)\n",
        "  x_offset = tf.reshape(x_offset, (-1, 1))\n",
        "  y_offset = tf.reshape(y_offset, (-1, 1))\n",
        "  x_y_offset = tf.concate([x_offset, y_offset], axis=-1)\n",
        "  x_y_offset = tf.tile(x_y_offset, [1, n_anchors])\n",
        "  x_y_offset = tf.reshape(x_y_offset, [1, -1, 2])\n",
        "  box_centers = tf.nn.sigmoid(box_centors)\n",
        "  box_centers = (box_centers + x_y_offset) * strides\n",
        "\n",
        "  anchors = tf.tile(anchors, [grd_shape[0]*grid_shape[1], 1])\n",
        "  box_shapes = tf.exp(box_shapes) * tf.to_float(anchors)\n",
        "  confidence = tf.nn.sigmoid(classes)\n",
        "  inputs = tf.concat([box_centors, box_shapes, confidence, classes], axis=-1)\n",
        "  return inputs"
      ],
      "metadata": {
        "id": "4E87xE_ahch5"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Upsample layer"
      ],
      "metadata": {
        "id": "ztM3PP3aic1o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def upsample(inputs, out_shape, data_format):\n",
        "  if data_format == 'channels_first':\n",
        "    inputs = tf.transpose(inputs, [0, 2, 3, 1])\n",
        "    new_height = out_shape[3]\n",
        "    new_width = out_shape[2]\n",
        "  else:\n",
        "    new_height = out_shape[2]\n",
        "    new_width = out_shape[1]\n",
        "  \n",
        "  inputs = tf.image.resize_nearest_neighbor(inputs, (new_height, new_width))\n",
        "\n",
        "  if data_format == 'channels_first':\n",
        "    inputs = tf.transpose(inputs, [0, 3, 1, 2])\n",
        "  \n",
        "  return inputs"
      ],
      "metadata": {
        "id": "7rLiWM1XiYXU"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Non-max suppression"
      ],
      "metadata": {
        "id": "Cx_EsXwqturx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_boxes(inputs):\n",
        "  center_x, center_y, width, height, confidence, classes = tf.split(inputs, [1,1,1,1,1,-1], axis=-1)\n",
        "  top_left_x = center_x - width / 2\n",
        "  top_left_y = center_y - height / 2\n",
        "  bottom_right_x = cneter_x + width / 2\n",
        "  bottom_right_y = center_y + height / 2\n",
        "\n",
        "  boxes = tf.concat([top_left_x, top_left_y, bottom_right_x, bottom_right_y, confidence, classes], axis=-1)"
      ],
      "metadata": {
        "id": "VRmSnX8IjwLs"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "JHnEJSNLtyoM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}