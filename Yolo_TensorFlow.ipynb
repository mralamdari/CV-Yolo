{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Yolo_TensorFlow.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNOHf2tYzyBTeywI6QS4f5n",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mralamdari/CV-Yolo/blob/main/Yolo_TensorFlow.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W0qlttAELlC9"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import PIL\n",
        "import struct # used to convert native Python data types such as strings and numbers into a string of bytes and vice versa\n",
        "import colorsys\n",
        "import scipy.io\n",
        "import scipy.misc\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab.patches import cv2_imshow\n",
        "from tensorflow.python.saved_model import tag_constants"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ['KAGGLE_CONFIG_DIR'] = '/content/drive/MyDrive'\n",
        "!kaggle datasets download -d aruchomu/data-for-yolo-v3-kernel\n",
        "!unzip \\*.zip && rm *.zip"
      ],
      "metadata": {
        "id": "hStuvGiBMSja"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -P model_data https://pjreddie.com/media/files/yolov3.weights\n",
        "\n",
        "!wget -P model_data https://pjreddie.com/media/files/yolov3-tiny.weights\n",
        "\n",
        "!wget -P model_data https://github.com/AlexeyAB/darknet/releases/download/darknet_yolo_v3_optimal/yolov4.weights\n",
        "\n",
        "!wget -P model_data https://github.com/AlexeyAB/darknet/releases/download/darknet_yolo_v4_pre/yolov4-tiny.weights"
      ],
      "metadata": {
        "id": "tMGQsu3aMShB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load The Yolo Model\n",
        "\n",
        "choose between yolo frameworks between; tf and trt\n",
        "\n",
        "\n",
        "and yolo types between;\n",
        "yolov3\n",
        "yolov3-tiny\n",
        "yolov4\n",
        "yolov4-tiny\n",
        "\n",
        "\n",
        " and decide if you need custom weights "
      ],
      "metadata": {
        "id": "kTSIBwjdMX5v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_yolo_model(yolo_framework, yolo_type, yolo_costom_weights, input_size, input_classes, class_names):\n",
        "    \n",
        "    physical_devices = tf.config.list_physical_devices('GPU')\n",
        "    try:\n",
        "        tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "    if yolo_framework == \"tf\": # TensorFlow detection framework\n",
        "        \n",
        "        if yolo_costom_weights:\n",
        "            checkpoint = f\"./checkpoints/{yolo_type}_custom\"\n",
        "            print(f\"Loading custom weights from: {checkpoint}\")\n",
        "            yolo = create_yolo_model(yolo_type, class_names, input_size=input_size, classes=input_classes)\n",
        "            yolo.load_weights(checkpoint)\n",
        "        else:\n",
        "            Darknet_weights = f'model_data/{yolo_type}.weights'\n",
        "            print(f\"Loading Darknet_weights from: {Darknet_weights}\")\n",
        "            yolo = create_yolo_model(yolo_type, class_names, input_size=input_size, classes=input_classes)\n",
        "            load_yolo_weights(yolo, Darknet_weights) # use Darknet weights\n",
        "        \n",
        "    elif yolo_framework == \"trt\": # TensorRT detection framework\n",
        "        saved_model_loaded = tf.saved_model.load(yolo_costom_weights, tags=[tag_constants.SERVING])\n",
        "        signature_keys = list(saved_model_loaded.signatures.keys())\n",
        "        yolo = saved_model_loaded.signatures['serving_default']\n",
        "\n",
        "    return yolo "
      ],
      "metadata": {
        "id": "sG_4jEUNMZNh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create Yolo Model\n"
      ],
      "metadata": {
        "id": "3Boa4t2WNSS7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_yolo_model(yolo_type, class_names, classes, input_size=416, channels=3, training=False):\n",
        "    \n",
        "    num_classes = len(class_names)\n",
        "    input_layer  = tf.keras.layers.Input([input_size, input_size, channels])\n",
        "\n",
        "    if yolo_type[-4:] == 'tiny':\n",
        "        if yolo_type == \"yolov4\":\n",
        "            convolutional_layers = YOLOv4_tiny(input_layer, num_classes)\n",
        "        if yolo_type == \"yolov3\":\n",
        "            convolutional_layers = YOLOv3_tiny(input_layer, num_classes)\n",
        "    else:\n",
        "        if yolo_type == \"yolov4\":\n",
        "            convolutional_layers = YOLOv4(input_layer, num_classes)\n",
        "        if yolo_type == \"yolov3\":\n",
        "            convolutional_layers = YOLOv3(input_layer, num_classes)\n",
        "\n",
        "    output_tensors = []\n",
        "    for i, conv_layer in enumerate(convolutional_layers):\n",
        "        pred_tensor = decode(conv_layer, num_classes, i)\n",
        "        \n",
        "        if training: \n",
        "          output_tensors.append(conv_layer)\n",
        "        \n",
        "        output_tensors.append(pred_tensor)\n",
        "\n",
        "    Yolo = tf.keras.Model(input_layer, output_tensors)\n",
        "\n",
        "    return Yolo"
      ],
      "metadata": {
        "id": "RR6_TxpcNVCp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Up Sample\n",
        "\n",
        "resize the batch of images' height and weidth\n",
        "\n",
        "    # shape=(None, 13, 13, 256)    ===>   (None, 26, 26, 256)\n",
        "    # shape=(None, 26, 26, 128)    ===>   (None, 56, 56, 128)"
      ],
      "metadata": {
        "id": "xV-iOWU0NXgp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def upsample(input_layer):\n",
        "    return tf.keras.layers.UpSampling2D(2)(input_layer)\n",
        "    # return tf.image.resize(input_layer, (input_layer.shape[1] * 2, input_layer.shape[2] * 2), method='nearest')"
      ],
      "metadata": {
        "id": "DTnP9K6zNXv2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Convolutional Layer"
      ],
      "metadata": {
        "id": "YMFUMkkxNz33"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def convolutional(input_layer, filters_shape, downsample=False, activate=True, bn=True, activate_type='leaky'):\n",
        "    if downsample:\n",
        "        input_layer = tf.keras.layers.ZeroPadding2D(((1, 0), (1, 0)))(input_layer)\n",
        "        padding = 'valid'\n",
        "        strides = 2\n",
        "    else:\n",
        "        strides = 1\n",
        "        padding = 'same'\n",
        "\n",
        "    conv = tf.keras.layers.Conv2d(filters=filters_shape[-1],\n",
        "                                  kernel_size=filters_shape[0],\n",
        "                                  strides=strides,\n",
        "                                  padding=padding,\n",
        "                                  use_bias=not bn,\n",
        "                                  kernel_regularizer=tf.keras.regularizers.L2(0.0005),\n",
        "                                  kernel_initializer=tf.random_normal_initializer(stddev=0.01),\n",
        "                                  bias_initializer=tf.constant_initializer(0.))(input_layer)  \n",
        "\n",
        "    if bn: # BatchNormalization\n",
        "        conv = tf.keras.layers.BatchNormalization()(conv)\n",
        "    if activate == True: # Activation\n",
        "        if activate_type == \"leaky\":\n",
        "            conv = tf.keras.layers.LeakyReLU(alpha=0.1)(conv)\n",
        "        elif activate_type == \"mish\":\n",
        "          conv = tf.math.softplus(conv)\n",
        "          conv = conv * tf.math.tanh(conv)\n",
        "\n",
        "    return conv "
      ],
      "metadata": {
        "id": "qOQfi4XqN2Tj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Residual Block"
      ],
      "metadata": {
        "id": "kOPp6kF4N-iW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def residual_block(x, channels, filter1, filter2, activation='leaky'):\n",
        "    shortcut = x\n",
        "    x = convolutional(x, filters_shape=(1, 1, channels,filter1), activate_type=activation)\n",
        "    x = convolutional(x, filters_shape=(3, 3, filter1, filter2), activate_type=activation)\n",
        "\n",
        "    residual_layer = shortcut + x\n",
        "    return residual_layer"
      ],
      "metadata": {
        "id": "leAucGvIN_Tl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# yolo_framework    ====> 'tf', 'trt'   \n",
        "# yolo_type         ====> yolov3, yolov4, yolov3-tiny, yolov4-tiny\n",
        "# input_classes     ====> \"mnist/mnist.names\", \"/content/coco.names\"\n",
        "\n",
        "input_classes=\"/content/coco.names\"\n",
        "\n",
        "class_names = {}\n",
        "with open(input_classes, 'r') as data:\n",
        "    for ID, name in enumerate(data):\n",
        "        class_names[ID] = name.strip('\\n')\n",
        "\n",
        "yolo = Load_Yolo_model(yolo_framework='tf',\n",
        "                       yolo_type='yolov3',\n",
        "                       yolo_costom_weights=False,\n",
        "                       input_size=416,\n",
        "                       input_classes=input_classes, \n",
        "                       class_names=class_names)\n",
        "\n",
        "image_path = '/content/dog.jpg'\n",
        "image_path = '/content/office.jpg'"
      ],
      "metadata": {
        "id": "0UdBcAxOOCyQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}