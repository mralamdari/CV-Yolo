{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Yolo_TensorFlow.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "zlKh5ITE4Gpr",
        "fijLvIz9Jdn1",
        "mi72zdD370_k"
      ],
      "authorship_tag": "ABX9TyN0Shs/ZrDPxb3qtDnvEo3M",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mralamdari/CV-Yolo/blob/main/Yolo_TensorFlow.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W0qlttAELlC9"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import PIL\n",
        "import colorsys\n",
        "import scipy.io\n",
        "import scipy.misc\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab.patches import cv2_imshow\n",
        "from tensorflow.python.saved_model import tag_constants"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ['KAGGLE_CONFIG_DIR'] = '/content/drive/MyDrive'\n",
        "!kaggle datasets download -d aruchomu/data-for-yolo-v3-kernel\n",
        "!unzip \\*.zip && rm *.zip"
      ],
      "metadata": {
        "id": "hStuvGiBMSja"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load The Yolo Model\n",
        "\n",
        "choose between yolo frameworks between; tf and trt\n",
        "\n",
        "\n",
        "and yolo types between;\n",
        "yolov3\n",
        "yolov3-tiny\n",
        "yolov4\n",
        "yolov4-tiny\n",
        "\n",
        "\n",
        " and decide if you need custom weights "
      ],
      "metadata": {
        "id": "kTSIBwjdMX5v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_yolo_model(yolo_framework, yolo_type, yolo_costom_weights, input_size, input_classes, class_names):\n",
        "    \n",
        "    physical_devices = tf.config.list_physical_devices('GPU')\n",
        "    try:\n",
        "        tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "    if yolo_framework == \"tf\": # TensorFlow detection framework\n",
        "        \n",
        "        if yolo_costom_weights:\n",
        "            checkpoint = f\"./checkpoints/{yolo_type}_custom\"\n",
        "            print(f\"Loading custom weights from: {checkpoint}\")\n",
        "            yolo = create_yolo_model(yolo_type, class_names, input_size=input_size, classes=input_classes)\n",
        "            yolo.load_weights(checkpoint)\n",
        "        else:\n",
        "            Darknet_weights = f'model_data/{yolo_type}.weights'\n",
        "            print(f\"Loading Darknet_weights from: {Darknet_weights}\")\n",
        "            yolo = create_yolo_model(yolo_type, class_names, input_size=input_size, classes=input_classes)\n",
        "            load_yolo_weights(yolo, Darknet_weights) # use Darknet weights\n",
        "        \n",
        "    elif yolo_framework == \"trt\": # TensorRT detection framework\n",
        "        saved_model_loaded = tf.saved_model.load(yolo_costom_weights, tags=[tag_constants.SERVING])\n",
        "        signature_keys = list(saved_model_loaded.signatures.keys())\n",
        "        yolo = saved_model_loaded.signatures['serving_default']\n",
        "\n",
        "    return yolo "
      ],
      "metadata": {
        "id": "sG_4jEUNMZNh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create Yolo Model\n"
      ],
      "metadata": {
        "id": "3Boa4t2WNSS7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_yolo_model(yolo_type, class_names, classes, input_size=416, channels=3, training=False):\n",
        "    \n",
        "    num_classes = len(class_names)\n",
        "    input_layer  = tf.keras.layers.Input([input_size, input_size, channels])\n",
        "\n",
        "    if yolo_type[-4:] == 'tiny':\n",
        "        if yolo_type == \"yolov4\":\n",
        "            convolutional_layers = YOLOv4_tiny(input_layer, num_classes)\n",
        "        if yolo_type == \"yolov3\":\n",
        "            convolutional_layers = YOLOv3_tiny(input_layer, num_classes)\n",
        "    else:\n",
        "        if yolo_type == \"yolov4\":\n",
        "            convolutional_layers = YOLOv4(input_layer, num_classes)\n",
        "        if yolo_type == \"yolov3\":\n",
        "            convolutional_layers = YOLOv3(input_layer, num_classes)\n",
        "\n",
        "    output_tensors = []\n",
        "    for i, conv_layer in enumerate(convolutional_layers):\n",
        "        pred_tensor = decode(conv_layer, num_classes, i)\n",
        "        \n",
        "        if training: \n",
        "          output_tensors.append(conv_layer)\n",
        "        \n",
        "        output_tensors.append(pred_tensor)\n",
        "\n",
        "    Yolo = tf.keras.Model(input_layer, output_tensors)\n",
        "\n",
        "    return Yolo"
      ],
      "metadata": {
        "id": "RR6_TxpcNVCp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Up Sample\n",
        "\n",
        "resize the batch of images' height and weidth\n",
        "\n",
        "    # shape=(None, 13, 13, 256)    ===>   (None, 26, 26, 256)\n",
        "    # shape=(None, 26, 26, 128)    ===>   (None, 56, 56, 128)"
      ],
      "metadata": {
        "id": "xV-iOWU0NXgp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def upsample(input_layer):\n",
        "    return tf.keras.layers.UpSampling2D(2)(input_layer)\n",
        "    # return tf.image.resize(input_layer, (input_layer.shape[1] * 2, input_layer.shape[2] * 2), method='nearest')"
      ],
      "metadata": {
        "id": "DTnP9K6zNXv2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Convolutional Layer"
      ],
      "metadata": {
        "id": "YMFUMkkxNz33"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def convolutional(input_layer, input_dim, output_dim, kernel_size, downsample=False, activate=True, bn=True, activate_type='leaky'):\n",
        "    if downsample:\n",
        "        input_layer = tf.keras.layers.ZeroPadding2D(((1, 0), (1, 0)))(input_layer)\n",
        "        padding = 'valid'\n",
        "        strides = 2\n",
        "    else:\n",
        "        strides = 1\n",
        "        padding = 'same'\n",
        "\n",
        "    conv = tf.keras.layers.Conv2d(filters=output_dim,\n",
        "                                  kernel_size=kernel_size,\n",
        "                                  strides=strides,\n",
        "                                  padding=padding,\n",
        "                                  use_bias=not bn,\n",
        "                                  kernel_regularizer=tf.keras.regularizers.L2(0.0005),\n",
        "                                  kernel_initializer=tf.random_normal_initializer(stddev=0.01),\n",
        "                                  bias_initializer=tf.constant_initializer(0.))(input_layer)  \n",
        "\n",
        "    if bn: # BatchNormalization\n",
        "        conv = tf.keras.layers.BatchNormalization()(conv)\n",
        "    if activate == True: # Activation\n",
        "        if activate_type == \"leaky\":\n",
        "            conv = tf.keras.layers.LeakyReLU(alpha=0.1)(conv)\n",
        "        elif activate_type == \"mish\":\n",
        "          conv = tf.math.softplus(conv)\n",
        "          conv = conv * tf.math.tanh(conv)\n",
        "\n",
        "    return conv "
      ],
      "metadata": {
        "id": "qOQfi4XqN2Tj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Residual Block\n",
        "\n",
        "this blocks uses 2 convolutional layers with different kernels and filters, but at last, their output's and input's dimention are same so we can concatenate them and prevent the model from loosing the details in lower layers.\n"
      ],
      "metadata": {
        "id": "kOPp6kF4N-iW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def residual_block(x, channels, filter1, filter2, activation='leaky'):\n",
        "    shortcut = x\n",
        "    x = convolutional(x, channels,filter1, 1, activate_type=activation)\n",
        "    x = convolutional(x, filter1, filter2, 3, activate_type=activation)\n",
        "\n",
        "    residual_layer = shortcut + x\n",
        "    return residual_layer"
      ],
      "metadata": {
        "id": "leAucGvIN_Tl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Yolo V3"
      ],
      "metadata": {
        "id": "zlKh5ITE4Gpr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -P model_data https://pjreddie.com/media/files/yolov3.weights"
      ],
      "metadata": {
        "id": "SYO17crZ56a5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## DarkNet 53\n",
        "\n",
        "it returns 3 branches to the yolo model"
      ],
      "metadata": {
        "id": "q9CpBj_MIyRQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def darknet53(input_data):\n",
        "    input_data = convolutional(input_data, 3, 32, 3)\n",
        "    input_data = convolutional(input_data, 32, 64, 3, downsample=True)\n",
        "\n",
        "    for i in range(1):\n",
        "        input_data = residual_block(input_data,  64, 32, 64)\n",
        "\n",
        "    input_data = convolutional(input_data, 64, 128, 3, downsample=True)\n",
        "\n",
        "    for i in range(2):\n",
        "        input_data = residual_block(input_data, 128, 64, 128)\n",
        "\n",
        "    input_data = convolutional(input_data, 128, 256, 3, downsample=True)\n",
        "\n",
        "    for i in range(8):\n",
        "        input_data = residual_block(input_data, 256, 128, 256)\n",
        "\n",
        "    route_1 = input_data\n",
        "    input_data = convolutional(input_data, 256, 512, 3, downsample=True)\n",
        "\n",
        "    for i in range(8):\n",
        "        input_data = residual_block(input_data, 512, 256, 512)\n",
        "\n",
        "    route_2 = input_data\n",
        "    input_data = convolutional(input_data, 512, 1024, 3, downsample=True)\n",
        "\n",
        "    for i in range(4):\n",
        "        input_data = residual_block(input_data, 1024, 512, 1024)\n",
        "\n",
        "    return route_1, route_2, input_data"
      ],
      "metadata": {
        "id": "sL8cXdFz4ODO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Yolov3 model\n",
        "\n",
        "it gets the results from the Darknet-53 bloack then predicts the pictures in 3 scales"
      ],
      "metadata": {
        "id": "fijLvIz9Jdn1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def YOLOv3(input_layer, classes_count):\n",
        "    route_1, route_2, conv = darknet53(input_layer)\n",
        "\n",
        "    conv = convolutional(conv, 1024, 512, 1)\n",
        "    conv = convolutional(conv, 512, 1024, 3)\n",
        "    conv = convolutional(conv, 1024, 512, 1)\n",
        "    conv = convolutional(conv, 512, 1024, 3)\n",
        "    conv = convolutional(conv, 1024, 512, 1)\n",
        "    conv_lobj_branch = convolutional(conv, 512, 1024, 3)\n",
        "\n",
        "    # convolution_lbbox is used to predict large-sized objects , Shape = [None, 13, 13, 255]     \n",
        "    convolution_lbbox = convolutional(conv_lobj_branch, 1024, 3*(classes_count + 5), 1, activate=False, bn=False)\n",
        "\n",
        "    conv = convolutional(conv, 512,  256, 1)\n",
        "    # upsample here uses the \"nearest neighbor interpolation\" method, which has the advantage that the\n",
        "    # upsampling process does not need to learn, thereby reducing the network parameter  \n",
        "    conv = upsample(conv)\n",
        "\n",
        "    conv = tf.concat([conv, route_2], axis=-1)\n",
        "\n",
        "    conv = convolutional(conv, 768, 256, 1)\n",
        "    conv = convolutional(conv, 256, 512, 3)\n",
        "    conv = convolutional(conv, 512, 256, 1)\n",
        "    conv = convolutional(conv, 256, 512, 3)\n",
        "    conv = convolutional(conv, 512, 256, 1)\n",
        "    conv_mobj_branch = convolutional(conv, 256, 512, 3)\n",
        "\n",
        "    # convolution_mbbox is used to predict medium-sized objects, shape = [None, 26, 26, 255]\n",
        "    convolution_mbbox = convolutional(conv_mobj_branch, 512, 3*(classes_count + 5), 1, activate=False, bn=False)\n",
        "\n",
        "    conv = convolutional(conv, 256, 128, 1)\n",
        "    conv = upsample(conv)\n",
        "\n",
        "    conv = tf.concat([conv, route_1], axis=-1)\n",
        "    conv = convolutional(conv, 384, 128, 1)\n",
        "    conv = convolutional(conv, 128, 256, 3)\n",
        "    conv = convolutional(conv, 256, 128, 1)\n",
        "    conv = convolutional(conv, 128, 256, 3)\n",
        "    conv = convolutional(conv, 256, 128, 1)\n",
        "    conv_sobj_branch = convolutional(conv, 128, 256, 3)\n",
        "\n",
        "    # conv_sbbox is used to predict small size objects, shape = [None, 52, 52, 255]\n",
        "    conv_sbbox = convolutional(conv_sobj_branch, 256, 3*(classes_count +5), 1, activate=False, bn=False)\n",
        "        \n",
        "    return [conv_sbbox, convolution_mbbox, convolution_lbbox]"
      ],
      "metadata": {
        "id": "O6JopKdwIkOW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Yolo V3 Tiny"
      ],
      "metadata": {
        "id": "lyuBaNNa5wte"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -P model_data https://pjreddie.com/media/files/yolov3-tiny.weights"
      ],
      "metadata": {
        "id": "IMwIg6125_E8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## DarkNet19_tiny"
      ],
      "metadata": {
        "id": "cHoTs16a6iVQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def darknet19_tiny(input_data):\n",
        "    input_data = convolutional(input_data, 3, 16, 3)\n",
        "    input_data = tf.keras.layers.MaxPool2D(2, 2, 'same')(input_data)\n",
        "    input_data = convolutional(input_data, 16, 32, 3)\n",
        "    input_data = tf.keras.layers.MaxPool2D(2, 2, 'same')(input_data)\n",
        "    input_data = convolutional(input_data, 32, 64, 3)\n",
        "    input_data = tf.keras.layers.MaxPool2D(2, 2, 'same')(input_data)\n",
        "    input_data = convolutional(input_data, 64, 128, 3)\n",
        "    input_data = tf.keras.layers.MaxPool2D(2, 2, 'same')(input_data)\n",
        "    input_data = convolutional(input_data, 128, 256, 3)\n",
        "    route_1 = input_data\n",
        "    input_data = tf.keras.layers.MaxPool2D(2, 2, 'same')(input_data)\n",
        "    input_data = convolutional(input_data, 256, 512, 3)\n",
        "    input_data = tf.keras.layers.MaxPool2D(2, 1, 'same')(input_data)\n",
        "    input_data = convolutional(input_data, 512, 1024, 3)\n",
        "\n",
        "    return route_1, input_data"
      ],
      "metadata": {
        "id": "MaJocHKm5ziC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Yolov3-Tiny model\n"
      ],
      "metadata": {
        "id": "R_wPFgyX7mQ8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def YOLOv3_tiny(input_layer, NUM_CLASS):\n",
        "    # After the input layer enters the Darknet-19 network, we get two branches\n",
        "    route_1, conv = darknet19_tiny(input_layer)\n",
        "\n",
        "    conv = convolutional(conv, 1024, 256, 1)\n",
        "    conv_lobj_branch = convolutional(conv, 256, 512, 3)\n",
        "    \n",
        "    # conv_lbbox is used to predict large-sized objects , Shape = [None, 26, 26, 255]\n",
        "    conv_lbbox = convolutional(conv_lobj_branch, 512, 3*(NUM_CLASS + 5), 1, activate=False, bn=False)\n",
        "\n",
        "    conv = convolutional(conv, 256, 128, 1)\n",
        "    # upsample here uses the nearest neighbor interpolation method, which has the advantage that the\n",
        "    # upsampling process does not need to learn, thereby reducing the network parameter  \n",
        "    conv = upsample(conv)\n",
        "    \n",
        "    conv = tf.concat([conv, route_1], axis=-1)\n",
        "    conv_mobj_branch = convolutional(conv, 128, 256, 3)\n",
        "    # conv_mbbox is used to predict medium size objects, shape = [None, 13, 13, 255]\n",
        "    conv_mbbox = convolutional(conv_mobj_branch, 256, 3 * (NUM_CLASS + 5), 1, activate=False, bn=False)\n",
        "\n",
        "    return [conv_mbbox, conv_lbbox]"
      ],
      "metadata": {
        "id": "QWqdgZl550B6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Yolo V4"
      ],
      "metadata": {
        "id": "qmT-eAiV50Pr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -P model_data https://github.com/AlexeyAB/darknet/releases/download/darknet_yolo_v3_optimal/yolov4.weights"
      ],
      "metadata": {
        "id": "-hPgvibk7p1S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def cspdarknet53(input_data):\n",
        "    input_data = convolutional(input_data, 3,  32, 3, activate_type=\"mish\")\n",
        "    input_data = convolutional(input_data, 32, 64, 3, downsample=True, activate_type=\"mish\")\n",
        "\n",
        "    route = input_data\n",
        "    route = convolutional(route, 64, 64, 1, activate_type=\"mish\")\n",
        "    input_data = convolutional(input_data, 64, 64, 1, activate_type=\"mish\")\n",
        "\n",
        "    for i in range(1):\n",
        "        input_data = residual_block(input_data,  64,  32, 64, activate_type=\"mish\")\n",
        "\n",
        "    input_data = convolutional(input_data, 64, 64, 1, activate_type=\"mish\")\n",
        "\n",
        "    input_data = tf.concat([input_data, route], axis=-1)\n",
        "    input_data = convolutional(input_data, 128, 64, 1, activate_type=\"mish\")\n",
        "    input_data = convolutional(input_data, 64, 128, 3, downsample=True, activate_type=\"mish\")\n",
        "    route = input_data\n",
        "\n",
        "    route = convolutional(route, 128, 64, 1, activate_type=\"mish\")\n",
        "    input_data = convolutional(input_data, 128, 64, 1, activate_type=\"mish\")\n",
        "\n",
        "    for i in range(2):\n",
        "        input_data = residual_block(input_data, 64,  64, 64, activate_type=\"mish\")\n",
        "\n",
        "    input_data = convolutional(input_data, 64, 64, 1, activate_type=\"mish\")\n",
        "    input_data = tf.concat([input_data, route], axis=-1)\n",
        "\n",
        "    input_data = convolutional(input_data, 128, 128, 1, activate_type=\"mish\")\n",
        "    input_data = convolutional(input_data, 128, 256, 3, downsample=True, activate_type=\"mish\")\n",
        "    route = input_data\n",
        "\n",
        "    route = convolutional(route, 256, 128, 1, activate_type=\"mish\")\n",
        "    input_data = convolutional(input_data, 256, 128, 1, activate_type=\"mish\")\n",
        "\n",
        "    for i in range(8):\n",
        "        input_data = residual_block(input_data, 128, 128, 128, activate_type=\"mish\")\n",
        "\n",
        "    input_data = convolutional(input_data, 128, 128, 1, activate_type=\"mish\")\n",
        "    input_data = tf.concat([input_data, route], axis=-1)\n",
        "\n",
        "    input_data = convolutional(input_data, 256, 256, 1, activate_type=\"mish\")\n",
        "    route_1 = input_data\n",
        "\n",
        "    input_data = convolutional(input_data, 256, 512, 3, downsample=True, activate_type=\"mish\")\n",
        "    route = input_data\n",
        "\n",
        "    route = convolutional(route, 512, 256, 1, activate_type=\"mish\")\n",
        "    input_data = convolutional(input_data, 512, 256, 1, activate_type=\"mish\")\n",
        "\n",
        "    for i in range(8):\n",
        "        input_data = residual_block(input_data, 256, 256, 256, activate_type=\"mish\")\n",
        "\n",
        "    input_data = convolutional(input_data, 256, 256, 1, activate_type=\"mish\")\n",
        "    input_data = tf.concat([input_data, route], axis=-1)\n",
        "\n",
        "    input_data = convolutional(input_data, 512, 512, 1, activate_type=\"mish\")\n",
        "    route_2 = input_data\n",
        "\n",
        "    input_data = convolutional(input_data, 512, 1024, 3, downsample=True, activate_type=\"mish\")\n",
        "    route = input_data\n",
        "\n",
        "    route = convolutional(route, 1024, 512, 1, activate_type=\"mish\")\n",
        "    input_data = convolutional(input_data, 1024, 512, 1, activate_type=\"mish\")\n",
        "\n",
        "    for i in range(4):\n",
        "        input_data = residual_block(input_data, 512, 512, 512, activate_type=\"mish\")\n",
        "        \n",
        "    input_data = convolutional(input_data, 512, 512, 1, activate_type=\"mish\")\n",
        "    input_data = tf.concat([input_data, route], axis=-1)\n",
        "\n",
        "    input_data = convolutional(input_data, 1024, 1024, 1, activate_type=\"mish\")\n",
        "    input_data = convolutional(input_data, 1024, 512, 1)\n",
        "    input_data = convolutional(input_data, 512, 1024, 3)\n",
        "    input_data = convolutional(input_data, 1024, 512, 1)\n",
        "\n",
        "    max_pooling_1 = tf.keras.layers.MaxPool2D(pool_size=13, padding='SAME', strides=1)(input_data)\n",
        "    max_pooling_2 = tf.keras.layers.MaxPool2D(pool_size=9, padding='SAME', strides=1)(input_data)\n",
        "    max_pooling_3 = tf.keras.layers.MaxPool2D(pool_size=5, padding='SAME', strides=1)(input_data)\n",
        "    input_data = tf.concat([max_pooling_1, max_pooling_2, max_pooling_3, input_data], axis=-1)\n",
        "\n",
        "    input_data = convolutional(input_data, 2048, 512, 1)\n",
        "    input_data = convolutional(input_data, 512, 1024, 3)\n",
        "    input_data = convolutional(input_data, 1024, 512, 1)\n",
        "\n",
        "    return route_1, route_2, input_data"
      ],
      "metadata": {
        "id": "qwrVRQMD7pw8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def YOLOv4(input_layer, NUM_CLASS):\n",
        "    route_1, route_2, conv = cspdarknet53(input_layer)\n",
        "\n",
        "    route = conv\n",
        "    conv = convolutional(conv, 512, 256, 1)\n",
        "    conv = upsample(conv)\n",
        "    route_2 = convolutional(route_2, 512, 256, 1)\n",
        "    conv = tf.concat([route_2, conv], axis=-1)\n",
        "\n",
        "    conv = convolutional(conv, 512, 256, 1)\n",
        "    conv = convolutional(conv, 256, 512, 1)\n",
        "    conv = convolutional(conv, 512, 256, 1)\n",
        "    conv = convolutional(conv, 256, 512, 1)\n",
        "    conv = convolutional(conv, 512, 256, 1)\n",
        "\n",
        "    route_2 = conv\n",
        "    conv = convolutional(conv, 256, 128, 1)\n",
        "    conv = upsample(conv)\n",
        "    route_1 = convolutional(route_1, 256, 128, 1)\n",
        "    conv = tf.concat([route_1, conv], axis=-1)\n",
        "\n",
        "    conv = convolutional(conv, 256, 128, 1)\n",
        "    conv = convolutional(conv, 128, 256, 3)\n",
        "    conv = convolutional(conv, 256, 128, 1)\n",
        "    conv = convolutional(conv, 128, 256, 3)\n",
        "    conv = convolutional(conv, 256, 128, 1)\n",
        "\n",
        "    route_1 = conv\n",
        "    conv = convolutional(conv, 128, 256, 3)\n",
        "    conv_sbbox = convolutional(conv, 256, 3 * (NUM_CLASS + 5), 1, activate=False, bn=False)\n",
        "\n",
        "    conv = convolutional(route_1, (3, 3, 128, 256), downsample=True)\n",
        "    conv = tf.concat([conv, route_2], axis=-1)\n",
        "\n",
        "    conv = convolutional(conv, 512, 256, 1)\n",
        "    conv = convolutional(conv, 256, 512, 1)\n",
        "    conv = convolutional(conv, 512, 256, 1)\n",
        "    conv = convolutional(conv, 256, 512, 1)\n",
        "    conv = convolutional(conv, 512, 256, 1)\n",
        "\n",
        "    route_2 = conv\n",
        "    conv = convolutional(conv, 256, 512, 1)\n",
        "    conv_mbbox = convolutional(conv, 512, 3 * (NUM_CLASS + 5), 1, activate=False, bn=False)\n",
        "\n",
        "    conv = convolutional(route_2, 256, 512, 3, downsample=True)\n",
        "    conv = tf.concat([conv, route], axis=-1)\n",
        "\n",
        "    conv = convolutional(conv, 1024, 512, 1)\n",
        "    conv = convolutional(conv, 512, 1024, 3)\n",
        "    conv = convolutional(conv, 1024, 512, 1)\n",
        "    conv = convolutional(conv, 512, 1024, 3)\n",
        "    conv = convolutional(conv, 1024, 512, 1)\n",
        "\n",
        "    conv = convolutional(conv, 512, 1024, 3)\n",
        "    conv_lbbox = convolutional(conv, 1024, 3 * (NUM_CLASS + 5), 1, activate=False, bn=False)\n",
        "\n",
        "    return [conv_sbbox, conv_mbbox, conv_lbbox]"
      ],
      "metadata": {
        "id": "5Pi35psw7prl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Yolo V4 Tiny"
      ],
      "metadata": {
        "id": "mi72zdD370_k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -P model_data https://github.com/AlexeyAB/darknet/releases/download/darknet_yolo_v4_pre/yolov4-tiny.weights"
      ],
      "metadata": {
        "id": "OKFI_I3q737q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def route_group(input_layer, groups, group_id):\n",
        "    convs = tf.split(input_layer, num_or_size_splits=groups, axis=-1)\n",
        "    return convs[group_id]"
      ],
      "metadata": {
        "id": "prV1BsyL77o7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def cspdarknet53_tiny(input_data): # not sure how this should be called\n",
        "    input_data = convolutional(input_data, (3, 3, 3, 32), downsample=True)\n",
        "    input_data = convolutional(input_data, (3, 3, 32, 64), downsample=True)\n",
        "    input_data = convolutional(input_data, (3, 3, 64, 64))\n",
        "\n",
        "    route = input_data\n",
        "    input_data = route_group(input_data, 2, 1)\n",
        "    input_data = convolutional(input_data, (3, 3, 32, 32))\n",
        "    route_1 = input_data\n",
        "    input_data = convolutional(input_data, (3, 3, 32, 32))\n",
        "    input_data = tf.concat([input_data, route_1], axis=-1)\n",
        "    input_data = convolutional(input_data, (1, 1, 32, 64))\n",
        "    input_data = tf.concat([route, input_data], axis=-1)\n",
        "    input_data = tf.keras.layers.MaxPool2D(2, 2, 'same')(input_data)\n",
        "\n",
        "    input_data = convolutional(input_data, (3, 3, 64, 128))\n",
        "    route = input_data\n",
        "    input_data = route_group(input_data, 2, 1)\n",
        "    input_data = convolutional(input_data, (3, 3, 64, 64))\n",
        "    route_1 = input_data\n",
        "    input_data = convolutional(input_data, (3, 3, 64, 64))\n",
        "    input_data = tf.concat([input_data, route_1], axis=-1)\n",
        "    input_data = convolutional(input_data, (1, 1, 64, 128))\n",
        "    input_data = tf.concat([route, input_data], axis=-1)\n",
        "    input_data = tf.keras.layers.MaxPool2D(2, 2, 'same')(input_data)\n",
        "\n",
        "    input_data = convolutional(input_data, (3, 3, 128, 256))\n",
        "    route = input_data\n",
        "    input_data = route_group(input_data, 2, 1)\n",
        "    input_data = convolutional(input_data, (3, 3, 128, 128))\n",
        "    route_1 = input_data\n",
        "    input_data = convolutional(input_data, (3, 3, 128, 128))\n",
        "    input_data = tf.concat([input_data, route_1], axis=-1)\n",
        "    input_data = convolutional(input_data, (1, 1, 128, 256))\n",
        "    route_1 = input_data\n",
        "    input_data = tf.concat([route, input_data], axis=-1)\n",
        "    input_data = tf.keras.layers.MaxPool2D(2, 2, 'same')(input_data)\n",
        "\n",
        "    input_data = convolutional(input_data, (3, 3, 512, 512))\n",
        "\n",
        "    return route_1, input_data"
      ],
      "metadata": {
        "id": "jTYbj9Tx77mK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def YOLOv4_tiny(input_layer, NUM_CLASS):\n",
        "    route_1, conv = cspdarknet53_tiny(input_layer)\n",
        "\n",
        "    conv = convolutional(conv, (1, 1, 512, 256))\n",
        "\n",
        "    conv_lobj_branch = convolutional(conv, (3, 3, 256, 512))\n",
        "    conv_lbbox = convolutional(conv_lobj_branch, (1, 1, 512, 3 * (NUM_CLASS + 5)), activate=False, bn=False)\n",
        "\n",
        "    conv = convolutional(conv, (1, 1, 256, 128))\n",
        "    conv = upsample(conv)\n",
        "    conv = tf.concat([conv, route_1], axis=-1)\n",
        "\n",
        "    conv_mobj_branch = convolutional(conv, (3, 3, 128, 256))\n",
        "    conv_mbbox = convolutional(conv_mobj_branch, (1, 1, 256, 3 * (NUM_CLASS + 5)), activate=False, bn=False)\n",
        "\n",
        "    return [conv_mbbox, conv_lbbox]"
      ],
      "metadata": {
        "id": "_UunTkiL78Dj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Boxes"
      ],
      "metadata": {
        "id": "KhduHHMu78Zf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# yolo_framework    ====> 'tf', 'trt'   \n",
        "# yolo_type         ====> yolov3, yolov4, yolov3-tiny, yolov4-tiny\n",
        "# input_classes     ====> \"mnist/mnist.names\", \"/content/coco.names\"\n",
        "\n",
        "input_classes=\"/content/coco.names\"\n",
        "\n",
        "class_names = {}\n",
        "with open(input_classes, 'r') as data:\n",
        "    for ID, name in enumerate(data):\n",
        "        class_names[ID] = name.strip('\\n')\n",
        "\n",
        "yolo = Load_Yolo_model(yolo_framework='tf',\n",
        "                       yolo_type='yolov3',\n",
        "                       yolo_costom_weights=False,\n",
        "                       input_size=416,\n",
        "                       input_classes=input_classes, \n",
        "                       class_names=class_names)\n",
        "\n",
        "image_path = '/content/dog.jpg'\n",
        "image_path = '/content/office.jpg'"
      ],
      "metadata": {
        "id": "0UdBcAxOOCyQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}