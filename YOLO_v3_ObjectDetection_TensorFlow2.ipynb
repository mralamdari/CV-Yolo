{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "YOLO_v3_ObjectDetection_TensorFlow2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOmyiwxVuR91pUrkV/9A8fs",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mralamdari/CV-Yolo/blob/main/YOLO_v3_ObjectDetection_TensorFlow2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k1hc6a129ByF"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import PIL\n",
        "import struct # used to convert native Python data types such as strings and numbers into a string of bytes and vice versa\n",
        "import colorsys\n",
        "import scipy.io\n",
        "import scipy.misc\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab.patches import cv2_imshow\n",
        "from tensorflow.python.saved_model import tag_constants"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ['KAGGLE_CONFIG_DIR'] = '/content/drive/MyDrive'\n",
        "!kaggle datasets download -d aruchomu/data-for-yolo-v3-kernel\n",
        "!unzip \\*.zip && rm *.zip"
      ],
      "metadata": {
        "id": "IZwp9Ds59S6z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -P model_data https://pjreddie.com/media/files/yolov3.weights"
      ],
      "metadata": {
        "id": "DTsUrw1n9XpN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_yolo_model(input_size, input_classes, class_names):\n",
        "    \n",
        "  checkpoint = \"./checkpoints/yoloV3_custom\"\n",
        "  yolo = create_yolo_model(class_names, input_size=input_size, classes=input_classes)\n",
        "  yolo.load_weights(checkpoint)\n",
        "  return yolo"
      ],
      "metadata": {
        "id": "joPT63ob9xuy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# create yolo model\n"
      ],
      "metadata": {
        "id": "crv0-DbRFYla"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_yolo_model(class_names, classes, input_size=416, channels=3, training=False):\n",
        "    \n",
        "    num_classes = len(class_names)\n",
        "    input_layer  = tf.keras.layers.Input([input_size, input_size, channels])\n",
        "    convolutional_layers = YOLOv3(input_layer, num_classes)\n",
        "\n",
        "    output_tensors = []\n",
        "    for i, conv_layer in enumerate(convolutional_layers):\n",
        "        pred_tensor = decode(conv_layer, num_classes, i)\n",
        "        \n",
        "        if training: \n",
        "          output_tensors.append(conv_layer)\n",
        "        \n",
        "        output_tensors.append(pred_tensor)\n",
        "\n",
        "    Yolo = tf.keras.Model(input_layer, output_tensors)\n",
        "\n",
        "    return Yolo"
      ],
      "metadata": {
        "id": "ml-WBZsUFW14"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def upsample(input_layer):\n",
        "    return tf.keras.layers.UpSampling2D(2)(input_layer)"
      ],
      "metadata": {
        "id": "LacxPhbEZn-W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Convolutional Layer"
      ],
      "metadata": {
        "id": "-igevIAoKw5s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def convolutional(input_layer, filters_shape, downsample=False, activate=True, bn=True, activate_type='leaky'):\n",
        "    if downsample:\n",
        "        input_layer = tf.keras.layers.ZeroPadding2D(((1, 0), (1, 0)))(input_layer)\n",
        "        padding = 'valid'\n",
        "        strides = 2\n",
        "    else:\n",
        "        strides = 1\n",
        "        padding = 'same'\n",
        "\n",
        "    conv = tf.keras.layers.Conv2d(filters=filters_shape[-1],\n",
        "                                  kernel_size=filters_shape[0],\n",
        "                                  strides=strides,\n",
        "                                  padding=padding,\n",
        "                                  use_bias=not bn,\n",
        "                                  kernel_regularizer=tf.keras.regularizers.L2(0.0005),\n",
        "                                  kernel_initializer=tf.random_normal_initializer(stddev=0.01),\n",
        "                                  bias_initializer=tf.constant_initializer(0.))(input_layer)  \n",
        "\n",
        "    if bn: # BatchNormalization\n",
        "        conv = tf.keras.layers.BatchNormalization()(conv)\n",
        "    if activate == True: # Activation\n",
        "        if activate_type == \"leaky\":\n",
        "            conv = tf.keras.layers.LeakyReLU(alpha=0.1)(conv)\n",
        "        elif activate_type == \"mish\":\n",
        "          conv = tf.math.softplus(conv)\n",
        "          conv = conv * tf.math.tanh(conv)\n",
        "\n",
        "    return conv "
      ],
      "metadata": {
        "id": "8Jls5thIKwrG"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Residual Block"
      ],
      "metadata": {
        "id": "IggSQwAE6OQT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def residual_block(x, channels, filter1, filter2, activation='leaky'):\n",
        "    shortcut = x\n",
        "    x = convolutional(x, filters_shape=(1, 1, channels,filter1), activate_type=activation)\n",
        "    x = convolutional(x, filters_shape=(3, 3, filter1, filter2), activate_type=activation)\n",
        "\n",
        "    residual_layer = shortcut + x\n",
        "    return residual_layer"
      ],
      "metadata": {
        "id": "blX3YFMf6OgI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# yolo_framework    ====> 'tf', 'trt'   \n",
        "# yolo_type         ====> yolov3, yolov4, yolov3-tiny, yolov4-tiny\n",
        "# input_classes     ====> \"mnist/mnist.names\", \"/content/coco.names\"\n",
        "\n",
        "input_classes=\"/content/coco.names\"\n",
        "\n",
        "class_names = {}\n",
        "with open(input_classes, 'r') as data:\n",
        "    for ID, name in enumerate(data):\n",
        "        class_names[ID] = name.strip('\\n')\n",
        "\n",
        "yolo = Load_Yolo_model(yolo_framework='tf',\n",
        "                       yolo_type='yolov3',\n",
        "                       yolo_costom_weights=False,\n",
        "                       input_size=416,\n",
        "                       input_classes=input_classes, \n",
        "                       class_names=class_names)\n",
        "\n",
        "image_path = '/content/dog.jpg'\n",
        "image_path = '/content/office.jpg'"
      ],
      "metadata": {
        "id": "jJEcH5VN9i6E"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}