{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "YOLO_v3_ObjectDetection_TensorFlow_2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1KjWF9QoBfEoW0C2TD82LIxAwn3xIY5Ls",
      "authorship_tag": "ABX9TyMibEA1DrJRKJGeCi7gQnEP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mralamdari/CV-Yolo/blob/main/YOLO_v3_ObjectDetection_TensorFlow_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Source to this code is [here](https://www.kaggle.com/code/mirzamujtaba/yolo-object-detection-using-keras)"
      ],
      "metadata": {
        "id": "koap0m03i_z9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import PIL\n",
        "import struct # used to convert native Python data types such as strings and numbers into a string of bytes and vice versa\n",
        "import scipy.io\n",
        "import scipy.misc\n",
        "import matplotlib\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.layers.merge import add, concatenate"
      ],
      "metadata": {
        "id": "bL3c2-PULwm7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ['KAGGLE_CONFIG_DIR'] = '/content/drive/MyDrive'\n",
        "!kaggle datasets download -d aruchomu/data-for-yolo-v3-kernel\n",
        "!unzip \\*.zip && rm *.zip"
      ],
      "metadata": {
        "id": "M92HYbsA7ML2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "43be6b81-fb07-48a0-c1cc-4dcc0b4b2200"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data-for-yolo-v3-kernel.zip to /content\n",
            " 96% 257M/267M [00:02<00:00, 118MB/s]\n",
            "100% 267M/267M [00:02<00:00, 108MB/s]\n",
            "Archive:  data-for-yolo-v3-kernel.zip\n",
            "  inflating: coco.names              \n",
            "  inflating: detections.gif          \n",
            "  inflating: dog.jpg                 \n",
            "  inflating: futur.ttf               \n",
            "  inflating: office.jpg              \n",
            "  inflating: yolov3.weights          \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Extracting YOLO v3 weights\n",
        "`Read_Weights` class is used to extract the model weights from the \"yolov3.weights\" file into a suitbale format that can be used for keras. The class is also used to integrate the Darknet and YOLO architecures.\n",
        "\n",
        "Yolo is an algorithm that uses convolutional neural networks for object detection. So what's great about object detection? In comparison to recognition algorithms, a detection algorithm does not only predict class labels, but detects locations of objects as well."
      ],
      "metadata": {
        "id": "I66C7p1B8iJg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Read_Weights:\n",
        "\n",
        "    def __init__(self, file_name):\n",
        "\n",
        "        with open(file_name, 'rb') as weights_file:\n",
        "            major, = struct.unpack('i', weights_file.read(4))\n",
        "            minor, = struct.unpack('i', weights_file.read(4))\n",
        "            revision, = struct.unpack('i', weights_file.read(4))\n",
        "\n",
        "            if (major*10 + minor) >= 2 and major < 1000 and minor < 1000:\n",
        "              weights_file.read(8)\n",
        "            else: \n",
        "              weights_file.read(4)\n",
        "            \n",
        "            transpose = (major > 1000) or (minor > 1000)\n",
        "            binary = weights_file.read()\n",
        "\n",
        "        self.offset = 0\n",
        "        self.all_weights = np.frombuffer(binary, dtype='float32')\n",
        "\n",
        "    def read_bytes(self, size):\n",
        "        self.offset = self.offset + size\n",
        "\n",
        "        return self.all_weights[self.offset-size: self.offset]\n",
        "\n",
        "    def load_weights(self, model):\n",
        "        for i in range(106):\n",
        "            try:\n",
        "                conv_layer = model.get_layer(f'conv_{i}')\n",
        "                print(f'Loading weights of Convolution Layer {i}')\n",
        "\n",
        "                if i not in [81, 93, 105]:\n",
        "\n",
        "                    norm_layer = model.get_layer(f'bnorm_{i}')\n",
        "                    size = np.prod(norm_layer.get_weights()[0].shape)\n",
        "                    \n",
        "                    beta  = self.read_bytes(size) # bias\n",
        "                    gamma = self.read_bytes(size) # scale\n",
        "                    mean  = self.read_bytes(size) # mean\n",
        "                    var   = self.read_bytes(size) # variance\n",
        "\n",
        "                    weights = norm_layer.set_weights([gamma, beta, mean, var])\n",
        "\n",
        "                if len(conv_layer.get_weights()) > 1:\n",
        "\n",
        "                    bias   = self.read_bytes(np.prod(conv_layer.get_weights()[1].shape))\n",
        "                    kernel = self.read_bytes(np.prod(conv_layer.get_weights()[0].shape))\n",
        "                    kernel = kernel.reshape(list(reversed(conv_layer.get_weights()[0].shape)))\n",
        "                    kernel = kernel.transpose([2,3,1,0])\n",
        "                    conv_layer.set_weights([kernel, bias])\n",
        "\n",
        "                else:\n",
        "\n",
        "                    kernel = self.read_bytes(np.prod(conv_layer.get_weights()[0].shape))\n",
        "                    kernel = kernel.reshape(list(reversed(conv_layer.get_weights()[0].shape)))\n",
        "                    kernel = kernel.transpose([2,3,1,0])\n",
        "                    conv_layer.set_weights([kernel])\n",
        "\n",
        "            except ValueError:\n",
        "                print(f\"Layer {i} is Not Convolution Layer\")\n",
        " \n",
        "    def reset(self):\n",
        "        self.offset = 0     "
      ],
      "metadata": {
        "id": "h3cAr1Cq68OW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Construction of the YOLO model\n",
        "- `conv_block` is a function to create convolutional layers for CNN\n",
        "- `make_yolov3_model` is a function to create layers of convoluational and stack together as a whole yolo model (Since YOLO v3 uses darknet for feature extraction we will be constructing the model accordingly)\n",
        "\n",
        "For feature extraction Yolo uses Darknet-53 neural net pretrained on ImageNet. Same as ResNet, Darknet-53 has shortcut (residual) connections, which help information from earlier layers flow further. We omit the last 3 layers (Avgpool, Connected and Softmax) since we only need the features.\n",
        "\n"
      ],
      "metadata": {
        "id": "5-VjqFSk7d0U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def conv_block(inp, convs, skip=True):\n",
        "\n",
        "    x = inp\n",
        "    count = 0\n",
        "    \n",
        "    for conv in convs:\n",
        "\n",
        "        if count == (len(convs) - 2) and skip:\n",
        "            skip_connection = x\n",
        "\n",
        "        count += 1\n",
        "        if conv['stride'] > 1 :  x = tf.keras.layers.ZeroPadding2D(((1,0),(1,0)))(x) # peculiar padding as darknet prefers left and top\n",
        "\n",
        "        x = tf.keras.layers.Conv2D(conv['filter'], conv['kernel'],\n",
        "                   strides = conv['stride'],\n",
        "                   padding = 'valid' if conv['stride'] > 1 else 'same', # peculiar padding as darknet prefers left and top\n",
        "                   name = 'conv_' + str(conv['layer_idx']),\n",
        "                   use_bias = False if conv['bnorm'] else True)(x)\n",
        "\n",
        "        if conv['bnorm']: x = tf.keras.layers.BatchNormalization(epsilon = 0.001, name = 'bnorm_' + str(conv['layer_idx']))(x)\n",
        "        if conv['leaky']: x = tf.keras.layers.LeakyReLU(alpha = 0.1, name = 'leaky_' + str(conv['layer_idx']))(x)\n",
        "\n",
        "    return add([skip_connection, x]) if skip else x\n",
        "\n",
        "\n",
        "def make_yolov3_model():\n",
        "\n",
        "    input_image = tf.keras.layers.Input(shape=(None, None, 3))\n",
        "\n",
        "    # Layers 0 to 4\n",
        "    x = conv_block(input_image, [{'filter': 32, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 0},\n",
        "                                {'filter': 64, 'kernel': 3, 'stride': 2, 'bnorm': True, 'leaky': True, 'layer_idx': 1},\n",
        "                                {'filter': 32, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 2},\n",
        "                                {'filter': 64, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 3}])\n",
        "\n",
        "    # Layers 5 to 8\n",
        "    x = conv_block(x, [{'filter': 128, 'kernel': 3, 'stride': 2, 'bnorm': True, 'leaky': True, 'layer_idx': 5},\n",
        "                        {'filter':  64, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 6},\n",
        "                        {'filter': 128, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 7}])\n",
        "\n",
        "    # Layers 9 to 11\n",
        "    x = conv_block(x, [{'filter':  64, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 9},\n",
        "                        {'filter': 128, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 10}])\n",
        "\n",
        "    # Layers 12 to 15\n",
        "    x = conv_block(x, [{'filter': 256, 'kernel': 3, 'stride': 2, 'bnorm': True, 'leaky': True, 'layer_idx': 12},\n",
        "                        {'filter': 128, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 13},\n",
        "                        {'filter': 256, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 14}])\n",
        "\n",
        "    # Layers 16 to 36\n",
        "    for i in range(7):\n",
        "        x = conv_block(x, [{'filter': 128, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 16+i*3},\n",
        "                            {'filter': 256, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 17+i*3}])\n",
        "    skip_36 = x\n",
        "    \n",
        "    # Layers 37 to 40\n",
        "    x = conv_block(x, [{'filter': 512, 'kernel': 3, 'stride': 2, 'bnorm': True, 'leaky': True, 'layer_idx': 37},\n",
        "                        {'filter': 256, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 38},\n",
        "                        {'filter': 512, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 39}])\n",
        "\n",
        "    # Layers 41 to 61\n",
        "    for i in range(7):\n",
        "        x = conv_block(x, [{'filter': 256, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 41+i*3},\n",
        "                            {'filter': 512, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 42+i*3}])\n",
        "    skip_61 = x\n",
        "\n",
        "    # Layers 62 to 65\n",
        "    x = conv_block(x, [{'filter': 1024, 'kernel': 3, 'stride': 2, 'bnorm': True, 'leaky': True, 'layer_idx': 62},\n",
        "                        {'filter':  512, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 63},\n",
        "                        {'filter': 1024, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 64}])\n",
        "\n",
        "    # Layers 66 to 74\n",
        "    for i in range(3):\n",
        "        x = conv_block(x, [{'filter':  512, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 66+i*3},\n",
        "                            {'filter': 1024, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 67+i*3}])\n",
        "\n",
        "    # Layers 75 to 79\n",
        "    x = conv_block(x, [{'filter':  512, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 75},\n",
        "                        {'filter': 1024, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 76},\n",
        "                        {'filter':  512, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 77},\n",
        "                        {'filter': 1024, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 78},\n",
        "                        {'filter':  512, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 79}], skip=False)\n",
        "\n",
        "    # Layers 80 to 82\n",
        "    yolo_82 = conv_block(x, [{'filter': 1024, 'kernel': 3, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 80},\n",
        "                             {'filter':  255, 'kernel': 1, 'stride': 1, 'bnorm': False, 'leaky': False, 'layer_idx': 81}], skip=False)\n",
        "\n",
        "    # Layers 83 to 86\n",
        "    x = conv_block(x, [{'filter': 256, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 84}], skip=False)\n",
        "    x = tf.keras.layers.UpSampling2D(2)(x)\n",
        "    x = concatenate([x, skip_61])\n",
        "\n",
        "    # Layers 87 to 91\n",
        "    x = conv_block(x, [{'filter': 256, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 87},\n",
        "                        {'filter': 512, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 88},\n",
        "                        {'filter': 256, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 89},\n",
        "                        {'filter': 512, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 90},\n",
        "                        {'filter': 256, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 91}], skip=False)\n",
        "\n",
        "    # Layers 92 to 94\n",
        "    yolo_94 = conv_block(x, [{'filter': 512, 'kernel': 3, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 92},\n",
        "                                                                                     {'filter': 255, 'kernel': 1, 'stride': 1, 'bnorm': False, 'leaky': False, 'layer_idx': 93}], skip=False)\n",
        "\n",
        "    # Layers 95 to 98\n",
        "    x = conv_block(x, [{'filter': 128, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True,   'layer_idx': 96}], skip=False)\n",
        "    x = tf.keras.layers.UpSampling2D(2)(x)\n",
        "    x = concatenate([x, skip_36])\n",
        "\n",
        "    # Layers 99 to 106\n",
        "    yolo_106 = conv_block(x, [{'filter': 128, 'kernel': 1, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 99},\n",
        "                                {'filter': 256, 'kernel': 3, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 100},\n",
        "                                {'filter': 128, 'kernel': 1, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 101},\n",
        "                                {'filter': 256, 'kernel': 3, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 102},\n",
        "                                {'filter': 128, 'kernel': 1, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 103},\n",
        "                                {'filter': 256, 'kernel': 3, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 104},\n",
        "                                {'filter': 255, 'kernel': 1, 'stride': 1, 'bnorm': False, 'leaky': False, 'layer_idx': 105}], skip=False)\n",
        "\n",
        "    model = tf.keras.models.Model(input_image, [yolo_82, yolo_94, yolo_106])\n",
        "    return model"
      ],
      "metadata": {
        "id": "m2xiO7Lo7GXL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Define the model"
      ],
      "metadata": {
        "id": "sAbQtaU87SY_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# define the yolo v3 model\n",
        "yolov3 = make_yolov3_model()\n",
        "\n",
        "# load the weights\n",
        "# weight_reader = Read_Weights(\"../input/data-for-yolo-v3-kernel/yolov3.weights\")\n",
        "weight_reader = Read_Weights(\"/content/yolov3.weights\")\n",
        "\n",
        "\n",
        "\n",
        "# set the weights\n",
        "weight_reader.load_weights(yolov3)\n",
        "\n",
        "# save the model to file\n",
        "yolov3.save('yolo_model.h5')"
      ],
      "metadata": {
        "id": "katferSq7P34",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "68924c22-6146-44c4-dffd-c8b98a835bbf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading weights of Convolution Layer 0\n",
            "Loading weights of Convolution Layer 1\n",
            "Loading weights of Convolution Layer 2\n",
            "Loading weights of Convolution Layer 3\n",
            "Layer 4 is Not Convolution Layer\n",
            "Loading weights of Convolution Layer 5\n",
            "Loading weights of Convolution Layer 6\n",
            "Loading weights of Convolution Layer 7\n",
            "Layer 8 is Not Convolution Layer\n",
            "Loading weights of Convolution Layer 9\n",
            "Loading weights of Convolution Layer 10\n",
            "Layer 11 is Not Convolution Layer\n",
            "Loading weights of Convolution Layer 12\n",
            "Loading weights of Convolution Layer 13\n",
            "Loading weights of Convolution Layer 14\n",
            "Layer 15 is Not Convolution Layer\n",
            "Loading weights of Convolution Layer 16\n",
            "Loading weights of Convolution Layer 17\n",
            "Layer 18 is Not Convolution Layer\n",
            "Loading weights of Convolution Layer 19\n",
            "Loading weights of Convolution Layer 20\n",
            "Layer 21 is Not Convolution Layer\n",
            "Loading weights of Convolution Layer 22\n",
            "Loading weights of Convolution Layer 23\n",
            "Layer 24 is Not Convolution Layer\n",
            "Loading weights of Convolution Layer 25\n",
            "Loading weights of Convolution Layer 26\n",
            "Layer 27 is Not Convolution Layer\n",
            "Loading weights of Convolution Layer 28\n",
            "Loading weights of Convolution Layer 29\n",
            "Layer 30 is Not Convolution Layer\n",
            "Loading weights of Convolution Layer 31\n",
            "Loading weights of Convolution Layer 32\n",
            "Layer 33 is Not Convolution Layer\n",
            "Loading weights of Convolution Layer 34\n",
            "Loading weights of Convolution Layer 35\n",
            "Layer 36 is Not Convolution Layer\n",
            "Loading weights of Convolution Layer 37\n",
            "Loading weights of Convolution Layer 38\n",
            "Loading weights of Convolution Layer 39\n",
            "Layer 40 is Not Convolution Layer\n",
            "Loading weights of Convolution Layer 41\n",
            "Loading weights of Convolution Layer 42\n",
            "Layer 43 is Not Convolution Layer\n",
            "Loading weights of Convolution Layer 44\n",
            "Loading weights of Convolution Layer 45\n",
            "Layer 46 is Not Convolution Layer\n",
            "Loading weights of Convolution Layer 47\n",
            "Loading weights of Convolution Layer 48\n",
            "Layer 49 is Not Convolution Layer\n",
            "Loading weights of Convolution Layer 50\n",
            "Loading weights of Convolution Layer 51\n",
            "Layer 52 is Not Convolution Layer\n",
            "Loading weights of Convolution Layer 53\n",
            "Loading weights of Convolution Layer 54\n",
            "Layer 55 is Not Convolution Layer\n",
            "Loading weights of Convolution Layer 56\n",
            "Loading weights of Convolution Layer 57\n",
            "Layer 58 is Not Convolution Layer\n",
            "Loading weights of Convolution Layer 59\n",
            "Loading weights of Convolution Layer 60\n",
            "Layer 61 is Not Convolution Layer\n",
            "Loading weights of Convolution Layer 62\n",
            "Loading weights of Convolution Layer 63\n",
            "Loading weights of Convolution Layer 64\n",
            "Layer 65 is Not Convolution Layer\n",
            "Loading weights of Convolution Layer 66\n",
            "Loading weights of Convolution Layer 67\n",
            "Layer 68 is Not Convolution Layer\n",
            "Loading weights of Convolution Layer 69\n",
            "Loading weights of Convolution Layer 70\n",
            "Layer 71 is Not Convolution Layer\n",
            "Loading weights of Convolution Layer 72\n",
            "Loading weights of Convolution Layer 73\n",
            "Layer 74 is Not Convolution Layer\n",
            "Loading weights of Convolution Layer 75\n",
            "Loading weights of Convolution Layer 76\n",
            "Loading weights of Convolution Layer 77\n",
            "Loading weights of Convolution Layer 78\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading weights of Convolution Layer 79\n",
            "Loading weights of Convolution Layer 80\n",
            "Loading weights of Convolution Layer 81\n",
            "Layer 82 is Not Convolution Layer\n",
            "Layer 83 is Not Convolution Layer\n",
            "Loading weights of Convolution Layer 84\n",
            "Layer 85 is Not Convolution Layer\n",
            "Layer 86 is Not Convolution Layer\n",
            "Loading weights of Convolution Layer 87\n",
            "Loading weights of Convolution Layer 88\n",
            "Loading weights of Convolution Layer 89\n",
            "Loading weights of Convolution Layer 90\n",
            "Loading weights of Convolution Layer 91\n",
            "Loading weights of Convolution Layer 92\n",
            "Loading weights of Convolution Layer 93\n",
            "Layer 94 is Not Convolution Layer\n",
            "Layer 95 is Not Convolution Layer\n",
            "Loading weights of Convolution Layer 96\n",
            "Layer 97 is Not Convolution Layer\n",
            "Layer 98 is Not Convolution Layer\n",
            "Loading weights of Convolution Layer 99\n",
            "Loading weights of Convolution Layer 100\n",
            "Loading weights of Convolution Layer 101\n",
            "Loading weights of Convolution Layer 102\n",
            "Loading weights of Convolution Layer 103\n",
            "Loading weights of Convolution Layer 104\n",
            "Loading weights of Convolution Layer 105\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_image_pixels(filename, shape):\n",
        "\n",
        "  # load image to get its shape\n",
        "  image = tf.keras.preprocessing.image.load_img(filename)\n",
        "  width, height = image.size\n",
        "\n",
        "  # load image with required size\n",
        "  image = tf.keras.preprocessing.image.load_img(filename, target_size = shape)\n",
        "  image = tf.keras.preprocessing.image.img_to_array(image)\n",
        "\n",
        "  # grayscale image normalization\n",
        "  image = image.astype('float32')\n",
        "  image /= 255.0\n",
        "\n",
        "  # add a dimension so that we have one sample\n",
        "  image = np.expand_dims(image, 0)\n",
        "  return image, width, height"
      ],
      "metadata": {
        "id": "jQYbCy8Y7USc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " ## Bounding Boxes\n"
      ],
      "metadata": {
        "id": "8XUwhnuJ79mM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class BoundBox:\n",
        "\n",
        "    def __init__(self, xmin, ymin, xmax, ymax, objness = None, classes = None):\n",
        "        self.xmin = xmin\n",
        "        self.ymin = ymin\n",
        "        self.xmax = xmax\n",
        "        self.ymax = ymax\n",
        "        self.objness = objness\n",
        "        self.classes = classes\n",
        "        self.label = -1\n",
        "        self.score = -1\n",
        "\n",
        "    def get_label(self):\n",
        "        if self.label == -1:\n",
        "            self.label = np.argmax(self.classes)\n",
        "\n",
        "        return self.label\n",
        "\n",
        "    def get_score(self):\n",
        "        if self.score == -1:\n",
        "            self.score = self.classes[self.get_label()]\n",
        "        return self.get_score\n",
        "\n",
        "def _sigmoid(x):\n",
        "    return 1. /(1. + np.exp(-x))\n",
        "\n",
        "def decode_netout(netout, anchors, obj_thresh, net_h, net_w):\n",
        "\n",
        "    grid_h, grid_w = netout.shape[:2]\n",
        "    nb_box = 3\n",
        "    netout = netout.reshape((grid_h, grid_w, nb_box, -1))\n",
        "    nb_class = netout.shape[-1] - 5\n",
        "    boxes = []\n",
        "    netout[..., :2]  = _sigmoid(netout[..., :2])\n",
        "    netout[..., 4:]  = _sigmoid(netout[..., 4:])\n",
        "    netout[..., 5:]  = netout[..., 4][..., np.newaxis] * netout[..., 5:]\n",
        "    netout[..., 5:] *= netout[..., 5:] > obj_thresh\n",
        "\n",
        "    for i in range(grid_h*grid_w):\n",
        "        row = i / grid_w\n",
        "        col = i % grid_w\n",
        "        for b in range(nb_box):\n",
        "\n",
        "            # 4th element is objectness score\n",
        "            objectness = netout[int(row)][int(col)][b][4]\n",
        "            if(objectness.all() <= obj_thresh): continue\n",
        "\n",
        "            # first 4 elements are x, y, w, and h\n",
        "            x, y, w, h = netout[int(row)][int(col)][b][:4]\n",
        "            x = (col + x) / grid_w # center position, unit: image width\n",
        "            y = (row + y) / grid_h # center position, unit: image height\n",
        "            w = anchors[2 * b + 0] * np.exp(w) / net_w # unit: image width\n",
        "            h = anchors[2 * b + 1] * np.exp(h) / net_h # unit: image height\n",
        "\n",
        "            # last elements are class probabilities\n",
        "            classes = netout[int(row)][col][b][5:]\n",
        "            box = BoundBox(x-w/2, y-h/2, x+w/2, y+h/2, objectness, classes)\n",
        "            boxes.append(box)\n",
        "\n",
        "    return boxes"
      ],
      "metadata": {
        "id": "zNgaYqez77rb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## `correct_yolo_boxes` is used to resize the bounding boxes to the original image shape."
      ],
      "metadata": {
        "id": "c0T_3WV98C5N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def correct_yolo_boxes(boxes, image_h, image_w, net_h, net_w):\n",
        "\n",
        "    new_w, new_h = net_w, net_h\n",
        "    for i in range(len(boxes)):\n",
        "\n",
        "        x_offset, x_scale = (net_w - new_w)/2./net_w, float(new_w)/net_w\n",
        "        y_offset, y_scale = (net_h - new_h)/2./net_h, float(new_h)/net_h\n",
        "\n",
        "        boxes[i].xmin = int((boxes[i].xmin - x_offset) / x_scale * image_w)\n",
        "        boxes[i].xmax = int((boxes[i].xmax - x_offset) / x_scale * image_w)\n",
        "        boxes[i].ymin = int((boxes[i].ymin - y_offset) / y_scale * image_h)\n",
        "        boxes[i].ymax = int((boxes[i].ymax - y_offset) / y_scale * image_h)"
      ],
      "metadata": {
        "id": "NAaPe93z8AC8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Non Max Supression (NMS) and Intersection over Union (IOU)\n",
        "### `interval_overlap` function is used to find the overlapping regions\n",
        "\n",
        "### `bbox_iou` function is the implementation of IOU\n",
        "\n",
        "### `nms` function is the implementation of NMS\n",
        "\n"
      ],
      "metadata": {
        "id": "Kf3vmksk8IaO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def interval_overlap(interval_a, interval_b):\n",
        "\n",
        "    x1, x2 = interval_a\n",
        "    x3, x4 = interval_b\n",
        "\n",
        "    if x3 < x1:\n",
        "        if x4 < x1:\n",
        "            return 0\n",
        "        else:\n",
        "            return min(x2,x4) - x1\n",
        "    else:\n",
        "        if x2 < x3:\n",
        "             return 0\n",
        "        else:\n",
        "            return min(x2,x4) - x3\n",
        " \n",
        "def bbox_iou(box1, box2):\n",
        "\n",
        "    intersect_w = interval_overlap([box1.xmin, box1.xmax], [box2.xmin, box2.xmax])\n",
        "    intersect_h = interval_overlap([box1.ymin, box1.ymax], [box2.ymin, box2.ymax])\n",
        "    intersect = intersect_w * intersect_h\n",
        "    w1, h1 = box1.xmax-box1.xmin, box1.ymax-box1.ymin\n",
        "    w2, h2 = box2.xmax-box2.xmin, box2.ymax-box2.ymin\n",
        "    union = w1*h1 + w2*h2 - intersect\n",
        "    return float(intersect) / union\n",
        " \n",
        "def nms(boxes, nms_thresh):\n",
        "\n",
        "    if len(boxes) > 0:\n",
        "        nb_class = len(boxes[0].classes)\n",
        "    else:\n",
        "        return\n",
        "\n",
        "    for c in range(nb_class):\n",
        "        sorted_indices = np.argsort([-box.classes[c] for box in boxes])\n",
        "\n",
        "        for i in range(len(sorted_indices)):\n",
        "            index_i = sorted_indices[i]\n",
        "\n",
        "            if boxes[index_i].classes[c] == 0: continue\n",
        "\n",
        "            for j in range(i+1, len(sorted_indices)):\n",
        "                index_j = sorted_indices[j]\n",
        "\n",
        "                if bbox_iou(boxes[index_i], boxes[index_j]) >= nms_thresh:\n",
        "                    boxes[index_j].classes[c] = 0\n",
        "\n",
        "# get all of the results above a threshold\n",
        "def get_boxes(boxes, labels, thresh):\n",
        "\n",
        "    v_boxes, v_labels, v_scores = list(), list(), list()\n",
        "    # enumerate all boxes\n",
        "    for box in boxes:\n",
        "        # enumerate all possible labels\n",
        "        for i in range(len(labels)):\n",
        "            # check if the threshold for this label is high enough\n",
        "            if box.classes[i] > thresh:\n",
        "                v_boxes.append(box)\n",
        "                v_labels.append(labels[i])\n",
        "                v_scores.append(box.classes[i]*100)\n",
        "                # don't break, many labels may trigger for one box\n",
        "\n",
        "    return v_boxes, v_labels, v_scores\n",
        "\n",
        "# draw all results\n",
        "def draw_boxes(filename, v_boxes, v_labels, v_scores):\n",
        "  \n",
        "    data = plt.imread(filename)\n",
        "    plt.imshow(data)\n",
        "    ax = plt.gca()\n",
        "\n",
        "    # plot each box\n",
        "    for i in range(len(v_boxes)):\n",
        "        box = v_boxes[i]\n",
        "\n",
        "        # get coordinates\n",
        "        y1, x1, y2, x2 = box.ymin, box.xmin, box.ymax, box.xmax\n",
        "        width, height = x2 - x1, y2 - y1\n",
        "        # create the shape\n",
        "        rect = plt.Rectangle((x1, y1), width, height, fill = False, color = 'red', linewidth = '2')\n",
        "\n",
        "        # draw the box\n",
        "        ax.add_patch(rect)\n",
        "        # draw text and score in top left corner\n",
        "        label = \"%s (%.3f)\" % (v_labels[i], v_scores[i])\n",
        "        plt.text(x1, y1, label, color = 'b')\n",
        "\n",
        "    # show the plot\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "RGvFOc8G8Cln"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Anchors and labels\n"
      ],
      "metadata": {
        "id": "93j7wbLU8OHr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# define the anchors\n",
        "anchors = [[116,90, 156,198, 373,326], [30,61, 62,45, 59,119], [10,13, 16,30, 33,23]]\n",
        "\n",
        "# define the probability threshold for detected objects\n",
        "class_threshold = 0.6\n",
        "\n",
        "# define the labels\n",
        "labels = [\"person\", \"bicycle\", \"car\", \"motorbike\", \"aeroplane\", \"bus\", \"train\", \"truck\",\n",
        "    \"boat\", \"traffic light\", \"fire hydrant\", \"stop sign\", \"parking meter\", \"bench\",\n",
        "    \"bird\", \"cat\", \"dog\", \"horse\", \"sheep\", \"cow\", \"elephant\", \"bear\", \"zebra\", \"giraffe\",\n",
        "    \"backpack\", \"umbrella\", \"handbag\", \"tie\", \"suitcase\", \"frisbee\", \"skis\", \"snowboard\",\n",
        "    \"sports ball\", \"kite\", \"baseball bat\", \"baseball glove\", \"skateboard\", \"surfboard\",\n",
        "    \"tennis racket\", \"bottle\", \"wine glass\", \"cup\", \"fork\", \"knife\", \"spoon\", \"bowl\", \"banana\",\n",
        "    \"apple\", \"sandwich\", \"orange\", \"broccoli\", \"carrot\", \"hot dog\", \"pizza\", \"donut\", \"cake\",\n",
        "    \"chair\", \"sofa\", \"pottedplant\", \"bed\", \"diningtable\", \"toilet\", \"tvmonitor\", \"laptop\", \"mouse\",\n",
        "    \"remote\", \"keyboard\", \"cell phone\", \"microwave\", \"oven\", \"toaster\", \"sink\", \"refrigerator\",\n",
        "    \"book\", \"clock\", \"vase\", \"scissors\", \"teddy bear\", \"hair drier\", \"toothbrush\"]"
      ],
      "metadata": {
        "id": "R8lXpHKA8Mfp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Make predictions"
      ],
      "metadata": {
        "id": "0Hzs6eY08R7k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_w, input_h = 416, 416\n",
        "\n",
        "def predict_boxes(image_names):\n",
        "    for image_name in image_names:\n",
        "      image, image_w, image_h = load_image_pixels(image_name, (input_w, input_h))\n",
        "\n",
        "      # make prediction\n",
        "      yhat = yolov3.predict(image)\n",
        "      # summarize the shape of the list of arrays\n",
        "      print([a.shape for a in yhat])\n",
        "\n",
        "      boxes = list() \n",
        "      for i in range(len(yhat)):\n",
        "        # decode the output of the network\n",
        "        boxes += decode_netout(yhat[i][0], anchors[i], class_threshold, input_h, input_w)\n",
        "\n",
        "      # correct the sizes of the bounding boxes for the shape of the image\n",
        "      correct_yolo_boxes(boxes, image_h, image_w, input_h, input_w)\n",
        "\n",
        "      # suppress non-maximal boxes\n",
        "      nms(boxes, 0.5)\n",
        "\n",
        "      # get the details of the detected objects\n",
        "      v_boxes, v_labels, v_scores = get_boxes(boxes, labels, class_threshold)\n",
        "\n",
        "      # summarize what we found\n",
        "      for i in range(len(v_boxes)):\n",
        "        print(v_labels[i], v_scores[i])\n",
        "\n",
        "      # draw what we found\n",
        "      draw_boxes(image_name, v_boxes, v_labels, v_scores)"
      ],
      "metadata": {
        "id": "VW2XRB6h8QbV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# image_names = [\"../input/data-for-yolo-v3-kernel/dog.jpg\", \"../input/data-for-yolo-v3-kernel/office.jpg\"]\n",
        "image_names = [\"/content/dog.jpg\", \"/content/office.jpg\"]\n",
        "\n",
        "predict_boxes(image_names)"
      ],
      "metadata": {
        "id": "SKG-JfOb8Uil"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "xuySnlQp7sRC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
