{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "YOLO_v3_ObjectDetection_TensorFlow_3.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNugD7RwzdilIQJ9o/2/stD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mralamdari/CV-Yolo/blob/main/YOLO_v3_ObjectDetection_TensorFlow_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Source is [here](https://github.com/pythonlessons/TensorFlow-2.x-YOLOv3)"
      ],
      "metadata": {
        "id": "l-ZmkMB_5qon"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "_bps36GS5qXg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ['KAGGLE_CONFIG_DIR'] = '/content/drive/MyDrive'\n",
        "!kaggle datasets download -d aruchomu/data-for-yolo-v3-kernel\n",
        "!unzip \\*.zip && rm *.zip"
      ],
      "metadata": {
        "id": "4N6EFXSt5qUf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# YOLO options\n",
        "YOLO_TYPE                   = \"yolov3\" # yolov4 or yolov3\n",
        "YOLO_FRAMEWORK              = \"tf\" # \"tf\" or \"trt\"\n",
        "YOLO_V3_WEIGHTS             = \"model_data/yolov3.weights\"\n",
        "YOLO_V4_WEIGHTS             = \"model_data/yolov4.weights\"\n",
        "YOLO_V3_TINY_WEIGHTS        = \"model_data/yolov3-tiny.weights\"\n",
        "YOLO_V4_TINY_WEIGHTS        = \"model_data/yolov4-tiny.weights\"\n",
        "YOLO_TRT_QUANTIZE_MODE      = \"INT8\" # INT8, FP16, FP32\n",
        "YOLO_CUSTOM_WEIGHTS         = False # \"checkpoints/yolov3_custom\" # used in evaluate_mAP.py and custom model detection, if not using leave False\n",
        "                            # YOLO_CUSTOM_WEIGHTS also used with TensorRT and custom model detection\n",
        "YOLO_COCO_CLASSES           = \"model_data/coco/coco.names\"\n",
        "YOLO_STRIDES                = [8, 16, 32]\n",
        "YOLO_IOU_LOSS_THRESH        = 0.5\n",
        "YOLO_ANCHOR_PER_SCALE       = 3\n",
        "YOLO_MAX_BBOX_PER_SCALE     = 100\n",
        "YOLO_INPUT_SIZE             = 416\n",
        "if YOLO_TYPE                == \"yolov4\":\n",
        "    YOLO_ANCHORS            = [[[12,  16], [19,   36], [40,   28]],\n",
        "                               [[36,  75], [76,   55], [72,  146]],\n",
        "                               [[142,110], [192, 243], [459, 401]]]\n",
        "if YOLO_TYPE                == \"yolov3\":\n",
        "    YOLO_ANCHORS            = [[[10,  13], [16,   30], [33,   23]],\n",
        "                               [[30,  61], [62,   45], [59,  119]],\n",
        "                               [[116, 90], [156, 198], [373, 326]]]\n",
        "# Train options\n",
        "TRAIN_YOLO_TINY             = False\n",
        "TRAIN_SAVE_BEST_ONLY        = True # saves only best model according validation loss (True recommended)\n",
        "TRAIN_SAVE_CHECKPOINT       = False # saves all best validated checkpoints in training process (may require a lot disk space) (False recommended)\n",
        "TRAIN_CLASSES               = \"mnist/mnist.names\"\n",
        "TRAIN_ANNOT_PATH            = \"mnist/mnist_train.txt\"\n",
        "TRAIN_LOGDIR                = \"log\"\n",
        "TRAIN_CHECKPOINTS_FOLDER    = \"checkpoints\"\n",
        "TRAIN_MODEL_NAME            = f\"{YOLO_TYPE}_custom\"\n",
        "TRAIN_LOAD_IMAGES_TO_RAM    = True # With True faster training, but need more RAM\n",
        "TRAIN_BATCH_SIZE            = 4\n",
        "TRAIN_INPUT_SIZE            = 416\n",
        "TRAIN_DATA_AUG              = True\n",
        "TRAIN_TRANSFER              = True\n",
        "TRAIN_FROM_CHECKPOINT       = False # \"checkpoints/yolov3_custom\"\n",
        "TRAIN_LR_INIT               = 1e-4\n",
        "TRAIN_LR_END                = 1e-6\n",
        "TRAIN_WARMUP_EPOCHS         = 2\n",
        "TRAIN_EPOCHS                = 100\n",
        "\n",
        "# TEST options\n",
        "TEST_ANNOT_PATH             = \"mnist/mnist_test.txt\"\n",
        "TEST_BATCH_SIZE             = 4\n",
        "TEST_INPUT_SIZE             = 416\n",
        "TEST_DATA_AUG               = False\n",
        "TEST_DECTECTED_IMAGE_PATH   = \"\"\n",
        "TEST_SCORE_THRESHOLD        = 0.3\n",
        "TEST_IOU_THRESHOLD          = 0.45\n",
        "\n",
        "if TRAIN_YOLO_TINY:\n",
        "    YOLO_STRIDES            = [16, 32]    \n",
        "    # YOLO_ANCHORS            = [[[23, 27],  [37, 58],   [81,  82]], # this line can be uncommented for default coco weights\n",
        "    YOLO_ANCHORS            = [[[10, 14],  [23, 27],   [37, 58]],\n",
        "                               [[81,  82], [135, 169], [344, 319]]]"
      ],
      "metadata": {
        "id": "DO6B41A6f_do"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_yolo_weights(model, weights_file):\n",
        "    tf.keras.backend.clear_session() # used to reset layer names\n",
        "    # load Darknet original weights to TensorFlow model\n",
        "    if YOLO_TYPE == \"yolov3\":\n",
        "        range1 = 75 if not TRAIN_YOLO_TINY else 13\n",
        "        range2 = [58, 66, 74] if not TRAIN_YOLO_TINY else [9, 12]\n",
        "    if YOLO_TYPE == \"yolov4\":\n",
        "        range1 = 110 if not TRAIN_YOLO_TINY else 21\n",
        "        range2 = [93, 101, 109] if not TRAIN_YOLO_TINY else [17, 20]\n",
        "    \n",
        "    with open(weights_file, 'rb') as wf:\n",
        "        major, minor, revision, seen, _ = np.fromfile(wf, dtype=np.int32, count=5)\n",
        "\n",
        "        j = 0\n",
        "        for i in range(range1):\n",
        "            if i > 0:\n",
        "                conv_layer_name = 'conv2d_%d' %i\n",
        "            else:\n",
        "                conv_layer_name = 'conv2d'\n",
        "                \n",
        "            if j > 0:\n",
        "                bn_layer_name = 'batch_normalization_%d' %j\n",
        "            else:\n",
        "                bn_layer_name = 'batch_normalization'\n",
        "            \n",
        "            conv_layer = model.get_layer(conv_layer_name)\n",
        "            filters = conv_layer.filters\n",
        "            k_size = conv_layer.kernel_size[0]\n",
        "            in_dim = conv_layer.input_shape[-1]\n",
        "\n",
        "            if i not in range2:\n",
        "                # darknet weights: [beta, gamma, mean, variance]\n",
        "                bn_weights = np.fromfile(wf, dtype=np.float32, count=4 * filters)\n",
        "                # tf weights: [gamma, beta, mean, variance]\n",
        "                bn_weights = bn_weights.reshape((4, filters))[[1, 0, 2, 3]]\n",
        "                bn_layer = model.get_layer(bn_layer_name)\n",
        "                j += 1\n",
        "            else:\n",
        "                conv_bias = np.fromfile(wf, dtype=np.float32, count=filters)\n",
        "\n",
        "            # darknet shape (out_dim, in_dim, height, width)\n",
        "            conv_shape = (filters, in_dim, k_size, k_size)\n",
        "            conv_weights = np.fromfile(wf, dtype=np.float32, count=np.product(conv_shape))\n",
        "            # tf shape (height, width, in_dim, out_dim)\n",
        "            conv_weights = conv_weights.reshape(conv_shape).transpose([2, 3, 1, 0])\n",
        "\n",
        "            if i not in range2:\n",
        "                conv_layer.set_weights([conv_weights])\n",
        "                bn_layer.set_weights(bn_weights)\n",
        "            else:\n",
        "                conv_layer.set_weights([conv_weights, conv_bias])\n",
        "\n",
        "        assert len(wf.read()) == 0, 'failed to read all data'"
      ],
      "metadata": {
        "id": "JgTx03lnfLKz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def Load_Yolo_model():\n",
        "    gpus = tf.config.experimental.list_physical_devices('GPU')\n",
        "    if len(gpus) > 0:\n",
        "        print(f'GPUs {gpus}')\n",
        "        try: tf.config.experimental.set_memory_growth(gpus[0], True)\n",
        "        except RuntimeError: pass\n",
        "        \n",
        "    if YOLO_FRAMEWORK == \"tf\": # TensorFlow detection\n",
        "        if YOLO_TYPE == \"yolov4\":\n",
        "            Darknet_weights = YOLO_V4_TINY_WEIGHTS if TRAIN_YOLO_TINY else YOLO_V4_WEIGHTS\n",
        "        if YOLO_TYPE == \"yolov3\":\n",
        "            Darknet_weights = YOLO_V3_TINY_WEIGHTS if TRAIN_YOLO_TINY else YOLO_V3_WEIGHTS\n",
        "            \n",
        "        if YOLO_CUSTOM_WEIGHTS == False:\n",
        "            print(\"Loading Darknet_weights from:\", Darknet_weights)\n",
        "            yolo = Create_Yolo(input_size=YOLO_INPUT_SIZE, CLASSES=YOLO_COCO_CLASSES)\n",
        "            load_yolo_weights(yolo, Darknet_weights) # use Darknet weights\n",
        "        else:\n",
        "            checkpoint = f\"./checkpoints/{TRAIN_MODEL_NAME}\"\n",
        "            if TRAIN_YOLO_TINY:\n",
        "                checkpoint += \"_Tiny\"\n",
        "            print(\"Loading custom weights from:\", checkpoint)\n",
        "            yolo = Create_Yolo(input_size=YOLO_INPUT_SIZE, CLASSES=TRAIN_CLASSES)\n",
        "            yolo.load_weights(checkpoint)  # use custom weights\n",
        "        \n",
        "    elif YOLO_FRAMEWORK == \"trt\": # TensorRT detection\n",
        "        saved_model_loaded = tf.saved_model.load(YOLO_CUSTOM_WEIGHTS, tags=[tag_constants.SERVING])\n",
        "        signature_keys = list(saved_model_loaded.signatures.keys())\n",
        "        yolo = saved_model_loaded.signatures['serving_default']\n",
        "\n",
        "    return yolo"
      ],
      "metadata": {
        "id": "n7EdmRXbfLIX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def image_preprocess(image, target_size, gt_boxes=None):\n",
        "    ih, iw    = target_size\n",
        "    h,  w, _  = image.shape\n",
        "\n",
        "    scale = min(iw/w, ih/h)\n",
        "    nw, nh  = int(scale * w), int(scale * h)\n",
        "    image_resized = cv2.resize(image, (nw, nh))\n",
        "\n",
        "    image_paded = np.full(shape=[ih, iw, 3], fill_value=128.0)\n",
        "    dw, dh = (iw - nw) // 2, (ih-nh) // 2\n",
        "    image_paded[dh:nh+dh, dw:nw+dw, :] = image_resized\n",
        "    image_paded = image_paded / 255.\n",
        "\n",
        "    if gt_boxes is None:\n",
        "        return image_paded\n",
        "\n",
        "    else:\n",
        "        gt_boxes[:, [0, 2]] = gt_boxes[:, [0, 2]] * scale + dw\n",
        "        gt_boxes[:, [1, 3]] = gt_boxes[:, [1, 3]] * scale + dh\n",
        "        return image_paded, gt_boxes"
      ],
      "metadata": {
        "id": "obhVCkzWfRtW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def draw_bbox(image, bboxes, CLASSES=YOLO_COCO_CLASSES, show_label=True, show_confidence = True, Text_colors=(255,255,0), rectangle_colors='', tracking=False):   \n",
        "    NUM_CLASS = read_class_names(CLASSES)\n",
        "    num_classes = len(NUM_CLASS)\n",
        "    image_h, image_w, _ = image.shape\n",
        "    hsv_tuples = [(1.0 * x / num_classes, 1., 1.) for x in range(num_classes)]\n",
        "    #print(\"hsv_tuples\", hsv_tuples)\n",
        "    colors = list(map(lambda x: colorsys.hsv_to_rgb(*x), hsv_tuples))\n",
        "    colors = list(map(lambda x: (int(x[0] * 255), int(x[1] * 255), int(x[2] * 255)), colors))\n",
        "\n",
        "    random.seed(0)\n",
        "    random.shuffle(colors)\n",
        "    random.seed(None)\n",
        "\n",
        "    for i, bbox in enumerate(bboxes):\n",
        "        coor = np.array(bbox[:4], dtype=np.int32)\n",
        "        score = bbox[4]\n",
        "        class_ind = int(bbox[5])\n",
        "        bbox_color = rectangle_colors if rectangle_colors != '' else colors[class_ind]\n",
        "        bbox_thick = int(0.6 * (image_h + image_w) / 1000)\n",
        "        if bbox_thick < 1: bbox_thick = 1\n",
        "        fontScale = 0.75 * bbox_thick\n",
        "        (x1, y1), (x2, y2) = (coor[0], coor[1]), (coor[2], coor[3])\n",
        "\n",
        "        # put object rectangle\n",
        "        cv2.rectangle(image, (x1, y1), (x2, y2), bbox_color, bbox_thick*2)\n",
        "\n",
        "        if show_label:\n",
        "            # get text label\n",
        "            score_str = \" {:.2f}\".format(score) if show_confidence else \"\"\n",
        "\n",
        "            if tracking: score_str = \" \"+str(score)\n",
        "\n",
        "            try:\n",
        "                label = \"{}\".format(NUM_CLASS[class_ind]) + score_str\n",
        "            except KeyError:\n",
        "                print(\"You received KeyError, this might be that you are trying to use yolo original weights\")\n",
        "                print(\"while using custom classes, if using custom model in configs.py set YOLO_CUSTOM_WEIGHTS = True\")\n",
        "\n",
        "            # get text size\n",
        "            (text_width, text_height), baseline = cv2.getTextSize(label, cv2.FONT_HERSHEY_COMPLEX_SMALL,\n",
        "                                                                  fontScale, thickness=bbox_thick)\n",
        "            # put filled text rectangle\n",
        "            cv2.rectangle(image, (x1, y1), (x1 + text_width, y1 - text_height - baseline), bbox_color, thickness=cv2.FILLED)\n",
        "\n",
        "            # put text above rectangle\n",
        "            cv2.putText(image, label, (x1, y1-4), cv2.FONT_HERSHEY_COMPLEX_SMALL,\n",
        "                        fontScale, Text_colors, bbox_thick, lineType=cv2.LINE_AA)\n",
        "\n",
        "    return image\n",
        "\n",
        "\n",
        "def bboxes_iou(boxes1, boxes2):\n",
        "    boxes1 = np.array(boxes1)\n",
        "    boxes2 = np.array(boxes2)\n",
        "\n",
        "    boxes1_area = (boxes1[..., 2] - boxes1[..., 0]) * (boxes1[..., 3] - boxes1[..., 1])\n",
        "    boxes2_area = (boxes2[..., 2] - boxes2[..., 0]) * (boxes2[..., 3] - boxes2[..., 1])\n",
        "\n",
        "    left_up       = np.maximum(boxes1[..., :2], boxes2[..., :2])\n",
        "    right_down    = np.minimum(boxes1[..., 2:], boxes2[..., 2:])\n",
        "\n",
        "    inter_section = np.maximum(right_down - left_up, 0.0)\n",
        "    inter_area    = inter_section[..., 0] * inter_section[..., 1]\n",
        "    union_area    = boxes1_area + boxes2_area - inter_area\n",
        "    ious          = np.maximum(1.0 * inter_area / union_area, np.finfo(np.float32).eps)\n",
        "\n",
        "    return ious\n",
        "\n",
        "\n",
        "def nms(bboxes, iou_threshold, sigma=0.3, method='nms'):\n",
        "    \"\"\"\n",
        "    :param bboxes: (xmin, ymin, xmax, ymax, score, class)\n",
        "    Note: soft-nms, https://arxiv.org/pdf/1704.04503.pdf\n",
        "          https://github.com/bharatsingh430/soft-nms\n",
        "    \"\"\"\n",
        "    classes_in_img = list(set(bboxes[:, 5]))\n",
        "    best_bboxes = []\n",
        "\n",
        "    for cls in classes_in_img:\n",
        "        cls_mask = (bboxes[:, 5] == cls)\n",
        "        cls_bboxes = bboxes[cls_mask]\n",
        "        # Process 1: Determine whether the number of bounding boxes is greater than 0 \n",
        "        while len(cls_bboxes) > 0:\n",
        "            # Process 2: Select the bounding box with the highest score according to socre order A\n",
        "            max_ind = np.argmax(cls_bboxes[:, 4])\n",
        "            best_bbox = cls_bboxes[max_ind]\n",
        "            best_bboxes.append(best_bbox)\n",
        "            cls_bboxes = np.concatenate([cls_bboxes[: max_ind], cls_bboxes[max_ind + 1:]])\n",
        "            # Process 3: Calculate this bounding box A and\n",
        "            # Remain all iou of the bounding box and remove those bounding boxes whose iou value is higher than the threshold \n",
        "            iou = bboxes_iou(best_bbox[np.newaxis, :4], cls_bboxes[:, :4])\n",
        "            weight = np.ones((len(iou),), dtype=np.float32)\n",
        "\n",
        "            assert method in ['nms', 'soft-nms']\n",
        "\n",
        "            if method == 'nms':\n",
        "                iou_mask = iou > iou_threshold\n",
        "                weight[iou_mask] = 0.0\n",
        "\n",
        "            if method == 'soft-nms':\n",
        "                weight = np.exp(-(1.0 * iou ** 2 / sigma))\n",
        "\n",
        "            cls_bboxes[:, 4] = cls_bboxes[:, 4] * weight\n",
        "            score_mask = cls_bboxes[:, 4] > 0.\n",
        "            cls_bboxes = cls_bboxes[score_mask]\n",
        "\n",
        "    return best_bboxes"
      ],
      "metadata": {
        "id": "ed3Kq1oHfRpM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def postprocess_boxes(pred_bbox, original_image, input_size, score_threshold):\n",
        "    valid_scale=[0, np.inf]\n",
        "    pred_bbox = np.array(pred_bbox)\n",
        "\n",
        "    pred_xywh = pred_bbox[:, 0:4]\n",
        "    pred_conf = pred_bbox[:, 4]\n",
        "    pred_prob = pred_bbox[:, 5:]\n",
        "\n",
        "    # 1. (x, y, w, h) --> (xmin, ymin, xmax, ymax)\n",
        "    pred_coor = np.concatenate([pred_xywh[:, :2] - pred_xywh[:, 2:] * 0.5,\n",
        "                                pred_xywh[:, :2] + pred_xywh[:, 2:] * 0.5], axis=-1)\n",
        "    # 2. (xmin, ymin, xmax, ymax) -> (xmin_org, ymin_org, xmax_org, ymax_org)\n",
        "    org_h, org_w = original_image.shape[:2]\n",
        "    resize_ratio = min(input_size / org_w, input_size / org_h)\n",
        "\n",
        "    dw = (input_size - resize_ratio * org_w) / 2\n",
        "    dh = (input_size - resize_ratio * org_h) / 2\n",
        "\n",
        "    pred_coor[:, 0::2] = 1.0 * (pred_coor[:, 0::2] - dw) / resize_ratio\n",
        "    pred_coor[:, 1::2] = 1.0 * (pred_coor[:, 1::2] - dh) / resize_ratio\n",
        "\n",
        "    # 3. clip some boxes those are out of range\n",
        "    pred_coor = np.concatenate([np.maximum(pred_coor[:, :2], [0, 0]),\n",
        "                                np.minimum(pred_coor[:, 2:], [org_w - 1, org_h - 1])], axis=-1)\n",
        "    invalid_mask = np.logical_or((pred_coor[:, 0] > pred_coor[:, 2]), (pred_coor[:, 1] > pred_coor[:, 3]))\n",
        "    pred_coor[invalid_mask] = 0\n",
        "\n",
        "    # 4. discard some invalid boxes\n",
        "    bboxes_scale = np.sqrt(np.multiply.reduce(pred_coor[:, 2:4] - pred_coor[:, 0:2], axis=-1))\n",
        "    scale_mask = np.logical_and((valid_scale[0] < bboxes_scale), (bboxes_scale < valid_scale[1]))\n",
        "\n",
        "    # 5. discard boxes with low scores\n",
        "    classes = np.argmax(pred_prob, axis=-1)\n",
        "    scores = pred_conf * pred_prob[np.arange(len(pred_coor)), classes]\n",
        "    score_mask = scores > score_threshold\n",
        "    mask = np.logical_and(scale_mask, score_mask)\n",
        "    coors, scores, classes = pred_coor[mask], scores[mask], classes[mask]\n",
        "\n",
        "    return np.concatenate([coors, scores[:, np.newaxis], classes[:, np.newaxis]], axis=-1)\n",
        "\n",
        "\n",
        "def detect_image(Yolo, image_path, output_path, input_size=416, show=False, CLASSES=YOLO_COCO_CLASSES, score_threshold=0.3, iou_threshold=0.45, rectangle_colors=''):\n",
        "    original_image      = cv2.imread(image_path)\n",
        "    original_image      = cv2.cvtColor(original_image, cv2.COLOR_BGR2RGB)\n",
        "    original_image      = cv2.cvtColor(original_image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    image_data = image_preprocess(np.copy(original_image), [input_size, input_size])\n",
        "    image_data = image_data[np.newaxis, ...].astype(np.float32)\n",
        "\n",
        "    if YOLO_FRAMEWORK == \"tf\":\n",
        "        pred_bbox = Yolo.predict(image_data)\n",
        "    elif YOLO_FRAMEWORK == \"trt\":\n",
        "        batched_input = tf.constant(image_data)\n",
        "        result = Yolo(batched_input)\n",
        "        pred_bbox = []\n",
        "        for key, value in result.items():\n",
        "            value = value.numpy()\n",
        "            pred_bbox.append(value)\n",
        "        \n",
        "    pred_bbox = [tf.reshape(x, (-1, tf.shape(x)[-1])) for x in pred_bbox]\n",
        "    pred_bbox = tf.concat(pred_bbox, axis=0)\n",
        "    \n",
        "    bboxes = postprocess_boxes(pred_bbox, original_image, input_size, score_threshold)\n",
        "    bboxes = nms(bboxes, iou_threshold, method='nms')\n",
        "\n",
        "    image = draw_bbox(original_image, bboxes, CLASSES=CLASSES, rectangle_colors=rectangle_colors)\n",
        "    # CreateXMLfile(\"XML_Detections\", str(int(time.time())), original_image, bboxes, read_class_names(CLASSES))\n",
        "\n",
        "    if output_path != '': cv2.imwrite(output_path, image)\n",
        "    if show:\n",
        "        # Show the image\n",
        "        cv2.imshow(\"predicted image\", image)\n",
        "        # Load and hold the image\n",
        "        cv2.waitKey(0)\n",
        "        # To close the window after the required kill value was provided\n",
        "        cv2.destroyAllWindows()\n",
        "        \n",
        "    return image\n"
      ],
      "metadata": {
        "id": "23f3eFR1fRlI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def Predict_bbox_mp(Frames_data, Predicted_data, Processing_times):\n",
        "    gpus = tf.config.experimental.list_physical_devices('GPU')\n",
        "    if len(gpus) > 0:\n",
        "        try: tf.config.experimental.set_memory_growth(gpus[0], True)\n",
        "        except RuntimeError: print(\"RuntimeError in tf.config.experimental.list_physical_devices('GPU')\")\n",
        "    Yolo = Load_Yolo_model()\n",
        "    times = []\n",
        "    while True:\n",
        "        if Frames_data.qsize()>0:\n",
        "            image_data = Frames_data.get()\n",
        "            t1 = time.time()\n",
        "            Processing_times.put(time.time())\n",
        "            \n",
        "            if YOLO_FRAMEWORK == \"tf\":\n",
        "                pred_bbox = Yolo.predict(image_data)\n",
        "            elif YOLO_FRAMEWORK == \"trt\":\n",
        "                batched_input = tf.constant(image_data)\n",
        "                result = Yolo(batched_input)\n",
        "                pred_bbox = []\n",
        "                for key, value in result.items():\n",
        "                    value = value.numpy()\n",
        "                    pred_bbox.append(value)\n",
        "\n",
        "            pred_bbox = [tf.reshape(x, (-1, tf.shape(x)[-1])) for x in pred_bbox]\n",
        "            pred_bbox = tf.concat(pred_bbox, axis=0)\n",
        "            \n",
        "            Predicted_data.put(pred_bbox)\n",
        "\n",
        "\n",
        "def postprocess_mp(Predicted_data, original_frames, Processed_frames, Processing_times, input_size, CLASSES, score_threshold, iou_threshold, rectangle_colors, realtime):\n",
        "    times = []\n",
        "    while True:\n",
        "        if Predicted_data.qsize()>0:\n",
        "            pred_bbox = Predicted_data.get()\n",
        "            if realtime:\n",
        "                while original_frames.qsize() > 1:\n",
        "                    original_image = original_frames.get()\n",
        "            else:\n",
        "                original_image = original_frames.get()\n",
        "            \n",
        "            bboxes = postprocess_boxes(pred_bbox, original_image, input_size, score_threshold)\n",
        "            bboxes = nms(bboxes, iou_threshold, method='nms')\n",
        "            image = draw_bbox(original_image, bboxes, CLASSES=CLASSES, rectangle_colors=rectangle_colors)\n",
        "            times.append(time.time()-Processing_times.get())\n",
        "            times = times[-20:]\n",
        "            \n",
        "            ms = sum(times)/len(times)*1000\n",
        "            fps = 1000 / ms\n",
        "            image = cv2.putText(image, \"Time: {:.1f}FPS\".format(fps), (0, 30), cv2.FONT_HERSHEY_COMPLEX_SMALL, 1, (0, 0, 255), 2)\n",
        "            #print(\"Time: {:.2f}ms, Final FPS: {:.1f}\".format(ms, fps))\n",
        "            \n",
        "            Processed_frames.put(image)\n",
        "\n",
        "def Show_Image_mp(Processed_frames, show, Final_frames):\n",
        "    while True:\n",
        "        if Processed_frames.qsize()>0:\n",
        "            image = Processed_frames.get()\n",
        "            Final_frames.put(image)\n",
        "            if show:\n",
        "                cv2.imshow('output', image)\n",
        "                if cv2.waitKey(25) & 0xFF == ord(\"q\"):\n",
        "                    cv2.destroyAllWindows()\n",
        "                    break\n"
      ],
      "metadata": {
        "id": "6C67XQ8dfLD_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# detect from webcam\n",
        "def detect_video_realtime_mp(video_path, output_path, input_size=416, show=False, CLASSES=YOLO_COCO_CLASSES, score_threshold=0.3, iou_threshold=0.45, rectangle_colors='', realtime=False):\n",
        "    if realtime:\n",
        "        vid = cv2.VideoCapture(0)\n",
        "    else:\n",
        "        vid = cv2.VideoCapture(video_path)\n",
        "\n",
        "    # by default VideoCapture returns float instead of int\n",
        "    width = int(vid.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "    height = int(vid.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "    fps = int(vid.get(cv2.CAP_PROP_FPS))\n",
        "    codec = cv2.VideoWriter_fourcc(*'XVID')\n",
        "    out = cv2.VideoWriter(output_path, codec, fps, (width, height)) # output_path must be .mp4\n",
        "    no_of_frames = int(vid.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "\n",
        "    original_frames = Queue()\n",
        "    Frames_data = Queue()\n",
        "    Predicted_data = Queue()\n",
        "    Processed_frames = Queue()\n",
        "    Processing_times = Queue()\n",
        "    Final_frames = Queue()\n",
        "    \n",
        "    p1 = Process(target=Predict_bbox_mp, args=(Frames_data, Predicted_data, Processing_times))\n",
        "    p2 = Process(target=postprocess_mp, args=(Predicted_data, original_frames, Processed_frames, Processing_times, input_size, CLASSES, score_threshold, iou_threshold, rectangle_colors, realtime))\n",
        "    p3 = Process(target=Show_Image_mp, args=(Processed_frames, show, Final_frames))\n",
        "    p1.start()\n",
        "    p2.start()\n",
        "    p3.start()\n",
        "        \n",
        "    while True:\n",
        "        ret, img = vid.read()\n",
        "        if not ret:\n",
        "            break\n",
        "\n",
        "        original_image = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "        original_image = cv2.cvtColor(original_image, cv2.COLOR_BGR2RGB)\n",
        "        original_frames.put(original_image)\n",
        "\n",
        "        image_data = image_preprocess(np.copy(original_image), [input_size, input_size])\n",
        "        image_data = image_data[np.newaxis, ...].astype(np.float32)\n",
        "        Frames_data.put(image_data)\n",
        "        \n",
        "    while True:\n",
        "        if original_frames.qsize() == 0 and Frames_data.qsize() == 0 and Predicted_data.qsize() == 0  and Processed_frames.qsize() == 0  and Processing_times.qsize() == 0 and Final_frames.qsize() == 0:\n",
        "            p1.terminate()\n",
        "            p2.terminate()\n",
        "            p3.terminate()\n",
        "            break\n",
        "        elif Final_frames.qsize()>0:\n",
        "            image = Final_frames.get()\n",
        "            if output_path != '': out.write(image)\n",
        "\n",
        "    cv2.destroyAllWindows()\n",
        "\n",
        "def detect_video(Yolo, video_path, output_path, input_size=416, show=False, CLASSES=YOLO_COCO_CLASSES, score_threshold=0.3, iou_threshold=0.45, rectangle_colors=''):\n",
        "    times, times_2 = [], []\n",
        "    vid = cv2.VideoCapture(video_path)\n",
        "\n",
        "    # by default VideoCapture returns float instead of int\n",
        "    width = int(vid.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "    height = int(vid.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "    fps = int(vid.get(cv2.CAP_PROP_FPS))\n",
        "    codec = cv2.VideoWriter_fourcc(*'XVID')\n",
        "    out = cv2.VideoWriter(output_path, codec, fps, (width, height)) # output_path must be .mp4\n",
        "\n",
        "    while True:\n",
        "        _, img = vid.read()\n",
        "\n",
        "        try:\n",
        "            original_image = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "            original_image = cv2.cvtColor(original_image, cv2.COLOR_BGR2RGB)\n",
        "        except:\n",
        "            break\n",
        "\n",
        "        image_data = image_preprocess(np.copy(original_image), [input_size, input_size])\n",
        "        image_data = image_data[np.newaxis, ...].astype(np.float32)\n",
        "\n",
        "        t1 = time.time()\n",
        "        if YOLO_FRAMEWORK == \"tf\":\n",
        "            pred_bbox = Yolo.predict(image_data)\n",
        "        elif YOLO_FRAMEWORK == \"trt\":\n",
        "            batched_input = tf.constant(image_data)\n",
        "            result = Yolo(batched_input)\n",
        "            pred_bbox = []\n",
        "            for key, value in result.items():\n",
        "                value = value.numpy()\n",
        "                pred_bbox.append(value)\n",
        "        \n",
        "        t2 = time.time()\n",
        "        \n",
        "        pred_bbox = [tf.reshape(x, (-1, tf.shape(x)[-1])) for x in pred_bbox]\n",
        "        pred_bbox = tf.concat(pred_bbox, axis=0)\n",
        "\n",
        "        bboxes = postprocess_boxes(pred_bbox, original_image, input_size, score_threshold)\n",
        "        bboxes = nms(bboxes, iou_threshold, method='nms')\n",
        "        \n",
        "        image = draw_bbox(original_image, bboxes, CLASSES=CLASSES, rectangle_colors=rectangle_colors)\n",
        "\n",
        "        t3 = time.time()\n",
        "        times.append(t2-t1)\n",
        "        times_2.append(t3-t1)\n",
        "        \n",
        "        times = times[-20:]\n",
        "        times_2 = times_2[-20:]\n",
        "\n",
        "        ms = sum(times)/len(times)*1000\n",
        "        fps = 1000 / ms\n",
        "        fps2 = 1000 / (sum(times_2)/len(times_2)*1000)\n",
        "        \n",
        "        image = cv2.putText(image, \"Time: {:.1f}FPS\".format(fps), (0, 30), cv2.FONT_HERSHEY_COMPLEX_SMALL, 1, (0, 0, 255), 2)\n",
        "        # CreateXMLfile(\"XML_Detections\", str(int(time.time())), original_image, bboxes, read_class_names(CLASSES))\n",
        "        \n",
        "        print(\"Time: {:.2f}ms, Detection FPS: {:.1f}, total FPS: {:.1f}\".format(ms, fps, fps2))\n",
        "        if output_path != '': out.write(image)\n",
        "        if show:\n",
        "            cv2.imshow('output', image)\n",
        "            if cv2.waitKey(25) & 0xFF == ord(\"q\"):\n",
        "                cv2.destroyAllWindows()\n",
        "                break\n",
        "\n",
        "    cv2.destroyAllWindows()\n",
        "\n",
        "# detect from webcam\n",
        "def detect_realtime(Yolo, output_path, input_size=416, show=False, CLASSES=YOLO_COCO_CLASSES, score_threshold=0.3, iou_threshold=0.45, rectangle_colors=''):\n",
        "    times = []\n",
        "    vid = cv2.VideoCapture(0)\n",
        "\n",
        "    # by default VideoCapture returns float instead of int\n",
        "    width = int(vid.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "    height = int(vid.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "    fps = int(vid.get(cv2.CAP_PROP_FPS))\n",
        "    codec = cv2.VideoWriter_fourcc(*'XVID')\n",
        "    out = cv2.VideoWriter(output_path, codec, fps, (width, height)) # output_path must be .mp4\n",
        "\n",
        "    while True:\n",
        "        _, frame = vid.read()\n",
        "\n",
        "        try:\n",
        "            original_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "            original_frame = cv2.cvtColor(original_frame, cv2.COLOR_BGR2RGB)\n",
        "        except:\n",
        "            break\n",
        "        image_data = image_preprocess(np.copy(original_frame), [input_size, input_size])\n",
        "        image_data = image_data[np.newaxis, ...].astype(np.float32)\n",
        "\n",
        "        t1 = time.time()\n",
        "        if YOLO_FRAMEWORK == \"tf\":\n",
        "            pred_bbox = Yolo.predict(image_data)\n",
        "        elif YOLO_FRAMEWORK == \"trt\":\n",
        "            batched_input = tf.constant(image_data)\n",
        "            result = Yolo(batched_input)\n",
        "            pred_bbox = []\n",
        "            for key, value in result.items():\n",
        "                value = value.numpy()\n",
        "                pred_bbox.append(value)\n",
        "        \n",
        "        t2 = time.time()\n",
        "        \n",
        "        pred_bbox = [tf.reshape(x, (-1, tf.shape(x)[-1])) for x in pred_bbox]\n",
        "        pred_bbox = tf.concat(pred_bbox, axis=0)\n",
        "\n",
        "        bboxes = postprocess_boxes(pred_bbox, original_frame, input_size, score_threshold)\n",
        "        bboxes = nms(bboxes, iou_threshold, method='nms')\n",
        "        \n",
        "        times.append(t2-t1)\n",
        "        times = times[-20:]\n",
        "        \n",
        "        ms = sum(times)/len(times)*1000\n",
        "        fps = 1000 / ms\n",
        "        \n",
        "        print(\"Time: {:.2f}ms, {:.1f} FPS\".format(ms, fps))\n",
        "\n",
        "        frame = draw_bbox(original_frame, bboxes, CLASSES=CLASSES, rectangle_colors=rectangle_colors)\n",
        "        # CreateXMLfile(\"XML_Detections\", str(int(time.time())), original_frame, bboxes, read_class_names(CLASSES))\n",
        "        image = cv2.putText(frame, \"Time: {:.1f}FPS\".format(fps), (0, 30),\n",
        "                          cv2.FONT_HERSHEY_COMPLEX_SMALL, 1, (0, 0, 255), 2)\n",
        "\n",
        "        if output_path != '': out.write(frame)\n",
        "        if show:\n",
        "            cv2.imshow('output', frame)\n",
        "            if cv2.waitKey(25) & 0xFF == ord(\"q\"):\n",
        "                cv2.destroyAllWindows()\n",
        "                break\n",
        "\n",
        "    cv2.destroyAllWindows()"
      ],
      "metadata": {
        "id": "GRxcSSQkfhxh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Dataset"
      ],
      "metadata": {
        "id": "3fWZKB4AfnZZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Dataset(object):\n",
        "    # Dataset preprocess implementation\n",
        "    def __init__(self, dataset_type, TEST_INPUT_SIZE=TEST_INPUT_SIZE):\n",
        "        self.annot_path  = TRAIN_ANNOT_PATH if dataset_type == 'train' else TEST_ANNOT_PATH\n",
        "        self.input_sizes = TRAIN_INPUT_SIZE if dataset_type == 'train' else TEST_INPUT_SIZE\n",
        "        self.batch_size  = TRAIN_BATCH_SIZE if dataset_type == 'train' else TEST_BATCH_SIZE\n",
        "        self.data_aug    = TRAIN_DATA_AUG   if dataset_type == 'train' else TEST_DATA_AUG\n",
        "\n",
        "        self.train_yolo_tiny = TRAIN_YOLO_TINY\n",
        "        self.train_input_sizes = TRAIN_INPUT_SIZE\n",
        "        self.strides = np.array(YOLO_STRIDES)\n",
        "        self.classes = read_class_names(TRAIN_CLASSES)\n",
        "        self.num_classes = len(self.classes)\n",
        "        self.anchors = (np.array(YOLO_ANCHORS).T/self.strides).T\n",
        "        self.anchor_per_scale = YOLO_ANCHOR_PER_SCALE\n",
        "        self.max_bbox_per_scale = YOLO_MAX_BBOX_PER_SCALE\n",
        "\n",
        "        self.annotations = self.load_annotations(dataset_type)\n",
        "        self.num_samples = len(self.annotations)\n",
        "        self.num_batchs = int(np.ceil(self.num_samples / self.batch_size))\n",
        "        self.batch_count = 0\n",
        "\n",
        "\n",
        "    def load_annotations(self, dataset_type):\n",
        "        final_annotations = []\n",
        "        with open(self.annot_path, 'r') as f:\n",
        "            txt = f.read().splitlines()\n",
        "            annotations = [line.strip() for line in txt if len(line.strip().split()[1:]) != 0]\n",
        "        np.random.shuffle(annotations)\n",
        "\n",
        "        # for annotation in annotations:\n",
        "        #     image_extension = '.jpg'\n",
        "        #     extension_index = annotation.find(image_extension)\n",
        "        #     image_path = annotation[:extension_index+len(image_extension)]\n",
        "        #     line = annotation[extension_index+len(image_extension):].split()\n",
        "        #     if not os.path.exists(image_path):\n",
        "        #         raise KeyError(\"%s does not exist ... \" %image_path)\n",
        "        #     if TRAIN_LOAD_IMAGES_TO_RAM:\n",
        "        #         image = cv2.imread(image_path)\n",
        "        #     else:\n",
        "        #         image = ''\n",
        "        #     final_annotations.append([image_path, line, image])\n",
        "        # return final_annotations\n",
        "        for annotation in annotations:\n",
        "            # fully parse annotations\n",
        "            line = annotation.split()\n",
        "            image_path, index = \"\", 1\n",
        "            for i, one_line in enumerate(line):\n",
        "                if not one_line.replace(\",\",\"\").isnumeric():\n",
        "                    if image_path != \"\": image_path += \" \"\n",
        "                    image_path += one_line\n",
        "                else:\n",
        "                    index = i\n",
        "                    break\n",
        "            if not os.path.exists(image_path):\n",
        "                raise KeyError(\"%s does not exist ... \" %image_path)\n",
        "            if TRAIN_LOAD_IMAGES_TO_RAM:\n",
        "                image = cv2.imread(image_path)\n",
        "            else:\n",
        "                image = ''\n",
        "            final_annotations.append([image_path, line[index:], image])\n",
        "        return final_annotations\n",
        "\n",
        "    def __iter__(self):\n",
        "        return self\n",
        "\n",
        "    def Delete_bad_annotation(self, bad_annotation):\n",
        "        print(f'Deleting {bad_annotation} annotation line')\n",
        "        bad_image_path = bad_annotation[0]\n",
        "        bad_image_name = bad_annotation[0].split('/')[-1] # can be used to delete bad image\n",
        "        bad_xml_path = bad_annotation[0][:-3]+'xml' # can be used to delete bad xml file\n",
        "\n",
        "        # remove bad annotation line from annotation file\n",
        "        with open(self.annot_path, \"r+\") as f:\n",
        "            d = f.readlines()\n",
        "            f.seek(0)\n",
        "            for i in d:\n",
        "                if bad_image_name not in i:\n",
        "                    f.write(i)\n",
        "            f.truncate()\n",
        "\n",
        "    def __next__(self):\n",
        "        with tf.device('/cpu:0'):\n",
        "            self.train_input_size = random.choice([self.train_input_sizes])\n",
        "            self.train_output_sizes = self.train_input_size // self.strides\n",
        "\n",
        "            batch_image = np.zeros((self.batch_size, self.train_input_size, self.train_input_size, 3), dtype=np.float32)\n",
        "\n",
        "            if self.train_yolo_tiny:\n",
        "                batch_label_mbbox = np.zeros((self.batch_size, self.train_output_sizes[0], self.train_output_sizes[0], self.anchor_per_scale, 5 + self.num_classes), dtype=np.float32)\n",
        "                batch_label_lbbox = np.zeros((self.batch_size, self.train_output_sizes[1], self.train_output_sizes[1], self.anchor_per_scale, 5 + self.num_classes), dtype=np.float32)\n",
        "            else:\n",
        "                batch_label_sbbox = np.zeros((self.batch_size, self.train_output_sizes[0], self.train_output_sizes[0], self.anchor_per_scale, 5 + self.num_classes), dtype=np.float32)\n",
        "                batch_label_mbbox = np.zeros((self.batch_size, self.train_output_sizes[1], self.train_output_sizes[1], self.anchor_per_scale, 5 + self.num_classes), dtype=np.float32)\n",
        "                batch_label_lbbox = np.zeros((self.batch_size, self.train_output_sizes[2], self.train_output_sizes[2], self.anchor_per_scale, 5 + self.num_classes), dtype=np.float32)\n",
        "\n",
        "                batch_sbboxes = np.zeros((self.batch_size, self.max_bbox_per_scale, 4), dtype=np.float32)\n",
        "\n",
        "            batch_mbboxes = np.zeros((self.batch_size, self.max_bbox_per_scale, 4), dtype=np.float32)\n",
        "            batch_lbboxes = np.zeros((self.batch_size, self.max_bbox_per_scale, 4), dtype=np.float32)\n",
        "\n",
        "            exceptions = False\n",
        "            num = 0\n",
        "            if self.batch_count < self.num_batchs:\n",
        "                while num < self.batch_size:\n",
        "                    index = self.batch_count * self.batch_size + num\n",
        "                    if index >= self.num_samples: index -= self.num_samples\n",
        "                    annotation = self.annotations[index]\n",
        "                    image, bboxes = self.parse_annotation(annotation)\n",
        "                    try:\n",
        "                        if self.train_yolo_tiny:\n",
        "                            label_mbbox, label_lbbox, mbboxes, lbboxes = self.preprocess_true_boxes(bboxes)\n",
        "                        else:\n",
        "                            label_sbbox, label_mbbox, label_lbbox, sbboxes, mbboxes, lbboxes = self.preprocess_true_boxes(bboxes)\n",
        "                    except IndexError:\n",
        "                        exceptions = True\n",
        "                        self.Delete_bad_annotation(annotation)\n",
        "                        print(\"IndexError, something wrong with\", annotation[0], \"removed this line from annotation file\")\n",
        "\n",
        "                    batch_image[num, :, :, :] = image\n",
        "                    batch_label_mbbox[num, :, :, :, :] = label_mbbox\n",
        "                    batch_label_lbbox[num, :, :, :, :] = label_lbbox\n",
        "                    batch_mbboxes[num, :, :] = mbboxes\n",
        "                    batch_lbboxes[num, :, :] = lbboxes\n",
        "                    if not self.train_yolo_tiny:\n",
        "                        batch_label_sbbox[num, :, :, :, :] = label_sbbox\n",
        "                        batch_sbboxes[num, :, :] = sbboxes\n",
        "\n",
        "                    num += 1\n",
        "\n",
        "                if exceptions:\n",
        "                    print('\\n')\n",
        "                    raise Exception(\"There were problems with dataset, I fixed them, now restart the training process.\")\n",
        "                self.batch_count += 1\n",
        "                if not self.train_yolo_tiny:\n",
        "                    batch_smaller_target = batch_label_sbbox, batch_sbboxes\n",
        "                batch_medium_target  = batch_label_mbbox, batch_mbboxes\n",
        "                batch_larger_target  = batch_label_lbbox, batch_lbboxes\n",
        "\n",
        "                if self.train_yolo_tiny:\n",
        "                    return batch_image, (batch_medium_target, batch_larger_target)\n",
        "                return batch_image, (batch_smaller_target, batch_medium_target, batch_larger_target)\n",
        "            else:\n",
        "                self.batch_count = 0\n",
        "                np.random.shuffle(self.annotations)\n",
        "                raise StopIteration\n",
        "\n",
        "    def random_horizontal_flip(self, image, bboxes):\n",
        "        if random.random() < 0.5:\n",
        "            _, w, _ = image.shape\n",
        "            image = image[:, ::-1, :]\n",
        "            bboxes[:, [0,2]] = w - bboxes[:, [2,0]]\n",
        "\n",
        "        return image, bboxes\n",
        "\n",
        "    def random_crop(self, image, bboxes):\n",
        "        if random.random() < 0.5:\n",
        "            h, w, _ = image.shape\n",
        "            max_bbox = np.concatenate([np.min(bboxes[:, 0:2], axis=0), np.max(bboxes[:, 2:4], axis=0)], axis=-1)\n",
        "\n",
        "            max_l_trans = max_bbox[0]\n",
        "            max_u_trans = max_bbox[1]\n",
        "            max_r_trans = w - max_bbox[2]\n",
        "            max_d_trans = h - max_bbox[3]\n",
        "\n",
        "            crop_xmin = max(0, int(max_bbox[0] - random.uniform(0, max_l_trans)))\n",
        "            crop_ymin = max(0, int(max_bbox[1] - random.uniform(0, max_u_trans)))\n",
        "            crop_xmax = max(w, int(max_bbox[2] + random.uniform(0, max_r_trans)))\n",
        "            crop_ymax = max(h, int(max_bbox[3] + random.uniform(0, max_d_trans)))\n",
        "\n",
        "            image = image[crop_ymin : crop_ymax, crop_xmin : crop_xmax]\n",
        "\n",
        "            bboxes[:, [0, 2]] = bboxes[:, [0, 2]] - crop_xmin\n",
        "            bboxes[:, [1, 3]] = bboxes[:, [1, 3]] - crop_ymin\n",
        "\n",
        "        return image, bboxes\n",
        "\n",
        "    def random_translate(self, image, bboxes):\n",
        "        if random.random() < 0.5:\n",
        "            h, w, _ = image.shape\n",
        "            max_bbox = np.concatenate([np.min(bboxes[:, 0:2], axis=0), np.max(bboxes[:, 2:4], axis=0)], axis=-1)\n",
        "\n",
        "            max_l_trans = max_bbox[0]\n",
        "            max_u_trans = max_bbox[1]\n",
        "            max_r_trans = w - max_bbox[2]\n",
        "            max_d_trans = h - max_bbox[3]\n",
        "\n",
        "            tx = random.uniform(-(max_l_trans - 1), (max_r_trans - 1))\n",
        "            ty = random.uniform(-(max_u_trans - 1), (max_d_trans - 1))\n",
        "\n",
        "            M = np.array([[1, 0, tx], [0, 1, ty]])\n",
        "            image = cv2.warpAffine(image, M, (w, h))\n",
        "\n",
        "            bboxes[:, [0, 2]] = bboxes[:, [0, 2]] + tx\n",
        "            bboxes[:, [1, 3]] = bboxes[:, [1, 3]] + ty\n",
        "\n",
        "        return image, bboxes\n",
        "\n",
        "    def parse_annotation(self, annotation, mAP = 'False'):\n",
        "        if TRAIN_LOAD_IMAGES_TO_RAM:\n",
        "            image_path = annotation[0]\n",
        "            image = annotation[2]\n",
        "        else:\n",
        "            image_path = annotation[0]\n",
        "            image = cv2.imread(image_path)\n",
        "\n",
        "        bboxes = np.array([list(map(int, box.split(','))) for box in annotation[1]])\n",
        "\n",
        "        if self.data_aug:\n",
        "            image, bboxes = self.random_horizontal_flip(np.copy(image), np.copy(bboxes))\n",
        "            image, bboxes = self.random_crop(np.copy(image), np.copy(bboxes))\n",
        "            image, bboxes = self.random_translate(np.copy(image), np.copy(bboxes))\n",
        "\n",
        "        #image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "        if mAP == True:\n",
        "            return image, bboxes\n",
        "\n",
        "        image, bboxes = image_preprocess(np.copy(image), [self.input_sizes, self.input_sizes], np.copy(bboxes))\n",
        "        return image, bboxes\n",
        "\n",
        "    def preprocess_true_boxes(self, bboxes):\n",
        "        OUTPUT_LEVELS = len(self.strides)\n",
        "\n",
        "        label = [np.zeros((self.train_output_sizes[i], self.train_output_sizes[i], self.anchor_per_scale,\n",
        "                           5 + self.num_classes)) for i in range(OUTPUT_LEVELS)]\n",
        "        bboxes_xywh = [np.zeros((self.max_bbox_per_scale, 4)) for _ in range(OUTPUT_LEVELS)]\n",
        "        bbox_count = np.zeros((OUTPUT_LEVELS,))\n",
        "\n",
        "        for bbox in bboxes:\n",
        "            bbox_coor = bbox[:4]\n",
        "            bbox_class_ind = bbox[4]\n",
        "\n",
        "            onehot = np.zeros(self.num_classes, dtype=np.float)\n",
        "            onehot[bbox_class_ind] = 1.0\n",
        "            uniform_distribution = np.full(self.num_classes, 1.0 / self.num_classes)\n",
        "            deta = 0.01\n",
        "            smooth_onehot = onehot * (1 - deta) + deta * uniform_distribution\n",
        "\n",
        "            bbox_xywh = np.concatenate([(bbox_coor[2:] + bbox_coor[:2]) * 0.5, bbox_coor[2:] - bbox_coor[:2]], axis=-1)\n",
        "            bbox_xywh_scaled = 1.0 * bbox_xywh[np.newaxis, :] / self.strides[:, np.newaxis]\n",
        "\n",
        "            iou = []\n",
        "            exist_positive = False\n",
        "            for i in range(OUTPUT_LEVELS):#range(3):\n",
        "                anchors_xywh = np.zeros((self.anchor_per_scale, 4))\n",
        "                anchors_xywh[:, 0:2] = np.floor(bbox_xywh_scaled[i, 0:2]).astype(np.int32) + 0.5\n",
        "                anchors_xywh[:, 2:4] = self.anchors[i]\n",
        "\n",
        "                iou_scale = bbox_iou(bbox_xywh_scaled[i][np.newaxis, :], anchors_xywh)\n",
        "                iou.append(iou_scale)\n",
        "                iou_mask = iou_scale > 0.3\n",
        "\n",
        "                if np.any(iou_mask):\n",
        "                    xind, yind = np.floor(bbox_xywh_scaled[i, 0:2]).astype(np.int32)\n",
        "\n",
        "                    label[i][yind, xind, iou_mask, :] = 0\n",
        "                    label[i][yind, xind, iou_mask, 0:4] = bbox_xywh\n",
        "                    label[i][yind, xind, iou_mask, 4:5] = 1.0\n",
        "                    label[i][yind, xind, iou_mask, 5:] = smooth_onehot\n",
        "\n",
        "                    bbox_ind = int(bbox_count[i] % self.max_bbox_per_scale)\n",
        "                    bboxes_xywh[i][bbox_ind, :4] = bbox_xywh\n",
        "                    bbox_count[i] += 1\n",
        "\n",
        "                    exist_positive = True\n",
        "\n",
        "            if not exist_positive:\n",
        "                best_anchor_ind = np.argmax(np.array(iou).reshape(-1), axis=-1)\n",
        "                best_detect = int(best_anchor_ind / self.anchor_per_scale)\n",
        "                best_anchor = int(best_anchor_ind % self.anchor_per_scale)\n",
        "                xind, yind = np.floor(bbox_xywh_scaled[best_detect, 0:2]).astype(np.int32)\n",
        "\n",
        "                label[best_detect][yind, xind, best_anchor, :] = 0\n",
        "                label[best_detect][yind, xind, best_anchor, 0:4] = bbox_xywh\n",
        "                label[best_detect][yind, xind, best_anchor, 4:5] = 1.0\n",
        "                label[best_detect][yind, xind, best_anchor, 5:] = smooth_onehot\n",
        "\n",
        "                bbox_ind = int(bbox_count[best_detect] % self.max_bbox_per_scale)\n",
        "                bboxes_xywh[best_detect][bbox_ind, :4] = bbox_xywh\n",
        "                bbox_count[best_detect] += 1\n",
        "\n",
        "        if self.train_yolo_tiny:\n",
        "            label_mbbox, label_lbbox = label\n",
        "            mbboxes, lbboxes = bboxes_xywh\n",
        "            return label_mbbox, label_lbbox, mbboxes, lbboxes\n",
        "\n",
        "        label_sbbox, label_mbbox, label_lbbox = label\n",
        "        sbboxes, mbboxes, lbboxes = bboxes_xywh\n",
        "        return label_sbbox, label_mbbox, label_lbbox, sbboxes, mbboxes, lbboxes\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.num_batchs"
      ],
      "metadata": {
        "id": "PLyEklLbfxgT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#YoloV3"
      ],
      "metadata": {
        "id": "doiv5_9DgGp2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "STRIDES         = np.array(YOLO_STRIDES)\n",
        "ANCHORS         = (np.array(YOLO_ANCHORS).T/STRIDES).T\n",
        "\n",
        "class BatchNormalization(tf.keras.layers.BatchNormalization):\n",
        "    # \"Frozen state\" and \"inference mode\" are two separate concepts.\n",
        "    # `layer.trainable = False` is to freeze the layer, so the layer will use\n",
        "    # stored moving `var` and `mean` in the \"inference mode\", and both `gama`\n",
        "    # and `beta` will not be updated !\n",
        "    def call(self, x, training=False):\n",
        "        if not training:\n",
        "            training = tf.constant(False)\n",
        "        training = tf.logical_and(training, self.trainable)\n",
        "        return super().call(x, training)\n",
        "\n",
        "def convolutional(input_layer, filters_shape, downsample=False, activate=True, bn=True):\n",
        "    if downsample:\n",
        "        input_layer = tf.keras.layers.ZeroPadding2D(((1, 0), (1, 0)))(input_layer)\n",
        "        padding = 'valid'\n",
        "        strides = 2\n",
        "    else:\n",
        "        strides = 1\n",
        "        padding = 'same'\n",
        "\n",
        "    conv = tf.keras.layers.Conv2D(filters=filters_shape[-1], kernel_size = filters_shape[0], strides=strides,\n",
        "                  padding=padding, use_bias=not bn, kernel_regularizer=tf.keras.regularizers.l2(0.0005),\n",
        "                  kernel_initializer=tf.random_normal_initializer(stddev=0.01),\n",
        "                  bias_initializer=tf.constant_initializer(0.))(input_layer)\n",
        "    if bn:\n",
        "        conv = tf.keras.layers.BatchNormalization()(conv)\n",
        "    if activate == True:\n",
        "        conv = tf.keras.layers.LeakyReLU(alpha=0.1)(conv)\n",
        "\n",
        "    return conv\n",
        "\n",
        "def residual_block(input_layer, input_channel, filter_num1, filter_num2):\n",
        "    short_cut = input_layer\n",
        "    conv = convolutional(input_layer, filters_shape=(1, 1, input_channel, filter_num1))\n",
        "    conv = convolutional(conv       , filters_shape=(3, 3, filter_num1,   filter_num2))\n",
        "\n",
        "    residual_output = short_cut + conv\n",
        "    return residual_output\n",
        "\n",
        "def upsample(input_layer):\n",
        "    return tf.image.resize(input_layer, (input_layer.shape[1] * 2, input_layer.shape[2] * 2), method='nearest')\n",
        "\n",
        "\n",
        "def darknet53(input_data):\n",
        "    input_data = convolutional(input_data, (3, 3,  3,  32))\n",
        "    input_data = convolutional(input_data, (3, 3, 32,  64), downsample=True)\n",
        "\n",
        "    for i in range(1):\n",
        "        input_data = residual_block(input_data,  64,  32, 64)\n",
        "\n",
        "    input_data = convolutional(input_data, (3, 3,  64, 128), downsample=True)\n",
        "\n",
        "    for i in range(2):\n",
        "        input_data = residual_block(input_data, 128,  64, 128)\n",
        "\n",
        "    input_data = convolutional(input_data, (3, 3, 128, 256), downsample=True)\n",
        "\n",
        "    for i in range(8):\n",
        "        input_data = residual_block(input_data, 256, 128, 256)\n",
        "\n",
        "    route_1 = input_data\n",
        "    input_data = convolutional(input_data, (3, 3, 256, 512), downsample=True)\n",
        "\n",
        "    for i in range(8):\n",
        "        input_data = residual_block(input_data, 512, 256, 512)\n",
        "\n",
        "    route_2 = input_data\n",
        "    input_data = convolutional(input_data, (3, 3, 512, 1024), downsample=True)\n",
        "\n",
        "    for i in range(4):\n",
        "        input_data = residual_block(input_data, 1024, 512, 1024)\n",
        "\n",
        "    return route_1, route_2, input_data\n",
        "\n",
        "def darknet19_tiny(input_data):\n",
        "    input_data = convolutional(input_data, (3, 3, 3, 16))\n",
        "    input_data = tf.keras.layers.MaxPool2D(2, 2, 'same')(input_data)\n",
        "    input_data = convolutional(input_data, (3, 3, 16, 32))\n",
        "    input_data = tf.keras.layers.MaxPool2D(2, 2, 'same')(input_data)\n",
        "    input_data = convolutional(input_data, (3, 3, 32, 64))\n",
        "    input_data = tf.keras.layers.MaxPool2D(2, 2, 'same')(input_data)\n",
        "    input_data = convolutional(input_data, (3, 3, 64, 128))\n",
        "    input_data = tf.keras.layers.MaxPool2D(2, 2, 'same')(input_data)\n",
        "    input_data = convolutional(input_data, (3, 3, 128, 256))\n",
        "    route_1 = input_data\n",
        "    input_data = tf.keras.layers.MaxPool2D(2, 2, 'same')(input_data)\n",
        "    input_data = convolutional(input_data, (3, 3, 256, 512))\n",
        "    input_data = tf.keras.layers.MaxPool2D(2, 1, 'same')(input_data)\n",
        "    input_data = convolutional(input_data, (3, 3, 512, 1024))\n",
        "\n",
        "    return route_1, input_data\n",
        "\n",
        "def YOLOv3(input_layer, NUM_CLASS):\n",
        "    # After the input layer enters the Darknet-53 network, we get three branches\n",
        "    route_1, route_2, conv = darknet53(input_layer)\n",
        "    # See the orange module (DBL) in the figure above, a total of 5 Subconvolution operation\n",
        "    conv = convolutional(conv, (1, 1, 1024,  512))\n",
        "    conv = convolutional(conv, (3, 3,  512, 1024))\n",
        "    conv = convolutional(conv, (1, 1, 1024,  512))\n",
        "    conv = convolutional(conv, (3, 3,  512, 1024))\n",
        "    conv = convolutional(conv, (1, 1, 1024,  512))\n",
        "    conv_lobj_branch = convolutional(conv, (3, 3, 512, 1024))\n",
        "    \n",
        "    # conv_lbbox is used to predict large-sized objects , Shape = [None, 13, 13, 255] \n",
        "    conv_lbbox = convolutional(conv_lobj_branch, (1, 1, 1024, 3*(NUM_CLASS + 5)), activate=False, bn=False)\n",
        "\n",
        "    conv = convolutional(conv, (1, 1,  512,  256))\n",
        "    # upsample here uses the nearest neighbor interpolation method, which has the advantage that the\n",
        "    # upsampling process does not need to learn, thereby reducing the network parameter  \n",
        "    conv = upsample(conv)\n",
        "\n",
        "    conv = tf.concat([conv, route_2], axis=-1)\n",
        "    conv = convolutional(conv, (1, 1, 768, 256))\n",
        "    conv = convolutional(conv, (3, 3, 256, 512))\n",
        "    conv = convolutional(conv, (1, 1, 512, 256))\n",
        "    conv = convolutional(conv, (3, 3, 256, 512))\n",
        "    conv = convolutional(conv, (1, 1, 512, 256))\n",
        "    conv_mobj_branch = convolutional(conv, (3, 3, 256, 512))\n",
        "\n",
        "    # conv_mbbox is used to predict medium-sized objects, shape = [None, 26, 26, 255]\n",
        "    conv_mbbox = convolutional(conv_mobj_branch, (1, 1, 512, 3*(NUM_CLASS + 5)), activate=False, bn=False)\n",
        "\n",
        "    conv = convolutional(conv, (1, 1, 256, 128))\n",
        "    conv = upsample(conv)\n",
        "\n",
        "    conv = tf.concat([conv, route_1], axis=-1)\n",
        "    conv = convolutional(conv, (1, 1, 384, 128))\n",
        "    conv = convolutional(conv, (3, 3, 128, 256))\n",
        "    conv = convolutional(conv, (1, 1, 256, 128))\n",
        "    conv = convolutional(conv, (3, 3, 128, 256))\n",
        "    conv = convolutional(conv, (1, 1, 256, 128))\n",
        "    conv_sobj_branch = convolutional(conv, (3, 3, 128, 256))\n",
        "    \n",
        "    # conv_sbbox is used to predict small size objects, shape = [None, 52, 52, 255]\n",
        "    conv_sbbox = convolutional(conv_sobj_branch, (1, 1, 256, 3*(NUM_CLASS +5)), activate=False, bn=False)\n",
        "        \n",
        "    return [conv_sbbox, conv_mbbox, conv_lbbox]\n",
        "\n",
        "def YOLOv3_tiny(input_layer, NUM_CLASS):\n",
        "    # After the input layer enters the Darknet-53 network, we get three branches\n",
        "    route_1, conv = darknet19_tiny(input_layer)\n",
        "\n",
        "    conv = convolutional(conv, (1, 1, 1024, 256))\n",
        "    conv_lobj_branch = convolutional(conv, (3, 3, 256, 512))\n",
        "    \n",
        "    # conv_lbbox is used to predict large-sized objects , Shape = [None, 26, 26, 255]\n",
        "    conv_lbbox = convolutional(conv_lobj_branch, (1, 1, 512, 3*(NUM_CLASS + 5)), activate=False, bn=False)\n",
        "\n",
        "    conv = convolutional(conv, (1, 1, 256, 128))\n",
        "    # upsample here uses the nearest neighbor interpolation method, which has the advantage that the\n",
        "    # upsampling process does not need to learn, thereby reducing the network parameter  \n",
        "    conv = upsample(conv)\n",
        "    \n",
        "    conv = tf.concat([conv, route_1], axis=-1)\n",
        "    conv_mobj_branch = convolutional(conv, (3, 3, 128, 256))\n",
        "    # conv_mbbox is used to predict medium size objects, shape = [None, 13, 13, 255]\n",
        "    conv_mbbox = convolutional(conv_mobj_branch, (1, 1, 256, 3 * (NUM_CLASS + 5)), activate=False, bn=False)\n",
        "\n",
        "    return [conv_mbbox, conv_lbbox]\n",
        "\n",
        "def Create_Yolov3(input_size=416, channels=3, training=False, CLASSES=YOLO_COCO_CLASSES):\n",
        "    NUM_CLASS = len(read_class_names(CLASSES))\n",
        "    input_layer  = tf.keras.layers.Input([input_size, input_size, channels])\n",
        "\n",
        "    if TRAIN_YOLO_TINY:\n",
        "        conv_tensors = YOLOv3_tiny(input_layer, NUM_CLASS)\n",
        "    else:\n",
        "        conv_tensors = YOLOv3(input_layer, NUM_CLASS)\n",
        "\n",
        "    output_tensors = []\n",
        "    for i, conv_tensor in enumerate(conv_tensors):\n",
        "        pred_tensor = decode(conv_tensor, NUM_CLASS, i)\n",
        "        if training: output_tensors.append(conv_tensor)\n",
        "        output_tensors.append(pred_tensor)\n",
        "\n",
        "    YoloV3 = tf.keras.Model(input_layer, output_tensors)\n",
        "    return YoloV3\n",
        "\n",
        "def decode(conv_output, NUM_CLASS, i=0):\n",
        "    # where i = 0, 1 or 2 to correspond to the three grid scales  \n",
        "    conv_shape       = tf.shape(conv_output)\n",
        "    batch_size       = conv_shape[0]\n",
        "    output_size      = conv_shape[1]\n",
        "\n",
        "    conv_output = tf.reshape(conv_output, (batch_size, output_size, output_size, 3, 5 + NUM_CLASS))\n",
        "\n",
        "    conv_raw_dxdy = conv_output[:, :, :, :, 0:2] # offset of center position     \n",
        "    conv_raw_dwdh = conv_output[:, :, :, :, 2:4] # Prediction box length and width offset\n",
        "    conv_raw_conf = conv_output[:, :, :, :, 4:5] # confidence of the prediction box\n",
        "    conv_raw_prob = conv_output[:, :, :, :, 5: ] # category probability of the prediction box \n",
        "\n",
        "    # next need Draw the grid. Where output_size is equal to 13, 26 or 52  \n",
        "    y = tf.range(output_size, dtype=tf.int32)\n",
        "    y = tf.expand_dims(y, -1)\n",
        "    y = tf.tile(y, [1, output_size])\n",
        "    x = tf.range(output_size,dtype=tf.int32)\n",
        "    x = tf.expand_dims(x, 0)\n",
        "    x = tf.tile(x, [output_size, 1])\n",
        "\n",
        "    xy_grid = tf.concat([x[:, :, tf.newaxis], y[:, :, tf.newaxis]], axis=-1)\n",
        "    xy_grid = tf.tile(xy_grid[tf.newaxis, :, :, tf.newaxis, :], [batch_size, 1, 1, 3, 1])\n",
        "    xy_grid = tf.cast(xy_grid, tf.float32)\n",
        "\n",
        "    # Calculate the center position of the prediction box:\n",
        "    pred_xy = (tf.sigmoid(conv_raw_dxdy) + xy_grid) * STRIDES[i]\n",
        "    # Calculate the length and width of the prediction box:\n",
        "    pred_wh = (tf.exp(conv_raw_dwdh) * ANCHORS[i]) * STRIDES[i]\n",
        "\n",
        "    pred_xywh = tf.concat([pred_xy, pred_wh], axis=-1)\n",
        "    pred_conf = tf.sigmoid(conv_raw_conf) # object box calculates the predicted confidence\n",
        "    pred_prob = tf.sigmoid(conv_raw_prob) # calculating the predicted probability category box object\n",
        "\n",
        "    # calculating the predicted probability category box object\n",
        "    return tf.concat([pred_xywh, pred_conf, pred_prob], axis=-1)\n",
        "\n",
        "def bbox_iou(boxes1, boxes2):\n",
        "    boxes1_area = boxes1[..., 2] * boxes1[..., 3]\n",
        "    boxes2_area = boxes2[..., 2] * boxes2[..., 3]\n",
        "\n",
        "    boxes1 = tf.concat([boxes1[..., :2] - boxes1[..., 2:] * 0.5,\n",
        "                        boxes1[..., :2] + boxes1[..., 2:] * 0.5], axis=-1)\n",
        "    boxes2 = tf.concat([boxes2[..., :2] - boxes2[..., 2:] * 0.5,\n",
        "                        boxes2[..., :2] + boxes2[..., 2:] * 0.5], axis=-1)\n",
        "\n",
        "    left_up = tf.maximum(boxes1[..., :2], boxes2[..., :2])\n",
        "    right_down = tf.minimum(boxes1[..., 2:], boxes2[..., 2:])\n",
        "\n",
        "    inter_section = tf.maximum(right_down - left_up, 0.0)\n",
        "    inter_area = inter_section[..., 0] * inter_section[..., 1]\n",
        "    union_area = boxes1_area + boxes2_area - inter_area\n",
        "\n",
        "    return 1.0 * inter_area / union_area\n",
        "\n",
        "def bbox_giou(boxes1, boxes2):\n",
        "    boxes1 = tf.concat([boxes1[..., :2] - boxes1[..., 2:] * 0.5,\n",
        "                        boxes1[..., :2] + boxes1[..., 2:] * 0.5], axis=-1)\n",
        "    boxes2 = tf.concat([boxes2[..., :2] - boxes2[..., 2:] * 0.5,\n",
        "                        boxes2[..., :2] + boxes2[..., 2:] * 0.5], axis=-1)\n",
        "\n",
        "    boxes1 = tf.concat([tf.minimum(boxes1[..., :2], boxes1[..., 2:]),\n",
        "                        tf.maximum(boxes1[..., :2], boxes1[..., 2:])], axis=-1)\n",
        "    boxes2 = tf.concat([tf.minimum(boxes2[..., :2], boxes2[..., 2:]),\n",
        "                        tf.maximum(boxes2[..., :2], boxes2[..., 2:])], axis=-1)\n",
        "\n",
        "    boxes1_area = (boxes1[..., 2] - boxes1[..., 0]) * (boxes1[..., 3] - boxes1[..., 1])\n",
        "    boxes2_area = (boxes2[..., 2] - boxes2[..., 0]) * (boxes2[..., 3] - boxes2[..., 1])\n",
        "\n",
        "    left_up = tf.maximum(boxes1[..., :2], boxes2[..., :2])\n",
        "    right_down = tf.minimum(boxes1[..., 2:], boxes2[..., 2:])\n",
        "\n",
        "    inter_section = tf.maximum(right_down - left_up, 0.0)\n",
        "    inter_area = inter_section[..., 0] * inter_section[..., 1]\n",
        "    union_area = boxes1_area + boxes2_area - inter_area\n",
        "\n",
        "    # Calculate the iou value between the two bounding boxes\n",
        "    iou = inter_area / union_area\n",
        "\n",
        "    # Calculate the coordinates of the upper left corner and the lower right corner of the smallest closed convex surface\n",
        "    enclose_left_up = tf.minimum(boxes1[..., :2], boxes2[..., :2])\n",
        "    enclose_right_down = tf.maximum(boxes1[..., 2:], boxes2[..., 2:])\n",
        "    enclose = tf.maximum(enclose_right_down - enclose_left_up, 0.0)\n",
        "\n",
        "    # Calculate the area of the smallest closed convex surface C\n",
        "    enclose_area = enclose[..., 0] * enclose[..., 1]\n",
        "\n",
        "    # Calculate the GIoU value according to the GioU formula  \n",
        "    giou = iou - 1.0 * (enclose_area - union_area) / enclose_area\n",
        "\n",
        "    return giou\n",
        "\n",
        "# testing (should be better than giou)\n",
        "def bbox_ciou(boxes1, boxes2):\n",
        "    boxes1_coor = tf.concat([boxes1[..., :2] - boxes1[..., 2:] * 0.5,\n",
        "                        boxes1[..., :2] + boxes1[..., 2:] * 0.5], axis=-1)\n",
        "    boxes2_coor = tf.concat([boxes2[..., :2] - boxes2[..., 2:] * 0.5,\n",
        "                        boxes2[..., :2] + boxes2[..., 2:] * 0.5], axis=-1)\n",
        "\n",
        "    left = tf.maximum(boxes1_coor[..., 0], boxes2_coor[..., 0])\n",
        "    up = tf.maximum(boxes1_coor[..., 1], boxes2_coor[..., 1])\n",
        "    right = tf.maximum(boxes1_coor[..., 2], boxes2_coor[..., 2])\n",
        "    down = tf.maximum(boxes1_coor[..., 3], boxes2_coor[..., 3])\n",
        "\n",
        "    c = (right - left) * (right - left) + (up - down) * (up - down)\n",
        "    iou = bbox_iou(boxes1, boxes2)\n",
        "\n",
        "    u = (boxes1[..., 0] - boxes2[..., 0]) * (boxes1[..., 0] - boxes2[..., 0]) + (boxes1[..., 1] - boxes2[..., 1]) * (boxes1[..., 1] - boxes2[..., 1])\n",
        "    d = u / c\n",
        "\n",
        "    ar_gt = boxes2[..., 2] / boxes2[..., 3]\n",
        "    ar_pred = boxes1[..., 2] / boxes1[..., 3]\n",
        "\n",
        "    ar_loss = 4 / (np.pi * np.pi) * (tf.atan(ar_gt) - tf.atan(ar_pred)) * (tf.atan(ar_gt) - tf.atan(ar_pred))\n",
        "    alpha = ar_loss / (1 - iou + ar_loss + 0.000001)\n",
        "    ciou_term = d + alpha * ar_loss\n",
        "\n",
        "    return iou - ciou_term\n",
        "\n",
        "\n",
        "def compute_loss(pred, conv, label, bboxes, i=0, CLASSES=YOLO_COCO_CLASSES):\n",
        "    NUM_CLASS = len(read_class_names(CLASSES))\n",
        "    conv_shape  = tf.shape(conv)\n",
        "    batch_size  = conv_shape[0]\n",
        "    output_size = conv_shape[1]\n",
        "    input_size  = STRIDES[i] * output_size\n",
        "    conv = tf.reshape(conv, (batch_size, output_size, output_size, 3, 5 + NUM_CLASS))\n",
        "\n",
        "    conv_raw_conf = conv[:, :, :, :, 4:5]\n",
        "    conv_raw_prob = conv[:, :, :, :, 5:]\n",
        "\n",
        "    pred_xywh     = pred[:, :, :, :, 0:4]\n",
        "    pred_conf     = pred[:, :, :, :, 4:5]\n",
        "\n",
        "    label_xywh    = label[:, :, :, :, 0:4]\n",
        "    respond_bbox  = label[:, :, :, :, 4:5]\n",
        "    label_prob    = label[:, :, :, :, 5:]\n",
        "\n",
        "    giou = tf.expand_dims(bbox_giou(pred_xywh, label_xywh), axis=-1)\n",
        "    input_size = tf.cast(input_size, tf.float32)\n",
        "\n",
        "    bbox_loss_scale = 2.0 - 1.0 * label_xywh[:, :, :, :, 2:3] * label_xywh[:, :, :, :, 3:4] / (input_size ** 2)\n",
        "    giou_loss = respond_bbox * bbox_loss_scale * (1 - giou)\n",
        "\n",
        "    iou = bbox_iou(pred_xywh[:, :, :, :, np.newaxis, :], bboxes[:, np.newaxis, np.newaxis, np.newaxis, :, :])\n",
        "    # Find the value of IoU with the real box The largest prediction box\n",
        "    max_iou = tf.expand_dims(tf.reduce_max(iou, axis=-1), axis=-1)\n",
        "\n",
        "    # If the largest iou is less than the threshold, it is considered that the prediction box contains no objects, then the background box\n",
        "    respond_bgd = (1.0 - respond_bbox) * tf.cast( max_iou < YOLO_IOU_LOSS_THRESH, tf.float32 )\n",
        "\n",
        "    conf_focal = tf.pow(respond_bbox - pred_conf, 2)\n",
        "\n",
        "    # Calculate the loss of confidence\n",
        "    # we hope that if the grid contains objects, then the network output prediction box has a confidence of 1 and 0 when there is no object.\n",
        "    conf_loss = conf_focal * (\n",
        "            respond_bbox * tf.nn.sigmoid_cross_entropy_with_logits(labels=respond_bbox, logits=conv_raw_conf)\n",
        "            +\n",
        "            respond_bgd * tf.nn.sigmoid_cross_entropy_with_logits(labels=respond_bbox, logits=conv_raw_conf)\n",
        "    )\n",
        "\n",
        "    prob_loss = respond_bbox * tf.nn.sigmoid_cross_entropy_with_logits(labels=label_prob, logits=conv_raw_prob)\n",
        "\n",
        "    giou_loss = tf.reduce_mean(tf.reduce_sum(giou_loss, axis=[1,2,3,4]))\n",
        "    conf_loss = tf.reduce_mean(tf.reduce_sum(conf_loss, axis=[1,2,3,4]))\n",
        "    prob_loss = tf.reduce_mean(tf.reduce_sum(prob_loss, axis=[1,2,3,4]))\n",
        "\n",
        "    return giou_loss, conf_loss, prob_loss"
      ],
      "metadata": {
        "id": "3Hs6YIp6f4ZX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#YoloV4"
      ],
      "metadata": {
        "id": "F5kgsk1EgJbG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "STRIDES         = np.array(YOLO_STRIDES)\n",
        "ANCHORS         = (np.array(YOLO_ANCHORS).T/STRIDES).T\n",
        "\n",
        "def read_class_names(class_file_name):\n",
        "    # loads class name from a file\n",
        "    names = {}\n",
        "    with open(class_file_name, 'r') as data:\n",
        "        for ID, name in enumerate(data):\n",
        "            names[ID] = name.strip('\\n')\n",
        "    return names\n",
        "\n",
        "class BatchNormalization(tf.keras.layers.BatchNormalization):\n",
        "    # \"Frozen state\" and \"inference mode\" are two separate concepts.\n",
        "    # `layer.trainable = False` is to freeze the layer, so the layer will use\n",
        "    # stored moving `var` and `mean` in the \"inference mode\", and both `gama`\n",
        "    # and `beta` will not be updated !\n",
        "    def call(self, x, training=False):\n",
        "        if not training:\n",
        "            training = tf.constant(False)\n",
        "        training = tf.logical_and(training, self.trainable)\n",
        "        return super().call(x, training)\n",
        "\n",
        "def convolutional(input_layer, filters_shape, downsample=False, activate=True, bn=True, activate_type='leaky'):\n",
        "    if downsample:\n",
        "        input_layer = tf.keras.layers.ZeroPadding2D(((1, 0), (1, 0)))(input_layer)\n",
        "        padding = 'valid'\n",
        "        strides = 2\n",
        "    else:\n",
        "        strides = 1\n",
        "        padding = 'same'\n",
        "\n",
        "    conv = tf.keras.layers.Conv2D(filters=filters_shape[-1], kernel_size = filters_shape[0], strides=strides,\n",
        "                  padding=padding, use_bias=not bn, kernel_regularizer=tf.keras.regularizers.l2(0.0005),\n",
        "                  kernel_initializer=tf.random_normal_initializer(stddev=0.01),\n",
        "                  bias_initializer=tf.constant_initializer(0.))(input_layer)\n",
        "    if bn:\n",
        "        conv = tf.keras.layers.BatchNormalization()(conv)\n",
        "    if activate == True:\n",
        "        if activate_type == \"leaky\":\n",
        "            conv = tf.keras.layers.LeakyReLU(alpha=0.1)(conv)\n",
        "        elif activate_type == \"mish\":\n",
        "            conv = mish(conv)\n",
        "\n",
        "    return conv\n",
        "\n",
        "def mish(x):\n",
        "    return x * tf.math.tanh(tf.math.softplus(x))\n",
        "\n",
        "def residual_block(input_layer, input_channel, filter_num1, filter_num2, activate_type='leaky'):\n",
        "    short_cut = input_layer\n",
        "    conv = convolutional(input_layer, filters_shape=(1, 1, input_channel, filter_num1), activate_type=activate_type)\n",
        "    conv = convolutional(conv       , filters_shape=(3, 3, filter_num1,   filter_num2), activate_type=activate_type)\n",
        "\n",
        "    residual_output = short_cut + conv\n",
        "    return residual_output\n",
        "\n",
        "def upsample(input_layer):\n",
        "    return tf.image.resize(input_layer, (input_layer.shape[1] * 2, input_layer.shape[2] * 2), method='nearest')\n",
        "\n",
        "def route_group(input_layer, groups, group_id):\n",
        "    convs = tf.split(input_layer, num_or_size_splits=groups, axis=-1)\n",
        "    return convs[group_id]\n",
        "\n",
        "def darknet53(input_data):\n",
        "    input_data = convolutional(input_data, (3, 3,  3,  32))\n",
        "    input_data = convolutional(input_data, (3, 3, 32,  64), downsample=True)\n",
        "\n",
        "    for i in range(1):\n",
        "        input_data = residual_block(input_data,  64,  32, 64)\n",
        "\n",
        "    input_data = convolutional(input_data, (3, 3,  64, 128), downsample=True)\n",
        "\n",
        "    for i in range(2):\n",
        "        input_data = residual_block(input_data, 128,  64, 128)\n",
        "\n",
        "    input_data = convolutional(input_data, (3, 3, 128, 256), downsample=True)\n",
        "\n",
        "    for i in range(8):\n",
        "        input_data = residual_block(input_data, 256, 128, 256)\n",
        "\n",
        "    route_1 = input_data\n",
        "    input_data = convolutional(input_data, (3, 3, 256, 512), downsample=True)\n",
        "\n",
        "    for i in range(8):\n",
        "        input_data = residual_block(input_data, 512, 256, 512)\n",
        "\n",
        "    route_2 = input_data\n",
        "    input_data = convolutional(input_data, (3, 3, 512, 1024), downsample=True)\n",
        "\n",
        "    for i in range(4):\n",
        "        input_data = residual_block(input_data, 1024, 512, 1024)\n",
        "\n",
        "    return route_1, route_2, input_data\n",
        "\n",
        "def cspdarknet53(input_data):\n",
        "    input_data = convolutional(input_data, (3, 3,  3,  32), activate_type=\"mish\")\n",
        "    input_data = convolutional(input_data, (3, 3, 32,  64), downsample=True, activate_type=\"mish\")\n",
        "\n",
        "    route = input_data\n",
        "    route = convolutional(route, (1, 1, 64, 64), activate_type=\"mish\")\n",
        "    input_data = convolutional(input_data, (1, 1, 64, 64), activate_type=\"mish\")\n",
        "    for i in range(1):\n",
        "        input_data = residual_block(input_data,  64,  32, 64, activate_type=\"mish\")\n",
        "    input_data = convolutional(input_data, (1, 1, 64, 64), activate_type=\"mish\")\n",
        "\n",
        "    input_data = tf.concat([input_data, route], axis=-1)\n",
        "    input_data = convolutional(input_data, (1, 1, 128, 64), activate_type=\"mish\")\n",
        "    input_data = convolutional(input_data, (3, 3, 64, 128), downsample=True, activate_type=\"mish\")\n",
        "    route = input_data\n",
        "    route = convolutional(route, (1, 1, 128, 64), activate_type=\"mish\")\n",
        "    input_data = convolutional(input_data, (1, 1, 128, 64), activate_type=\"mish\")\n",
        "    for i in range(2):\n",
        "        input_data = residual_block(input_data, 64,  64, 64, activate_type=\"mish\")\n",
        "    input_data = convolutional(input_data, (1, 1, 64, 64), activate_type=\"mish\")\n",
        "    input_data = tf.concat([input_data, route], axis=-1)\n",
        "\n",
        "    input_data = convolutional(input_data, (1, 1, 128, 128), activate_type=\"mish\")\n",
        "    input_data = convolutional(input_data, (3, 3, 128, 256), downsample=True, activate_type=\"mish\")\n",
        "    route = input_data\n",
        "    route = convolutional(route, (1, 1, 256, 128), activate_type=\"mish\")\n",
        "    input_data = convolutional(input_data, (1, 1, 256, 128), activate_type=\"mish\")\n",
        "    for i in range(8):\n",
        "        input_data = residual_block(input_data, 128, 128, 128, activate_type=\"mish\")\n",
        "    input_data = convolutional(input_data, (1, 1, 128, 128), activate_type=\"mish\")\n",
        "    input_data = tf.concat([input_data, route], axis=-1)\n",
        "\n",
        "    input_data = convolutional(input_data, (1, 1, 256, 256), activate_type=\"mish\")\n",
        "    route_1 = input_data\n",
        "    input_data = convolutional(input_data, (3, 3, 256, 512), downsample=True, activate_type=\"mish\")\n",
        "    route = input_data\n",
        "    route = convolutional(route, (1, 1, 512, 256), activate_type=\"mish\")\n",
        "    input_data = convolutional(input_data, (1, 1, 512, 256), activate_type=\"mish\")\n",
        "    for i in range(8):\n",
        "        input_data = residual_block(input_data, 256, 256, 256, activate_type=\"mish\")\n",
        "    input_data = convolutional(input_data, (1, 1, 256, 256), activate_type=\"mish\")\n",
        "    input_data = tf.concat([input_data, route], axis=-1)\n",
        "\n",
        "    input_data = convolutional(input_data, (1, 1, 512, 512), activate_type=\"mish\")\n",
        "    route_2 = input_data\n",
        "    input_data = convolutional(input_data, (3, 3, 512, 1024), downsample=True, activate_type=\"mish\")\n",
        "    route = input_data\n",
        "    route = convolutional(route, (1, 1, 1024, 512), activate_type=\"mish\")\n",
        "    input_data = convolutional(input_data, (1, 1, 1024, 512), activate_type=\"mish\")\n",
        "    for i in range(4):\n",
        "        input_data = residual_block(input_data, 512, 512, 512, activate_type=\"mish\")\n",
        "    input_data = convolutional(input_data, (1, 1, 512, 512), activate_type=\"mish\")\n",
        "    input_data = tf.concat([input_data, route], axis=-1)\n",
        "\n",
        "    input_data = convolutional(input_data, (1, 1, 1024, 1024), activate_type=\"mish\")\n",
        "    input_data = convolutional(input_data, (1, 1, 1024, 512))\n",
        "    input_data = convolutional(input_data, (3, 3, 512, 1024))\n",
        "    input_data = convolutional(input_data, (1, 1, 1024, 512))\n",
        "\n",
        "    max_pooling_1 = tf.keras.layers.MaxPool2D(pool_size=13, padding='SAME', strides=1)(input_data)\n",
        "    max_pooling_2 = tf.keras.layers.MaxPool2D(pool_size=9, padding='SAME', strides=1)(input_data)\n",
        "    max_pooling_3 = tf.keras.layers.MaxPool2D(pool_size=5, padding='SAME', strides=1)(input_data)\n",
        "    input_data = tf.concat([max_pooling_1, max_pooling_2, max_pooling_3, input_data], axis=-1)\n",
        "\n",
        "    input_data = convolutional(input_data, (1, 1, 2048, 512))\n",
        "    input_data = convolutional(input_data, (3, 3, 512, 1024))\n",
        "    input_data = convolutional(input_data, (1, 1, 1024, 512))\n",
        "\n",
        "    return route_1, route_2, input_data\n",
        "\n",
        "def darknet19_tiny(input_data):\n",
        "    input_data = convolutional(input_data, (3, 3, 3, 16))\n",
        "    input_data = tf.keras.layers.MaxPool2D(2, 2, 'same')(input_data)\n",
        "    input_data = convolutional(input_data, (3, 3, 16, 32))\n",
        "    input_data = tf.keras.layers.MaxPool2D(2, 2, 'same')(input_data)\n",
        "    input_data = convolutional(input_data, (3, 3, 32, 64))\n",
        "    input_data = tf.keras.layers.MaxPool2D(2, 2, 'same')(input_data)\n",
        "    input_data = convolutional(input_data, (3, 3, 64, 128))\n",
        "    input_data = tf.keras.layers.MaxPool2D(2, 2, 'same')(input_data)\n",
        "    input_data = convolutional(input_data, (3, 3, 128, 256))\n",
        "    route_1 = input_data\n",
        "    input_data = tf.keras.layers.MaxPool2D(2, 2, 'same')(input_data)\n",
        "    input_data = convolutional(input_data, (3, 3, 256, 512))\n",
        "    input_data = tf.keras.layers.MaxPool2D(2, 1, 'same')(input_data)\n",
        "    input_data = convolutional(input_data, (3, 3, 512, 1024))\n",
        "\n",
        "    return route_1, input_data\n",
        "\n",
        "def cspdarknet53_tiny(input_data): # not sure how this should be called\n",
        "    input_data = convolutional(input_data, (3, 3, 3, 32), downsample=True)\n",
        "    input_data = convolutional(input_data, (3, 3, 32, 64), downsample=True)\n",
        "    input_data = convolutional(input_data, (3, 3, 64, 64))\n",
        "\n",
        "    route = input_data\n",
        "    input_data = route_group(input_data, 2, 1)\n",
        "    input_data = convolutional(input_data, (3, 3, 32, 32))\n",
        "    route_1 = input_data\n",
        "    input_data = convolutional(input_data, (3, 3, 32, 32))\n",
        "    input_data = tf.concat([input_data, route_1], axis=-1)\n",
        "    input_data = convolutional(input_data, (1, 1, 32, 64))\n",
        "    input_data = tf.concat([route, input_data], axis=-1)\n",
        "    input_data = tf.keras.layers.MaxPool2D(2, 2, 'same')(input_data)\n",
        "\n",
        "    input_data = convolutional(input_data, (3, 3, 64, 128))\n",
        "    route = input_data\n",
        "    input_data = route_group(input_data, 2, 1)\n",
        "    input_data = convolutional(input_data, (3, 3, 64, 64))\n",
        "    route_1 = input_data\n",
        "    input_data = convolutional(input_data, (3, 3, 64, 64))\n",
        "    input_data = tf.concat([input_data, route_1], axis=-1)\n",
        "    input_data = convolutional(input_data, (1, 1, 64, 128))\n",
        "    input_data = tf.concat([route, input_data], axis=-1)\n",
        "    input_data = tf.keras.layers.MaxPool2D(2, 2, 'same')(input_data)\n",
        "\n",
        "    input_data = convolutional(input_data, (3, 3, 128, 256))\n",
        "    route = input_data\n",
        "    input_data = route_group(input_data, 2, 1)\n",
        "    input_data = convolutional(input_data, (3, 3, 128, 128))\n",
        "    route_1 = input_data\n",
        "    input_data = convolutional(input_data, (3, 3, 128, 128))\n",
        "    input_data = tf.concat([input_data, route_1], axis=-1)\n",
        "    input_data = convolutional(input_data, (1, 1, 128, 256))\n",
        "    route_1 = input_data\n",
        "    input_data = tf.concat([route, input_data], axis=-1)\n",
        "    input_data = tf.keras.layers.MaxPool2D(2, 2, 'same')(input_data)\n",
        "\n",
        "    input_data = convolutional(input_data, (3, 3, 512, 512))\n",
        "\n",
        "    return route_1, input_data\n",
        "\n",
        "def YOLOv3(input_layer, NUM_CLASS):\n",
        "    # After the input layer enters the Darknet-53 network, we get three branches\n",
        "    route_1, route_2, conv = darknet53(input_layer)\n",
        "    # See the orange module (DBL) in the figure above, a total of 5 Subconvolution operation\n",
        "    conv = convolutional(conv, (1, 1, 1024,  512))\n",
        "    conv = convolutional(conv, (3, 3,  512, 1024))\n",
        "    conv = convolutional(conv, (1, 1, 1024,  512))\n",
        "    conv = convolutional(conv, (3, 3,  512, 1024))\n",
        "    conv = convolutional(conv, (1, 1, 1024,  512))\n",
        "    conv_lobj_branch = convolutional(conv, (3, 3, 512, 1024))\n",
        "    \n",
        "    # conv_lbbox is used to predict large-sized objects , Shape = [None, 13, 13, 255] \n",
        "    conv_lbbox = convolutional(conv_lobj_branch, (1, 1, 1024, 3*(NUM_CLASS + 5)), activate=False, bn=False)\n",
        "\n",
        "    conv = convolutional(conv, (1, 1,  512,  256))\n",
        "    # upsample here uses the nearest neighbor interpolation method, which has the advantage that the\n",
        "    # upsampling process does not need to learn, thereby reducing the network parameter  \n",
        "    conv = upsample(conv)\n",
        "\n",
        "    conv = tf.concat([conv, route_2], axis=-1)\n",
        "    conv = convolutional(conv, (1, 1, 768, 256))\n",
        "    conv = convolutional(conv, (3, 3, 256, 512))\n",
        "    conv = convolutional(conv, (1, 1, 512, 256))\n",
        "    conv = convolutional(conv, (3, 3, 256, 512))\n",
        "    conv = convolutional(conv, (1, 1, 512, 256))\n",
        "    conv_mobj_branch = convolutional(conv, (3, 3, 256, 512))\n",
        "\n",
        "    # conv_mbbox is used to predict medium-sized objects, shape = [None, 26, 26, 255]\n",
        "    conv_mbbox = convolutional(conv_mobj_branch, (1, 1, 512, 3*(NUM_CLASS + 5)), activate=False, bn=False)\n",
        "\n",
        "    conv = convolutional(conv, (1, 1, 256, 128))\n",
        "    conv = upsample(conv)\n",
        "\n",
        "    conv = tf.concat([conv, route_1], axis=-1)\n",
        "    conv = convolutional(conv, (1, 1, 384, 128))\n",
        "    conv = convolutional(conv, (3, 3, 128, 256))\n",
        "    conv = convolutional(conv, (1, 1, 256, 128))\n",
        "    conv = convolutional(conv, (3, 3, 128, 256))\n",
        "    conv = convolutional(conv, (1, 1, 256, 128))\n",
        "    conv_sobj_branch = convolutional(conv, (3, 3, 128, 256))\n",
        "    \n",
        "    # conv_sbbox is used to predict small size objects, shape = [None, 52, 52, 255]\n",
        "    conv_sbbox = convolutional(conv_sobj_branch, (1, 1, 256, 3*(NUM_CLASS +5)), activate=False, bn=False)\n",
        "        \n",
        "    return [conv_sbbox, conv_mbbox, conv_lbbox]\n",
        "\n",
        "def YOLOv4(input_layer, NUM_CLASS):\n",
        "    route_1, route_2, conv = cspdarknet53(input_layer)\n",
        "\n",
        "    route = conv\n",
        "    conv = convolutional(conv, (1, 1, 512, 256))\n",
        "    conv = upsample(conv)\n",
        "    route_2 = convolutional(route_2, (1, 1, 512, 256))\n",
        "    conv = tf.concat([route_2, conv], axis=-1)\n",
        "\n",
        "    conv = convolutional(conv, (1, 1, 512, 256))\n",
        "    conv = convolutional(conv, (3, 3, 256, 512))\n",
        "    conv = convolutional(conv, (1, 1, 512, 256))\n",
        "    conv = convolutional(conv, (3, 3, 256, 512))\n",
        "    conv = convolutional(conv, (1, 1, 512, 256))\n",
        "\n",
        "    route_2 = conv\n",
        "    conv = convolutional(conv, (1, 1, 256, 128))\n",
        "    conv = upsample(conv)\n",
        "    route_1 = convolutional(route_1, (1, 1, 256, 128))\n",
        "    conv = tf.concat([route_1, conv], axis=-1)\n",
        "\n",
        "    conv = convolutional(conv, (1, 1, 256, 128))\n",
        "    conv = convolutional(conv, (3, 3, 128, 256))\n",
        "    conv = convolutional(conv, (1, 1, 256, 128))\n",
        "    conv = convolutional(conv, (3, 3, 128, 256))\n",
        "    conv = convolutional(conv, (1, 1, 256, 128))\n",
        "\n",
        "    route_1 = conv\n",
        "    conv = convolutional(conv, (3, 3, 128, 256))\n",
        "    conv_sbbox = convolutional(conv, (1, 1, 256, 3 * (NUM_CLASS + 5)), activate=False, bn=False)\n",
        "\n",
        "    conv = convolutional(route_1, (3, 3, 128, 256), downsample=True)\n",
        "    conv = tf.concat([conv, route_2], axis=-1)\n",
        "\n",
        "    conv = convolutional(conv, (1, 1, 512, 256))\n",
        "    conv = convolutional(conv, (3, 3, 256, 512))\n",
        "    conv = convolutional(conv, (1, 1, 512, 256))\n",
        "    conv = convolutional(conv, (3, 3, 256, 512))\n",
        "    conv = convolutional(conv, (1, 1, 512, 256))\n",
        "\n",
        "    route_2 = conv\n",
        "    conv = convolutional(conv, (3, 3, 256, 512))\n",
        "    conv_mbbox = convolutional(conv, (1, 1, 512, 3 * (NUM_CLASS + 5)), activate=False, bn=False)\n",
        "\n",
        "    conv = convolutional(route_2, (3, 3, 256, 512), downsample=True)\n",
        "    conv = tf.concat([conv, route], axis=-1)\n",
        "\n",
        "    conv = convolutional(conv, (1, 1, 1024, 512))\n",
        "    conv = convolutional(conv, (3, 3, 512, 1024))\n",
        "    conv = convolutional(conv, (1, 1, 1024, 512))\n",
        "    conv = convolutional(conv, (3, 3, 512, 1024))\n",
        "    conv = convolutional(conv, (1, 1, 1024, 512))\n",
        "\n",
        "    conv = convolutional(conv, (3, 3, 512, 1024))\n",
        "    conv_lbbox = convolutional(conv, (1, 1, 1024, 3 * (NUM_CLASS + 5)), activate=False, bn=False)\n",
        "\n",
        "    return [conv_sbbox, conv_mbbox, conv_lbbox]\n",
        "\n",
        "def YOLOv3_tiny(input_layer, NUM_CLASS):\n",
        "    # After the input layer enters the Darknet-53 network, we get three branches\n",
        "    route_1, conv = darknet19_tiny(input_layer)\n",
        "\n",
        "    conv = convolutional(conv, (1, 1, 1024, 256))\n",
        "    conv_lobj_branch = convolutional(conv, (3, 3, 256, 512))\n",
        "    \n",
        "    # conv_lbbox is used to predict large-sized objects , Shape = [None, 26, 26, 255]\n",
        "    conv_lbbox = convolutional(conv_lobj_branch, (1, 1, 512, 3*(NUM_CLASS + 5)), activate=False, bn=False)\n",
        "\n",
        "    conv = convolutional(conv, (1, 1, 256, 128))\n",
        "    # upsample here uses the nearest neighbor interpolation method, which has the advantage that the\n",
        "    # upsampling process does not need to learn, thereby reducing the network parameter  \n",
        "    conv = upsample(conv)\n",
        "    \n",
        "    conv = tf.concat([conv, route_1], axis=-1)\n",
        "    conv_mobj_branch = convolutional(conv, (3, 3, 128, 256))\n",
        "    # conv_mbbox is used to predict medium size objects, shape = [None, 13, 13, 255]\n",
        "    conv_mbbox = convolutional(conv_mobj_branch, (1, 1, 256, 3 * (NUM_CLASS + 5)), activate=False, bn=False)\n",
        "\n",
        "    return [conv_mbbox, conv_lbbox]\n",
        "\n",
        "def YOLOv4_tiny(input_layer, NUM_CLASS):\n",
        "    route_1, conv = cspdarknet53_tiny(input_layer)\n",
        "\n",
        "    conv = convolutional(conv, (1, 1, 512, 256))\n",
        "\n",
        "    conv_lobj_branch = convolutional(conv, (3, 3, 256, 512))\n",
        "    conv_lbbox = convolutional(conv_lobj_branch, (1, 1, 512, 3 * (NUM_CLASS + 5)), activate=False, bn=False)\n",
        "\n",
        "    conv = convolutional(conv, (1, 1, 256, 128))\n",
        "    conv = upsample(conv)\n",
        "    conv = tf.concat([conv, route_1], axis=-1)\n",
        "\n",
        "    conv_mobj_branch = convolutional(conv, (3, 3, 128, 256))\n",
        "    conv_mbbox = convolutional(conv_mobj_branch, (1, 1, 256, 3 * (NUM_CLASS + 5)), activate=False, bn=False)\n",
        "\n",
        "    return [conv_mbbox, conv_lbbox]\n",
        "\n",
        "def Create_Yolo(input_size=416, channels=3, training=False, CLASSES=YOLO_COCO_CLASSES):\n",
        "    NUM_CLASS = len(read_class_names(CLASSES))\n",
        "    input_layer  = tf.keras.layers.Input([input_size, input_size, channels])\n",
        "\n",
        "    if TRAIN_YOLO_TINY:\n",
        "        if YOLO_TYPE == \"yolov4\":\n",
        "            conv_tensors = YOLOv4_tiny(input_layer, NUM_CLASS)\n",
        "        if YOLO_TYPE == \"yolov3\":\n",
        "            conv_tensors = YOLOv3_tiny(input_layer, NUM_CLASS)\n",
        "    else:\n",
        "        if YOLO_TYPE == \"yolov4\":\n",
        "            conv_tensors = YOLOv4(input_layer, NUM_CLASS)\n",
        "        if YOLO_TYPE == \"yolov3\":\n",
        "            conv_tensors = YOLOv3(input_layer, NUM_CLASS)\n",
        "\n",
        "    output_tensors = []\n",
        "    for i, conv_tensor in enumerate(conv_tensors):\n",
        "        pred_tensor = decode(conv_tensor, NUM_CLASS, i)\n",
        "        if training: output_tensors.append(conv_tensor)\n",
        "        output_tensors.append(pred_tensor)\n",
        "\n",
        "    Yolo = tf.keras.Model(input_layer, output_tensors)\n",
        "    return Yolo\n",
        "\n",
        "\n",
        "def decode(conv_output, NUM_CLASS, i=0):\n",
        "    # where i = 0, 1 or 2 to correspond to the three grid scales  \n",
        "    conv_shape       = tf.shape(conv_output)\n",
        "    batch_size       = conv_shape[0]\n",
        "    output_size      = conv_shape[1]\n",
        "\n",
        "    conv_output = tf.reshape(conv_output, (batch_size, output_size, output_size, 3, 5 + NUM_CLASS))\n",
        "\n",
        "    #conv_raw_dxdy = conv_output[:, :, :, :, 0:2] # offset of center position     \n",
        "    #conv_raw_dwdh = conv_output[:, :, :, :, 2:4] # Prediction box length and width offset\n",
        "    #conv_raw_conf = conv_output[:, :, :, :, 4:5] # confidence of the prediction box\n",
        "    #conv_raw_prob = conv_output[:, :, :, :, 5: ] # category probability of the prediction box\n",
        "    conv_raw_dxdy, conv_raw_dwdh, conv_raw_conf, conv_raw_prob = tf.split(conv_output, (2, 2, 1, NUM_CLASS), axis=-1)\n",
        "\n",
        "    # next need Draw the grid. Where output_size is equal to 13, 26 or 52  \n",
        "    #y = tf.range(output_size, dtype=tf.int32)\n",
        "    #y = tf.expand_dims(y, -1)\n",
        "    #y = tf.tile(y, [1, output_size])\n",
        "    #x = tf.range(output_size,dtype=tf.int32)\n",
        "    #x = tf.expand_dims(x, 0)\n",
        "    #x = tf.tile(x, [output_size, 1])\n",
        "    xy_grid = tf.meshgrid(tf.range(output_size), tf.range(output_size))\n",
        "    xy_grid = tf.expand_dims(tf.stack(xy_grid, axis=-1), axis=2)  # [gx, gy, 1, 2]\n",
        "    xy_grid = tf.tile(tf.expand_dims(xy_grid, axis=0), [batch_size, 1, 1, 3, 1])\n",
        "    xy_grid = tf.cast(xy_grid, tf.float32)\n",
        "    \n",
        "    #xy_grid = tf.concat([x[:, :, tf.newaxis], y[:, :, tf.newaxis]], axis=-1)\n",
        "    #xy_grid = tf.tile(xy_grid[tf.newaxis, :, :, tf.newaxis, :], [batch_size, 1, 1, 3, 1])\n",
        "    #y_grid = tf.cast(xy_grid, tf.float32)\n",
        "\n",
        "    # Calculate the center position of the prediction box:\n",
        "    pred_xy = (tf.sigmoid(conv_raw_dxdy) + xy_grid) * STRIDES[i]\n",
        "    # Calculate the length and width of the prediction box:\n",
        "    pred_wh = (tf.exp(conv_raw_dwdh) * ANCHORS[i]) * STRIDES[i]\n",
        "\n",
        "    pred_xywh = tf.concat([pred_xy, pred_wh], axis=-1)\n",
        "    pred_conf = tf.sigmoid(conv_raw_conf) # object box calculates the predicted confidence\n",
        "    pred_prob = tf.sigmoid(conv_raw_prob) # calculating the predicted probability category box object\n",
        "\n",
        "    # calculating the predicted probability category box object\n",
        "    return tf.concat([pred_xywh, pred_conf, pred_prob], axis=-1)\n",
        "\n",
        "\n",
        "def bbox_iou(boxes1, boxes2):\n",
        "    boxes1_area = boxes1[..., 2] * boxes1[..., 3]\n",
        "    boxes2_area = boxes2[..., 2] * boxes2[..., 3]\n",
        "\n",
        "    boxes1 = tf.concat([boxes1[..., :2] - boxes1[..., 2:] * 0.5,\n",
        "                        boxes1[..., :2] + boxes1[..., 2:] * 0.5], axis=-1)\n",
        "    boxes2 = tf.concat([boxes2[..., :2] - boxes2[..., 2:] * 0.5,\n",
        "                        boxes2[..., :2] + boxes2[..., 2:] * 0.5], axis=-1)\n",
        "\n",
        "    left_up = tf.maximum(boxes1[..., :2], boxes2[..., :2])\n",
        "    right_down = tf.minimum(boxes1[..., 2:], boxes2[..., 2:])\n",
        "\n",
        "    inter_section = tf.maximum(right_down - left_up, 0.0)\n",
        "    inter_area = inter_section[..., 0] * inter_section[..., 1]\n",
        "    union_area = boxes1_area + boxes2_area - inter_area\n",
        "\n",
        "    return 1.0 * inter_area / union_area\n",
        "\n",
        "def bbox_giou(boxes1, boxes2):\n",
        "    boxes1 = tf.concat([boxes1[..., :2] - boxes1[..., 2:] * 0.5,\n",
        "                        boxes1[..., :2] + boxes1[..., 2:] * 0.5], axis=-1)\n",
        "    boxes2 = tf.concat([boxes2[..., :2] - boxes2[..., 2:] * 0.5,\n",
        "                        boxes2[..., :2] + boxes2[..., 2:] * 0.5], axis=-1)\n",
        "\n",
        "    boxes1 = tf.concat([tf.minimum(boxes1[..., :2], boxes1[..., 2:]),\n",
        "                        tf.maximum(boxes1[..., :2], boxes1[..., 2:])], axis=-1)\n",
        "    boxes2 = tf.concat([tf.minimum(boxes2[..., :2], boxes2[..., 2:]),\n",
        "                        tf.maximum(boxes2[..., :2], boxes2[..., 2:])], axis=-1)\n",
        "\n",
        "    boxes1_area = (boxes1[..., 2] - boxes1[..., 0]) * (boxes1[..., 3] - boxes1[..., 1])\n",
        "    boxes2_area = (boxes2[..., 2] - boxes2[..., 0]) * (boxes2[..., 3] - boxes2[..., 1])\n",
        "\n",
        "    left_up = tf.maximum(boxes1[..., :2], boxes2[..., :2])\n",
        "    right_down = tf.minimum(boxes1[..., 2:], boxes2[..., 2:])\n",
        "\n",
        "    inter_section = tf.maximum(right_down - left_up, 0.0)\n",
        "    inter_area = inter_section[..., 0] * inter_section[..., 1]\n",
        "    union_area = boxes1_area + boxes2_area - inter_area\n",
        "\n",
        "    # Calculate the iou value between the two bounding boxes\n",
        "    iou = inter_area / union_area\n",
        "\n",
        "    # Calculate the coordinates of the upper left corner and the lower right corner of the smallest closed convex surface\n",
        "    enclose_left_up = tf.minimum(boxes1[..., :2], boxes2[..., :2])\n",
        "    enclose_right_down = tf.maximum(boxes1[..., 2:], boxes2[..., 2:])\n",
        "    enclose = tf.maximum(enclose_right_down - enclose_left_up, 0.0)\n",
        "\n",
        "    # Calculate the area of the smallest closed convex surface C\n",
        "    enclose_area = enclose[..., 0] * enclose[..., 1]\n",
        "\n",
        "    # Calculate the GIoU value according to the GioU formula  \n",
        "    giou = iou - 1.0 * (enclose_area - union_area) / enclose_area\n",
        "\n",
        "    return giou\n",
        "\n",
        "# testing (should be better than giou)\n",
        "def bbox_ciou(boxes1, boxes2):\n",
        "    boxes1_coor = tf.concat([boxes1[..., :2] - boxes1[..., 2:] * 0.5,\n",
        "                        boxes1[..., :2] + boxes1[..., 2:] * 0.5], axis=-1)\n",
        "    boxes2_coor = tf.concat([boxes2[..., :2] - boxes2[..., 2:] * 0.5,\n",
        "                        boxes2[..., :2] + boxes2[..., 2:] * 0.5], axis=-1)\n",
        "\n",
        "    left = tf.maximum(boxes1_coor[..., 0], boxes2_coor[..., 0])\n",
        "    up = tf.maximum(boxes1_coor[..., 1], boxes2_coor[..., 1])\n",
        "    right = tf.maximum(boxes1_coor[..., 2], boxes2_coor[..., 2])\n",
        "    down = tf.maximum(boxes1_coor[..., 3], boxes2_coor[..., 3])\n",
        "\n",
        "    c = (right - left) * (right - left) + (up - down) * (up - down)\n",
        "    iou = bbox_iou(boxes1, boxes2)\n",
        "\n",
        "    u = (boxes1[..., 0] - boxes2[..., 0]) * (boxes1[..., 0] - boxes2[..., 0]) + (boxes1[..., 1] - boxes2[..., 1]) * (boxes1[..., 1] - boxes2[..., 1])\n",
        "    d = u / c\n",
        "\n",
        "    ar_gt = boxes2[..., 2] / boxes2[..., 3]\n",
        "    ar_pred = boxes1[..., 2] / boxes1[..., 3]\n",
        "\n",
        "    ar_loss = 4 / (np.pi * np.pi) * (tf.atan(ar_gt) - tf.atan(ar_pred)) * (tf.atan(ar_gt) - tf.atan(ar_pred))\n",
        "    alpha = ar_loss / (1 - iou + ar_loss + 0.000001)\n",
        "    ciou_term = d + alpha * ar_loss\n",
        "\n",
        "    return iou - ciou_term\n",
        "\n",
        "\n",
        "def compute_loss(pred, conv, label, bboxes, i=0, CLASSES=YOLO_COCO_CLASSES):\n",
        "    NUM_CLASS = len(read_class_names(CLASSES))\n",
        "    conv_shape  = tf.shape(conv)\n",
        "    batch_size  = conv_shape[0]\n",
        "    output_size = conv_shape[1]\n",
        "    input_size  = STRIDES[i] * output_size\n",
        "    conv = tf.reshape(conv, (batch_size, output_size, output_size, 3, 5 + NUM_CLASS))\n",
        "\n",
        "    conv_raw_conf = conv[:, :, :, :, 4:5]\n",
        "    conv_raw_prob = conv[:, :, :, :, 5:]\n",
        "\n",
        "    pred_xywh     = pred[:, :, :, :, 0:4]\n",
        "    pred_conf     = pred[:, :, :, :, 4:5]\n",
        "\n",
        "    label_xywh    = label[:, :, :, :, 0:4]\n",
        "    respond_bbox  = label[:, :, :, :, 4:5]\n",
        "    label_prob    = label[:, :, :, :, 5:]\n",
        "\n",
        "    giou = tf.expand_dims(bbox_giou(pred_xywh, label_xywh), axis=-1)\n",
        "    input_size = tf.cast(input_size, tf.float32)\n",
        "\n",
        "    bbox_loss_scale = 2.0 - 1.0 * label_xywh[:, :, :, :, 2:3] * label_xywh[:, :, :, :, 3:4] / (input_size ** 2)\n",
        "    giou_loss = respond_bbox * bbox_loss_scale * (1 - giou)\n",
        "\n",
        "    iou = bbox_iou(pred_xywh[:, :, :, :, np.newaxis, :], bboxes[:, np.newaxis, np.newaxis, np.newaxis, :, :])\n",
        "    # Find the value of IoU with the real box The largest prediction box\n",
        "    max_iou = tf.expand_dims(tf.reduce_max(iou, axis=-1), axis=-1)\n",
        "\n",
        "    # If the largest iou is less than the threshold, it is considered that the prediction box contains no objects, then the background box\n",
        "    respond_bgd = (1.0 - respond_bbox) * tf.cast( max_iou < YOLO_IOU_LOSS_THRESH, tf.float32 )\n",
        "\n",
        "    conf_focal = tf.pow(respond_bbox - pred_conf, 2)\n",
        "\n",
        "    # Calculate the loss of confidence\n",
        "    # we hope that if the grid contains objects, then the network output prediction box has a confidence of 1 and 0 when there is no object.\n",
        "    conf_loss = conf_focal * (\n",
        "            respond_bbox * tf.nn.sigmoid_cross_entropy_with_logits(labels=respond_bbox, logits=conv_raw_conf)\n",
        "            +\n",
        "            respond_bgd * tf.nn.sigmoid_cross_entropy_with_logits(labels=respond_bbox, logits=conv_raw_conf)\n",
        "    )\n",
        "\n",
        "    prob_loss = respond_bbox * tf.nn.sigmoid_cross_entropy_with_logits(labels=label_prob, logits=conv_raw_prob)\n",
        "\n",
        "    giou_loss = tf.reduce_mean(tf.reduce_sum(giou_loss, axis=[1,2,3,4]))\n",
        "    conf_loss = tf.reduce_mean(tf.reduce_sum(conf_loss, axis=[1,2,3,4]))\n",
        "    prob_loss = tf.reduce_mean(tf.reduce_sum(prob_loss, axis=[1,2,3,4]))\n",
        "\n",
        "    return giou_loss, conf_loss, prob_loss"
      ],
      "metadata": {
        "id": "1Mq4zuz5fxZl"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}