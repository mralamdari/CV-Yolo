{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "YoloV3_tensorflow.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "-fjorTWDTECu",
        "PghgbUBPVX7i",
        "LW19EmO_WRBI"
      ],
      "mount_file_id": "1dqRmo_debScf0VI5pDyTHAeut5ZOCf3K",
      "authorship_tag": "ABX9TyOBVNL5vH/9axrns7oWSLlR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mralamdari/CV-Yolo/blob/main/YoloV3_tensorflow.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "Pq0LkzkGWBly"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Yolo with COCO Dataset"
      ],
      "metadata": {
        "id": "RweKo5-agtLb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.Clone and build Darknet"
      ],
      "metadata": {
        "id": "-fjorTWDTECu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/AlexeyAB/darknet"
      ],
      "metadata": {
        "id": "MOENav_RTKfP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# change makefile to have gpu and opencv enabled\n",
        "%cd darknet\n",
        "!sed -i 's/OPENCV=0/OPENCV=1/' Makefile\n",
        "!sed -i 's/GPU=0/GPU=1/' Makefile\n",
        "!sed -i 's/CUDNN=0/CUDNN=1/' Makefile"
      ],
      "metadata": {
        "id": "hMQURsX4TShy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# verify CUDA\n",
        "!/usr/local/cuda/bin/nvcc --version"
      ],
      "metadata": {
        "id": "BVHIKu8PUduU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Build(make) Darknet\n",
        "!make"
      ],
      "metadata": {
        "id": "jp8YyEauUz0z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Yolov3 Weights"
      ],
      "metadata": {
        "id": "PghgbUBPVX7i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://pjreddie.com/media/files/yolov3.weights"
      ],
      "metadata": {
        "id": "ol43VVGaU72h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def imShow(path):\n",
        "  image = cv2.imread(path)\n",
        "  height, width = image.shape[:2]\n",
        "  resized_image = cv2.resize(image,(3*width, 3*height), interpolation = cv2.INTER_CUBIC)\n",
        "\n",
        "  fig = plt.gcf()\n",
        "  fig.set_size_inches(18, 10)\n",
        "  plt.axis(\"off\")\n",
        "  plt.imshow(cv2.cvtColor(resized_image, cv2.COLOR_BGR2RGB))\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "UcOF28eMVwlh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.Predict\n",
        "    !./darknet detect <path to config> <path to weights> <path to image>\n",
        "\n",
        "    imShow('predictions.jpg')\n",
        "\n"
      ],
      "metadata": {
        "id": "LW19EmO_WRBI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://images.unsplash.com/photo-1583430999116-511887f6ee69?ixlib=rb-1.2.1&dl=donny-jiang-OWrC7nDbeM0-unsplash.jpg&q=80&fm=jpg&crop=entropy&cs=tinysrgb\n",
        "!wget https://images.unsplash.com/photo-1483526682683-7560afbb5299?ixlib=rb-1.2.1&dl=elias-ehmann-eP93fjCLv4g-unsplash.jpg&q=80&fm=jpg&crop=entropy&cs=tinysrgb\n",
        "!wget https://images.unsplash.com/photo-1520011554120-17c4c63fc213?ixlib=rb-1.2.1&dl=joseph-cooper-lEwc9W5eLH0-unsplash.jpg&q=80&fm=jpg&crop=entropy&cs=tinysrgb"
      ],
      "metadata": {
        "id": "fF08BtEPWczz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!./darknet detect cfg/yolov3.cfg yolov3.weights data/person.jpg"
      ],
      "metadata": {
        "id": "ODk47CSBWFEh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "imShow('predictions.jpg')"
      ],
      "metadata": {
        "id": "1e2CQ39aW0pc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# LOCAL MACHINE DOWNLOAD\n",
        "download('predictions.jpg')\n",
        "\n",
        "# GOOGLE DRIVE DOWNLOAD\n",
        "!cp predictions.jpg /content/drive/MyDrive/Classroom/detection1.jpg"
      ],
      "metadata": {
        "id": "ZzHFfWqUXg6i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Yolo with Custom Dataset"
      ],
      "metadata": {
        "id": "lIAV9AlMgwti"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/mralamdari/OIDv4_ToolKit.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yoKshcf3g0FG",
        "outputId": "8a722796-e804-48e3-d29b-1a03a3866bad"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'OIDv4_ToolKit'...\n",
            "remote: Enumerating objects: 444, done.\u001b[K\n",
            "remote: Total 444 (delta 0), reused 0 (delta 0), pack-reused 444\u001b[K\n",
            "Receiving objects: 100% (444/444), 34.09 MiB | 35.99 MiB/s, done.\n",
            "Resolving deltas: 100% (157/157), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd OIDv4_ToolKit\n",
        "!pip3 install -r requirements.txt"
      ],
      "metadata": {
        "id": "vvSFjvM9k7km"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 main.py downloader --classes Traffic_sign --type_csv train --limit 10"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7DIuOEPUut9C",
        "outputId": "bc58a311-bb92-4beb-f6f9-49cf589a8842"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[92m\n",
            "\t\t   ___   _____  ______            _    _    \n",
            "\t\t .'   `.|_   _||_   _ `.         | |  | |   \n",
            "\t\t/  .-.  \\ | |    | | `. \\ _   __ | |__| |_  \n",
            "\t\t| |   | | | |    | |  | |[ \\ [  ]|____   _| \n",
            "\t\t\\  `-'  /_| |_  _| |_.' / \\ \\/ /     _| |_  \n",
            "\t\t `.___.'|_____||______.'   \\__/     |_____|\n",
            "\t\u001b[0m\n",
            "\u001b[92m\n",
            "             _____                    _                 _             \n",
            "            (____ \\                  | |               | |            \n",
            "             _   \\ \\ ___  _ _ _ ____ | | ___   ____  _ | | ____  ____ \n",
            "            | |   | / _ \\| | | |  _ \\| |/ _ \\ / _  |/ || |/ _  )/ ___)\n",
            "            | |__/ / |_| | | | | | | | | |_| ( ( | ( (_| ( (/ /| |    \n",
            "            |_____/ \\___/ \\____|_| |_|_|\\___/ \\_||_|\\____|\\____)_|    \n",
            "                                                          \n",
            "        \u001b[0m\n",
            "    [INFO] | Downloading Traffic sign.\u001b[0m\n",
            "\u001b[91m   [ERROR] | Missing the class-descriptions-boxable.csv file.\u001b[0m\n",
            "\u001b[94m[DOWNLOAD] | Do you want to download the missing file? [Y/n] \u001b[0mY\n",
            "...145%, 0 MB, 41019 KB/s, 0 seconds passed\n",
            "\u001b[94m[DOWNLOAD] | File class-descriptions-boxable.csv downloaded into OID/csv_folder/class-descriptions-boxable.csv.\u001b[0m\n",
            "\u001b[91m   [ERROR] | Missing the train-annotations-bbox.csv file.\u001b[0m\n",
            "\u001b[94m[DOWNLOAD] | Do you want to download the missing file? [Y/n] \u001b[0mY\n",
            "...100%, 1138 MB, 36651 KB/s, 31 seconds passed\n",
            "\u001b[94m[DOWNLOAD] | File train-annotations-bbox.csv downloaded into OID/csv_folder/train-annotations-bbox.csv.\u001b[0m\n",
            "\n",
            "\u001b[95mTraffic sign\u001b[0m\n",
            "    [INFO] | Downloading train images.\u001b[0m\n",
            "    [INFO] | [INFO] Found 2817 online images for train.\u001b[0m\n",
            "    [INFO] | Limiting to 10 images.\u001b[0m\n",
            "    [INFO] | Download of 10 images in train.\u001b[0m\n",
            "100% 10/10 [00:04<00:00,  2.21it/s]\n",
            "    [INFO] | Done!\u001b[0m\n",
            "    [INFO] | Creating labels for Traffic sign of train.\u001b[0m\n",
            "    [INFO] | Labels creation completed.\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 convert_annotations.py"
      ],
      "metadata": {
        "id": "5nsw396tvLKK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "501569d6-be0c-4a26-bece-482fe63adb65"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Currently in subdirectory: train\n",
            "Converting annotations for class:  Traffic sign\n",
            "\r  0% 0/10 [00:00<?, ?it/s]\r  0% 0/10 [00:00<?, ?it/s]\n",
            "Traceback (most recent call last):\n",
            "  File \"convert_annotations.py\", line 63, in <module>\n",
            "    coords = np.asarray([float(labels[1]), float(labels[2]), float(labels[3]), float(labels[4])])\n",
            "ValueError: could not convert string to float: 'sign'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import argparse\n",
        "import fileinput\n",
        "\n",
        "# function that turns XMin, YMin, XMax, YMax coordinates to normalized yolo format\n",
        "def convert(filename_str, coords):\n",
        "    os.chdir(\"..\")\n",
        "    image = cv2.imread(filename_str + \".jpg\")\n",
        "    coords[2] -= coords[0]\n",
        "    coords[3] -= coords[1]\n",
        "    x_diff = int(coords[2]/2)\n",
        "    y_diff = int(coords[3]/2)\n",
        "    coords[0] = coords[0]+x_diff\n",
        "    coords[1] = coords[1]+y_diff\n",
        "    coords[0] /= int(image.shape[1])\n",
        "    coords[1] /= int(image.shape[0])\n",
        "    coords[2] /= int(image.shape[1])\n",
        "    coords[3] /= int(image.shape[0])\n",
        "    os.chdir(\"Label\")\n",
        "    return coords\n",
        "\n",
        "ROOT_DIR = os.getcwd()\n",
        "\n",
        "# create dict to map class names to numbers for yolo\n",
        "classes = {}\n",
        "with open(\"classes.txt\", \"r\") as myFile:\n",
        "    for num, line in enumerate(myFile, 0):\n",
        "        line = line.rstrip(\"\\n\")\n",
        "        classes[line] = num\n",
        "    myFile.close()\n",
        "# step into dataset directory\n",
        "os.chdir(os.path.join(\"OID\", \"Dataset\"))\n",
        "DIRS = os.listdir(os.getcwd())\n",
        "\n",
        "# for all train, validation and test folders\n",
        "for DIR in DIRS:\n",
        "    if os.path.isdir(DIR):\n",
        "        os.chdir(DIR)\n",
        "        print(\"Currently in subdirectory:\", DIR)\n",
        "        \n",
        "        CLASS_DIRS = os.listdir(os.getcwd())\n",
        "        # for all class folders step into directory to change annotations\n",
        "        for CLASS_DIR in CLASS_DIRS:\n",
        "            if os.path.isdir(CLASS_DIR):\n",
        "                os.chdir(CLASS_DIR)\n",
        "                print(\"Converting annotations for class: \", CLASS_DIR)\n",
        "                \n",
        "                # Step into Label folder where annotations are generated\n",
        "                os.chdir(\"Label\")\n",
        "\n",
        "                for filename in tqdm(os.listdir(os.getcwd())):\n",
        "                    filename_str = str.split(filename, \".\")[0]\n",
        "                    if filename.endswith(\".txt\"):\n",
        "                        annotations = []\n",
        "                        with open(filename) as f:\n",
        "                            for line in f:\n",
        "                                for class_type in classes:\n",
        "                                    line = line.replace(class_type, str(classes.get(class_type)))\n",
        "                                labels = line.split()\n",
        "                                coords = np.asarray([float(labels[1]), float(labels[2]), float(labels[3]), float(labels[4])])\n",
        "                                coords = convert(filename_str, coords)\n",
        "                                labels[1], labels[2], labels[3], labels[4] = coords[0], coords[1], coords[2], coords[3]\n",
        "                                newline = str(labels[0]) + \" \" + str(labels[1]) + \" \" + str(labels[2]) + \" \" + str(labels[3]) + \" \" + str(labels[4])\n",
        "                                line = line.replace(line, newline)\n",
        "                                annotations.append(line)\n",
        "                            f.close()\n",
        "                        os.chdir(\"..\")\n",
        "                        with open(filename, \"w\") as outfile:\n",
        "                            for line in annotations:\n",
        "                                outfile.write(line)\n",
        "                                outfile.write(\"\\n\")\n",
        "                            outfile.close()\n",
        "                        os.chdir(\"Label\")\n",
        "                os.chdir(\"..\")\n",
        "                os.chdir(\"..\")\n",
        "        os.chdir(\"..\")\n"
      ],
      "metadata": {
        "id": "So0HQP912XA-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "outputId": "951b5bbb-44a7-4648-f086-ac2dda34db24"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "usage: ipykernel_launcher.py [-h] [--Dataset /path/to/OID/csv/] [-y]\n",
            "                             [--classes list of classes [list of classes ...]]\n",
            "                             [--type_csv 'train' or 'validation' or 'test' or 'all']\n",
            "                             [--sub Subset of human verified images or machine generated h or m)]\n",
            "                             [--image_IsOccluded 1 or 0]\n",
            "                             [--image_IsTruncated 1 or 0]\n",
            "                             [--image_IsGroupOf 1 or 0]\n",
            "                             [--image_IsDepiction 1 or 0]\n",
            "                             [--image_IsInside 1 or 0]\n",
            "                             [--multiclasses 0 (default or 1]\n",
            "                             [--n_threads [default 20]] [--noLabels]\n",
            "                             [--limit integer number]\n",
            "                             <command> 'downloader', 'visualizer' or\n",
            "                             'ill_downloader'.\n",
            "ipykernel_launcher.py: error: unrecognized arguments: -f\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "SystemExit",
          "evalue": "ignored",
          "traceback": [
            "An exception has occurred, use %tb to see the full traceback.\n",
            "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py:3334: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
            "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mZZdsoh1Bcuu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}